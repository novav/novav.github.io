<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"novav.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Simon Shi的小站">
<meta property="og:url" content="https://novav.github.io/page/21/index.html">
<meta property="og:site_name" content="Simon Shi的小站">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Simon Shi">
<meta property="article:tag" content="AI,Machine Learning, Deep Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://novav.github.io/page/21/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Simon Shi的小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Simon Shi的小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能，机器学习， 强化学习，大模型，自动驾驶</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2022/01/01/Course/ActionGenerated/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/01/Course/ActionGenerated/" class="post-title-link" itemprop="url">AI应用热点方向</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-01 00:00:00" itemprop="dateCreated datePublished" datetime="2022-01-01T00:00:00+00:00">2022-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/Apply/" itemprop="url" rel="index"><span itemprop="name">Apply</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>AI生成骨骼动画</p>
</li>
<li><p>动作生成(miHoYo)</p>
</li>
</ul>
<p>​        PFNN <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/430442398">动作合成经典之作-PFNN</a></p>
<p>​        NSM</p>
<p>​        <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50141261">Motion Matching 的介绍</a></p>
<ul>
<li>deformation算法</li>
</ul>
<p>​    </p>
<ul>
<li>行为&#x2F;运动控制，规划，交互方向</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2022/01/01/Sub_Language/CUDA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/01/01/Sub_Language/CUDA/" class="post-title-link" itemprop="url">CUDA版本问题解决</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-01-01 00:00:00" itemprop="dateCreated datePublished" datetime="2022-01-01T00:00:00+00:00">2022-01-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/CUDA/" itemprop="url" rel="index"><span itemprop="name">CUDA</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="Ubuntu系统下的驱动安装"><a href="#Ubuntu系统下的驱动安装" class="headerlink" title="Ubuntu系统下的驱动安装"></a>Ubuntu系统下的驱动安装</h2><p>1- Ubuntu16 ()</p>
<ul>
<li>nvidia-384安装成功</li>
</ul>
<p>2- Ubuntu18 (驱动版本太低,无法安装成功)</p>
<ul>
<li><p>驱动410安装: 为了与UbuntuServer版本服务器一致，在18.04最新桌面版上安装410驱动，但是一直报内核报错，尝试了所有的安装方式，都无法顺利安装成功</p>
</li>
<li><p>网上也没有类似的问题，最终准备换440的驱动安装，安装成功</p>
</li>
</ul>
<h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h2><p>CUDA 驱动对应版本 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html</a></p>
<p>CUDA 下载 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a></p>
<table>
<thead>
<tr>
<th>CUDA Toolkit</th>
<th>Minimum Required Driver Version for CUDA Minor Version Compatibility*</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>Linux x86_64 Driver Version</td>
<td>Windows x86_64 Driver Version</td>
</tr>
<tr>
<td>CUDA 12.x</td>
<td>&gt;&#x3D;525.60.13</td>
<td>&gt;&#x3D;528.33</td>
</tr>
<tr>
<td>CUDA 11.8.x CUDA 11.7.x CUDA 11.6.x CUDA 11.5.x CUDA 11.4.x CUDA 11.3.x CUDA 11.2.x CUDA 11.1.x</td>
<td>&gt;&#x3D;450.80.02</td>
<td>&gt;&#x3D;452.39</td>
</tr>
<tr>
<td>CUDA 11.0 (11.0.3)</td>
<td>&gt;&#x3D;450.36.06**</td>
<td>&gt;&#x3D;451.22**</td>
</tr>
</tbody></table>
<p>\</p>
<table>
<thead>
<tr>
<th>CUDA 12.4 GA</th>
<th>&gt;&#x3D;550.54.14</th>
<th>&gt;&#x3D;551.61</th>
</tr>
</thead>
<tbody><tr>
<td>CUDA 12.3 Update 1</td>
<td>&gt;&#x3D;545.23.08</td>
<td>&gt;&#x3D;546.12</td>
</tr>
<tr>
<td>CUDA 12.3 GA</td>
<td>&gt;&#x3D;545.23.06</td>
<td>&gt;&#x3D;545.84</td>
</tr>
<tr>
<td>CUDA 12.2 Update 2</td>
<td>&gt;&#x3D;535.104.05</td>
<td>&gt;&#x3D;537.13</td>
</tr>
<tr>
<td>CUDA 12.2 Update 1</td>
<td>&gt;&#x3D;535.86.09</td>
<td>&gt;&#x3D;536.67</td>
</tr>
<tr>
<td>CUDA 12.2 GA</td>
<td>&gt;&#x3D;535.54.03</td>
<td>&gt;&#x3D;536.25</td>
</tr>
<tr>
<td>CUDA 12.1 Update 1</td>
<td>&gt;&#x3D;530.30.02</td>
<td>&gt;&#x3D;531.14</td>
</tr>
<tr>
<td>CUDA 12.1 GA</td>
<td>&gt;&#x3D;530.30.02</td>
<td>&gt;&#x3D;531.14</td>
</tr>
<tr>
<td>CUDA 12.0 Update 1</td>
<td>&gt;&#x3D;525.85.12</td>
<td>&gt;&#x3D;528.33</td>
</tr>
<tr>
<td>CUDA 12.0 GA</td>
<td>&gt;&#x3D;525.60.13</td>
<td>&gt;&#x3D;527.41</td>
</tr>
<tr>
<td>CUDA 11.8 GA</td>
<td>&gt;&#x3D;520.61.05</td>
<td>&gt;&#x3D;520.06</td>
</tr>
<tr>
<td>CUDA 11.7 Update 1</td>
<td>&gt;&#x3D;515.48.07</td>
<td>&gt;&#x3D;516.31</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>CUDA Toolkit</th>
<th>Linux x86_64 Driver Version</th>
<th>Windows x86_64 Driver Version</th>
</tr>
</thead>
<tbody><tr>
<td>CUDA 11.7 GA</td>
<td>&gt;&#x3D;515.43.04</td>
<td>&gt;&#x3D;516.01</td>
</tr>
<tr>
<td>CUDA 11.6 Update 2</td>
<td>&gt;&#x3D;510.47.03</td>
<td>&gt;&#x3D;511.65</td>
</tr>
<tr>
<td>CUDA 11.6 Update 1</td>
<td>&gt;&#x3D;510.47.03</td>
<td>&gt;&#x3D;511.65</td>
</tr>
<tr>
<td>CUDA 11.6 GA</td>
<td>&gt;&#x3D;510.39.01</td>
<td>&gt;&#x3D;511.23</td>
</tr>
<tr>
<td>CUDA 11.5 Update 2</td>
<td>&gt;&#x3D;495.29.05</td>
<td>&gt;&#x3D;496.13</td>
</tr>
<tr>
<td>CUDA 11.5 Update 1</td>
<td>&gt;&#x3D;495.29.05</td>
<td>&gt;&#x3D;496.13</td>
</tr>
<tr>
<td>CUDA 11.5 GA</td>
<td>&gt;&#x3D;495.29.05</td>
<td>&gt;&#x3D;496.04</td>
</tr>
<tr>
<td>CUDA 11.4 Update 4</td>
<td>&gt;&#x3D;470.82.01</td>
<td>&gt;&#x3D;472.50</td>
</tr>
<tr>
<td>CUDA 11.4 Update 3</td>
<td>&gt;&#x3D;470.82.01</td>
<td>&gt;&#x3D;472.50</td>
</tr>
<tr>
<td>CUDA 11.4 Update 2</td>
<td>&gt;&#x3D;470.57.02</td>
<td>&gt;&#x3D;471.41</td>
</tr>
<tr>
<td>CUDA 11.4 Update 1</td>
<td>&gt;&#x3D;470.57.02</td>
<td>&gt;&#x3D;471.41</td>
</tr>
<tr>
<td>CUDA 11.4.0 GA</td>
<td>&gt;&#x3D;470.42.01</td>
<td>&gt;&#x3D;471.11</td>
</tr>
<tr>
<td>CUDA 11.3.1 Update 1</td>
<td>&gt;&#x3D;465.19.01</td>
<td>&gt;&#x3D;465.89</td>
</tr>
<tr>
<td>CUDA 11.3.0 GA</td>
<td>&gt;&#x3D;465.19.01</td>
<td>&gt;&#x3D;465.89</td>
</tr>
<tr>
<td>CUDA 11.2.2 Update 2</td>
<td>&gt;&#x3D;460.32.03</td>
<td>&gt;&#x3D;461.33</td>
</tr>
<tr>
<td>CUDA 11.2.1 Update 1</td>
<td>&gt;&#x3D;460.32.03</td>
<td>&gt;&#x3D;461.09</td>
</tr>
<tr>
<td>CUDA 11.2.0 GA</td>
<td>&gt;&#x3D;460.27.03</td>
<td>&gt;&#x3D;460.82</td>
</tr>
<tr>
<td><strong>CUDA 10.2.89</strong></td>
<td>&gt;&#x3D; 440.33</td>
<td>&gt;&#x3D; 441.22</td>
</tr>
<tr>
<td>CUDA 10.1 (10.1.105 general release, and updates)</td>
<td>&gt;&#x3D; 418.39</td>
<td>&gt;&#x3D; 418.96</td>
</tr>
<tr>
<td><strong>CUDA 10.0.130</strong></td>
<td>&gt;&#x3D; 410.48</td>
<td>&gt;&#x3D; 411.31</td>
</tr>
<tr>
<td><strong>CUDA 9.2 (9.2.148 Update 1)</strong></td>
<td>&gt;&#x3D; 396.37</td>
<td>&gt;&#x3D; 398.26</td>
</tr>
<tr>
<td>CUDA 9.2 (9.2.88)</td>
<td>&gt;&#x3D; 396.26</td>
<td>&gt;&#x3D; 397.44</td>
</tr>
<tr>
<td>CUDA 9.1 (9.1.85)</td>
<td>&gt;&#x3D; 390.46</td>
<td>&gt;&#x3D; 391.29</td>
</tr>
<tr>
<td>CUDA 9.0 (9.0.76)</td>
<td>&gt;&#x3D; 384.81</td>
<td>&gt;&#x3D; 385.54</td>
</tr>
<tr>
<td>CUDA 8.0 (8.0.61 GA2)</td>
<td>&gt;&#x3D; 375.26</td>
<td>&gt;&#x3D; 376.51</td>
</tr>
<tr>
<td>CUDA 8.0 (8.0.44)</td>
<td>&gt;&#x3D; 367.48</td>
<td>&gt;&#x3D; 369.30</td>
</tr>
<tr>
<td>CUDA 7.5 (7.5.16)</td>
<td>&gt;&#x3D; 352.31</td>
<td>&gt;&#x3D; 353.66</td>
</tr>
<tr>
<td>CUDA 7.0 (7.0.28)</td>
<td>&gt;&#x3D; 346.46</td>
<td>&gt;&#x3D; 347.62</td>
</tr>
</tbody></table>
<h2 id="CUDNN"><a href="#CUDNN" class="headerlink" title="CUDNN"></a>CUDNN</h2><p><a target="_blank" rel="noopener" href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a></p>
<h2 id="算力评估"><a href="#算力评估" class="headerlink" title="算力评估"></a>算力评估</h2><ul>
<li>10.1之前的，可以去cuda自带的目录下，编译测试<ul>
<li>&#x2F;usr&#x2F;local&#x2F;cuda-9.0&#x2F;samples&#x2F;5_simulations&#x2F;</li>
</ul>
</li>
<li>11及之后的版本，需要去GitHub上下载，编译测试<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/NVIDIA/cuda-samples/tree/master/Samples/4_CUDA_Libraries/batchCUBLAS">Nvidia-cuda-sample batchCBLAS</a></li>
</ul>
</li>
</ul>
<h3 id="Cuda-GPU"><a href="#Cuda-GPU" class="headerlink" title="Cuda-GPU"></a>Cuda-GPU</h3><table>
<thead>
<tr>
<th>GPU</th>
<th>Compute Capability</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/geforce/gaming-laptops/#specs">GeForce RTX 3070</a></td>
<td>8.6</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/geforce/gaming-laptops/#specs">GeForce RTX 3060</a></td>
<td>8.6</td>
</tr>
</tbody></table>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/12/24/ResearchRecord/Papers-Log-2021/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/24/ResearchRecord/Papers-Log-2021/" class="post-title-link" itemprop="url">Papers Log 2021</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-24 12:00:00" itemprop="dateCreated datePublished" datetime="2021-12-24T12:00:00+00:00">2021-12-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Papers/" itemprop="url" rel="index"><span itemprop="name">Papers</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Papers/Years/" itemprop="url" rel="index"><span itemprop="name">Years</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN:"></a>GAN:</h2><ul>
<li><p>StarGAN</p>
</li>
<li><p>DeepFakeLab</p>
</li>
<li><p>CoGAN</p>
</li>
<li><p>DiscoFaceGAN</p>
</li>
<li><p>SimSwap</p>
</li>
</ul>
<h2 id="CV"><a href="#CV" class="headerlink" title="CV:"></a>CV:</h2><ul>
<li><p>WhiteBox</p>
</li>
<li><p>CartoonBody</p>
</li>
<li><p>photo2cartoon</p>
</li>
<li><p>pix2pix</p>
</li>
<li><p>CycleGan</p>
</li>
<li><p>AgileGAN</p>
</li>
</ul>
<h2 id="Game"><a href="#Game" class="headerlink" title="Game:"></a>Game:</h2><ul>
<li>DeltaDou</li>
<li>POG</li>
<li>DouZero</li>
<li>MuZero</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/12/19/Games/Paper-Game-POG/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/19/Games/Paper-Game-POG/" class="post-title-link" itemprop="url">Player Of Game(POG)论文翻译</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-19 11:39:58" itemprop="dateCreated datePublished" datetime="2021-12-19T11:39:58+00:00">2021-12-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:39" itemprop="dateModified" datetime="2025-08-06T08:16:39+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/" itemprop="url" rel="index"><span itemprop="name">Game</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/Imperfect-Information-Game/" itemprop="url" rel="index"><span itemprop="name">Imperfect Information Game</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Pog</p>
<p>[toc]</p>
<p>Abstract游戏作为人工智能发展的基准由来已久。最近，使用搜索和学习的方法在一组完美信息博弈中表现出了很强的表现，而使用博弈论推理和学习的方法在特定的不完美信息扑克变种中表现出了很强的表现。我们介绍了一种将引导搜索、自玩学习和博弈论推理相结合的通用算法Player of Games。players of Games是第一个在大型完备和不完备信息博弈中取得较强经验性能的算法—–这是向真正适用于任意环境的通用算法迈出的重要一步。我们证明了 Player of Games 是健全的，随着可用计算时间和近似容量的增加，收敛到完美的游戏。 Player of Games在国际象棋和围棋方面取得了强劲的表现，在单挑无限注德州扑克  中击败了最强大的公开智能体(Slumbot)，并在苏格兰场击败了最先进的Agent。 一个不完美的信息游戏，说明了引导搜索、学习和博弈论推理的价值。 </p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>在 1950 年代，Arthur L. Samuel 开发了一个跳棋程序，该程序采用了现在所谓的极小极大搜索（带有 alpha-beta 剪枝）和“（死记硬背）rote learning”，通过自我对弈来改进其评估功能 [62]。这项调查启发了许多其他人，最终塞缪尔共同创立了人工智能领域 [61] 并普及了“机器学习”一词。几年前，世界目睹了一个计算机程序在围棋比赛中击败了一位长期存在的专业人士 [70]。 AlphaGo 还结合了学习和搜索。许多类似的成就发生在这两者之间，例如super-human象棋的竞赛导致DeepBlue[17]，TD-Gammon通过自我对弈自学在西洋双陆棋（Backgammon ）中发挥大师级的表现[82]，延续了将游戏作为该领域主流进程的典型标志。    </p>
<p>​		在整个成功的过程中，有一个重要的共同元素：专注于单一游戏。确实，深蓝不会下围棋，塞缪尔的程序也不会下国际象棋。同样，AlphaGo 也不会下国际象棋；然而，它的继任者 AlphaZero [71] 能够并且做到了。 AlphaZero 证明了使用 AlphaGo 方法的简化，并且以最少的人类知识，单个算法可以掌握三种不同的完美信息游戏。尽管取得了这一成功，但 AlphaZero 不能玩扑克，而且对不完美信息游戏的扩展尚不清楚。    与此同时，实现超人类扑克人工智能的方法也大不相同。强大的扑克游戏依赖于博弈论推理来确保有效隐藏私人信息。最初，超人类扑克代理人主要基于计算近似纳什均衡oﬄine [37]。然后添加了搜索，并证明是在无限变体中取得超人成功的关键因素 [55, 11, 12]。其他大型游戏的训练也受到<strong>博弈论推理</strong>和<strong>搜索</strong>的启发，例如 Hanabi [4, 44]、The Resistance [69]、Bridge [49]、AlphaStar [83] 和（无新闻）外交【 (no-press) Diplomacy】 [ 2, 25, 3]。然而，尽管取得了显着的成功：每一次进步仍然是在一个单一的游戏中，明确使用特定领域的知识和结构来实现强大的性能。 </p>
<p>​		在本文中，我们介绍了游戏玩家 (PoG)，这是一种新算法，它概括了可以使用自我对弈学习、搜索和博弈论推理实现强大性能的游戏类别。 PoG 使用growing-tree反事实后悔最小化（GT-CFR）：一种随时局部搜索，非均匀地构建子博弈，将树扩展到最相关的未来状态，同时迭代地改进价值和策略。此外，PoG 采用合理的自我对弈：一种学习过程，该过程使用博弈结果和应用于先前搜索中出现的情况的递归子搜索来训练价值和策略网络。 </p>
<p>​		Player of Games 是第一个在具有完美和不完美信息的挑战领域中实现强大性能的算法——这是迈向可以在任意环境中学习的真正通用算法的重要一步。传统搜索的应用在不完美信息博弈中存在众所周知的问题 [61]。尽管最近在不完美信息游戏中的合理搜索取得了进展 [55, 10, 84]，但评估仍然集中在单个领域（例如扑克）。 Player of Games 填补了这一空白，它使用单一算法，以及很少领域特定知识。它在这些根本不同的游戏类型中的搜索是合理的 [84]：通过重新求解子游戏，以在在线游戏期间保持一致，保证找到一个近似的纳什均衡，并在可计算可利用性的小博弈中，在实践中产生较低的可利用性。 PoG 在四种不同的游戏中表现出强大的性能：两种完全信息（国际象棋和围棋）和两种不完全信息（扑克和苏格兰场）。最后，与扑克不同的是，苏格兰场的搜索范围和游戏长度明显更长，需要长期规划。 </p>
<h2 id="2-Background-and-Terminology"><a href="#2-Background-and-Terminology" class="headerlink" title="2 Background and Terminology"></a>2 Background and Terminology</h2><p>​		我们从必要的背景和符号开始来描述主要算法和结果。我们在第 5 节中将我们的算法与其他方法联系起来。在这里，我们简要介绍了必要的概念，这些概念基于因子观察随机博弈 (FOSG) 形式主义。有关形式主义的更多详细信息，请参见 [40, 64]。   </p>
<p>​		两个玩家之间的博弈从特定的世界状态 <a href="#">w^{init}</a>开始，然后进行到后继世界状态 w ∈ W 作为玩家选择动作 a ∈ A 的结果，直到达到最终状态时游戏结束。在任何世界状态 w，我们将使用符号 A(w) ⊆ A 来指代那些在世界状态 w 中可用或合法的动作。在游戏过程中采取的一系列动作称为历史，用 h ∈ H 表示，<a href="#">h^{‘} \subseteq h</a> 表示前缀历史（子序列）。在终端历史 z ⊂ H 处，每个玩家 i 收到一个效用 ui(z)。   </p>
<p>​		信息状态（私有状态）是关于一个玩家的信息的状态。具体来说，玩家 i 的 si ∈ Si 是一组由于缺少信息而无法区分的历史。一个简单的例子是扑克中的一个特定决策点，玩家 i 不知道对手的私人牌；信息状态中的历史仅在决定对手私人卡的机会事件结果上有所不同，因为其他一切都是公共知识。参与者 i 执行策略 πi : Si → Δ(A)，其中 Δ(A) 表示动作 A 的一组概率分布。每个参与者的目标是找到最大化他们自己预期效用的策略。 </p>
<p>​		每次玩家采取行动时，每个玩家都会得到一个<strong>私人观察 Opriv(i)(w, a, w )</strong> 和<strong>一个公开观察 Opub(w, a, w )</strong> 作为应用行动 a 的结果，改变游戏状态w 到 w 。公共状态 spub &#x3D; spub(h) ∈ Spub 是沿历史 h 遇到的公共观察序列。例如，德州扑克的公开状态由初始公开信息（筹码量和底注）、投注历史和任何公开显示的牌面代表。设 Si(spub) 是给定 spub 的玩家 i 的可能信息状态集合：每个信息状态 si ∈ Si(spub) 与 spub 中的公共观察一致，但具有不同的私人观察序列。例如，在扑克中，信息状态将包含玩家 i 的私人牌。 FOSG 的完整示例见附录 A。   </p>
<p>​		<strong>公共信念状态</strong> β &#x3D; (spub, r)，其中范围（或信念）r ∈ ∆(S1(spub))×∆(S2(spub)) 是代表两个参与者的可能信息状态的一对分布spub 中对信息状态的信念。图 1 描述了公共信仰状态的各个组成部分的基本描述。例如，在苏格兰场的游戏中，信息状态对应于逃避者（X 先生）的位置。一个具体的例子如图 2 所示。逃避者的真实位置是隐藏的，但可能是四个不同位置之一，侦探更怀疑逃避者在位置 63，而不是 35、62 或 78。在苏格兰场，r 中的分布之一是点质量，因为侦探没有对 X 先生隐藏任何私人信息。 <img src="https://uploader.shimo.im/f/7bF2LrZt1Is2olCj.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NDk2ODIyMDMsImciOiJXV3F3Q3ZSUjhXdFhRanRUIiwiaWF0IjoxNjQ5NjgxOTAzLCJ1c2VySWQiOjMyNzIxNjY5fQ.U9jNMkb0ZZcEMlHQ2fdRyY3GvN-Msz-GvMc4ftaszUY" alt="img"></p>
<p>Fig2: 在苏格兰场对公共信仰状态的描述:圆圈表示位置，边缘表示交通连接，红色的条表示对X先生所在位置的私人(未透露的)信息状态的beliefs。   </p>
<p>​		假设玩家使用联合策略 π &#x3D; (π1, π2)。将玩家对玩家 i 的期望效用表示为 ui(π1, π2)，将 -i 表示为玩家 i 的对手。<strong>最佳响应策略</strong>是针对某些 π−i 实现最大效用的任何策略 <a href="#">$$π_i^b：u_i(π_i^b, π_{−i}) &#x3D; max_{π_i^{‘}} u_i(π^{‘}<em>i, π</em>{−i})$$</a>。当且仅当 π1 是对 π2 的最佳响应且 π2 是对 π1 的最佳响应时，联合策略 π 是<strong>纳什均衡</strong>。还有近似均衡：当且仅当 ui(πib, π−i) − ui(πi, π−i) ≤ 所有参与者 i 时，π 是 <a href="#">$$\epsilon -Nash$$</a> <strong>均衡</strong>。在两人零和博弈中，纳什均衡是最优的，因为它们最大化了两个玩家的最坏情况效用保证。此外，均衡策略是可以互换的：如果 πA 和 πB 是纳什均衡，那么<a href="#">$(π_1^A, π_2^B)$</a>和 <a href="#">$(π_1^B, π_2^A)$</a> 也是均衡。因此，代理的目标是计算一种这样的最优（或近似最优)均衡策略。  </p>
<h3 id="2-1-Tree-Search-and-Machine-Learning"><a href="#2-1-Tree-Search-and-Machine-Learning" class="headerlink" title="2.1 Tree Search and Machine Learning"></a>2.1 Tree Search and Machine Learning</h3><p>​		人工智能领域的第一个主要里程碑是通过受极大极小定理启发的高效搜索技术获得的 [62, 17]。在具有完美信息的两人零和游戏中，该方法使用从当前世界状态 wt 开始的深度限制搜索，以及启发式评估函数来估计超出深度限制的状态值，h(wt+d ) 和博弈论推理来back up(倒推)价值 [38]。研究人员开发了显着的搜索增强功能 [52, 63]，极大地提高了性能，得到了 IBM 的超越人类的DeepBlue 国际象棋程序 [17]。 </p>
<p>​		然而，这种经典方法无法在围棋中实现超人类的表现，围棋的分支因子和状态空间复杂度明显高于国际象棋。在 Go [24] 的挑战下，研究人员提出了蒙特卡罗树搜索 (MCTS) [39, 18]。与极小极大搜索不同，MCTS 通过模拟构建树，从一棵以 wt 为根的空树开始，通过添加当前不在树中的模拟轨迹中遇到的第一个状态来扩展树，最后估计从 rollout 到游戏结束的值。 在围棋和其他游戏中MCTS发挥明显更强的作用 [14]，在围棋中达到 6 段业余水平。然而，领域知识形式的启发式方法对于实现这些里程碑仍然是必要的。   </p>
<p>​		在 AlphaGo [70] 中，价值函数和策略被合并，最初从人类专家数据中学习，然后通过自我对弈进行改进。深度网络近似值函数，先验策略有助于指导树搜索过程中动作的选择。该方法是第一个在围棋中实现超人类水平的方法 [70]。 AlphaGo Zero 移除了人类数据和围棋特定特征的初始训练 [72]。 AlphaZero 使用最少的领域知识在国际象棋和将棋以及围棋中达到了最先进的性能 [71]。   </p>
<p>​		PoG 与 AlphaZero 一样，使用最少的领域知识将<strong>搜索</strong>和从<strong>自我对弈</strong>中学习结合起来。然而，与 MCTS 不同，MCTS 不适用于不完美信息游戏，PoG 的搜索算法基于反事实后悔最小化，并且对于完美和不完美信息游戏都是合理的。</p>
<h3 id="2-2-Game-Theoretic-Reasoning-and-Counterfactual-Regret-Minimization"><a href="#2-2-Game-Theoretic-Reasoning-and-Counterfactual-Regret-Minimization" class="headerlink" title="2.2 Game-Theoretic Reasoning and Counterfactual Regret Minimization"></a><strong>2.2 Game-Theoretic Reasoning and Counterfactual Regret Minimization</strong></h3><p>​		在不完美信息博弈中，由隐藏信息产生的策略选择对于确定每个玩家的预期奖励至关重要。简单地玩太可预测可能会出现问题：在经典的示例游戏石头剪刀布中，玩家唯一不知道的是对手的行动选择，但是这些信息完全决定了他们可以获得的奖励。选择始终进行一个动作（例如rock）的玩家很容易被另一个做出最佳反应（例如paper）的玩家击败。纳什均衡以相等的概率执行每个动作，这将任何特定反策略的收益最小化。类似地，在扑克中，了解对手的牌或他们的策略可以产生显着更高的预期奖励，而在苏格兰场，如果知道玩家当前的位置，则有更高的机会抓住逃避者。在这些示例中，玩家可以利用隐藏信息的任何知识来执行反策略(counter-strategy)，从而获得更高的奖励。因此，为了避免被利用，玩家必须以不泄露自己私人信息的方式行事。我们将这种一般行为称为<strong>博弈论推理(<strong>gametheoretic reasoning</strong>)</strong>，因为它是计算（近似）极小极大优化策略的结果。在过去的 20 年里，博弈论推理对于竞争性扑克 AI 的成功至关重要。 </p>
<p>​		一种计算近似最优策略的算法是反事实后悔最小化（CFR）[86]。 CFR 是一种自我对弈算法，它以最小化长期平均遗憾的方式为每个玩家 i 在每个信息状态 s 上生成策略迭代 <a href="#">$π_i^t(s)$</a>。结果，CFR 在自我博弈中采用的 T次迭代平均策略<a href="#">$\bar{\pi}^{T}$</a>，以 O(1&#x2F; T ) 的速率收敛到  <a href="#">$\epsilon-Nash$</a>均衡。在每次迭代 ，为每个动作 a ∈ A(s) 计算 t 、反事实值 v_i(s, a)  和不玩 a 的直接遗憾，<a href="#">$r(s, a) &#x3D; v_i(s, a) − \sum_{a \in A (s)} π (s, a) v_i(s, a)$</a>被计算并列在一个累积后悔表中，存储 <a href="#">$R^T (s, a) &#x3D; \sum ^T_{t&#x3D;1} r^t(s, a)$</a>。使用遗憾匹配 [27] 计算新策略： <a href="#">$π^{t+1}(s) &#x3D; \frac{[R^t (s,a)]^+}{ \sum_a[R^t(s,a)]^+}$</a>，其中 <a href="#">$[x]^+ &#x3D; max (x, 0)$</a>，如果所有遗憾都是非正的，则重置为统一值。 CFR+ [79] 是 CFR 的后继者，它在完全解决单挑限注德州扑克游戏中发挥了关键作用，这是迄今为止有待解决的最大的不完美信息游戏 [6]。 CFR+ 的一个主要组成部分是不同的策略更新机制，regret-matching+，它对累积值的定义略有不同：<a href="#">$Q^t(s, a) &#x3D; (Q^{t−1}(s, a) + r^t(s, a))^+$</a>，和<a href="#">$π^{t+1}(s, a) &#x3D; \frac{ Q^t(s, a)}{\sum_b Q^t(s, b)}$</a>。 CFR（或 CFR+）的一种常见形式是<strong>遍历公共树</strong>，而不是经典的扩展形式博弈树。计算反事实值所需的数量，例如每个参与者在他们的策略下达到每个信息状态的概率（称为他们的范围）作为信念(beliefs)被维护。最后，可以使用范围、机会概率和效用（通常更有效 [36])直接评估叶节点。  </p>
<h3 id="2-3-Imperfect-Information-Search-Decomposition-and-Re-Solving"><a href="#2-3-Imperfect-Information-Search-Decomposition-and-Re-Solving" class="headerlink" title="2.3 Imperfect Information Search, Decomposition, and Re-Solving"></a><strong>2.3 Imperfect Information Search, Decomposition, and Re-Solving</strong></h3><p>2.3 不完善信息的搜索、分解和重新求解 纳什均衡和极小极大等解决方案概念是在联合策略（joint policies）上定义的。该政策是在比赛期间确定的。搜索可以被描述为一个过程，它可能会在后续访问相同状态时返回不同的动作分布。在基于搜索的决策中，新的解决方案是在决策时计算的。每个状态可能取决于过去的游戏玩法、时间限制和随机（机会）事件的样本，这引入了重要的微妙之处，例如交叉不同搜索的解决方案兼容性 [84]。 CFR 传统上被用作求解器，通过自我对弈计算整个策略。每次迭代都会遍历整个博弈树，从树中更深的子博弈中的其他值递归计算信息状态的值。假设有人想要针对某个深度 d &gt; 0 的游戏部分制定策略。如果有一个预言机（oracle）来计算深度 d 的值，那么 CFR 的每次迭代都可以运行到深度 d 并查询预言机以返回值。因此，策略在深度 d’ &gt; d 处不可用。通过一组值总结深度 d 以下的策略，这些值可用于重建深度 d 及以上的策略，这是不完美信息游戏分解的基础 [15]。不完美信息博弈中的子博弈是植根于公共状态 s_pub 的博弈。为了使子博弈成为合适的博弈，它与初始信息状态上的置信分布 r 配对，<a href="#">s \in S_i(s_{pub})</a>。这是完美信息博弈中子博弈的严格概括，其中每个公共状态都只有一个信息状态（因此实际上不再是私有的）和一个概率为 1 的信念。 子博弈分解一直是扑克 AI 最新发展的重要组成部分，这些发展可扩展到大型游戏，例如无限注德州扑克 [55、11、12、7]。子博弈分解使局部搜索能够在游戏过程中细化策略，类似于完美信息游戏中的<strong>经典搜索算法</strong>和传统的<strong>贝尔曼式自举</strong>来学习价值函数 [55, 69, 85, 7]。具体来说，由参数 θ 表示的<strong>反事实价值网络 (CVN)</strong> 对价值函数 <a href="#">vθ(β) &#x3D; {v_i(s_i)}<em>{s_i \in S_i(s</em>{pub})}</a>,i∈{1,2} 进行编码，其中 β 包括玩家对信息的信念在 s_pub 公开信息的状态。然后可以使用函数 vθ 代替上面提到的预言机来汇总 s_pub 下子树的值。图 3 显示了使用分解的深度限制 CFR 求解器的示例。 <img src="https://uploader.shimo.im/f/AyVb3paDBq4Ks0k4.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NDk2ODIyMDMsImciOiJXV3F3Q3ZSUjhXdFhRanRUIiwiaWF0IjoxNjQ5NjgxOTAzLCJ1c2VySWQiOjMyNzIxNjY5fQ.U9jNMkb0ZZcEMlHQ2fdRyY3GvN-Msz-GvMc4ftaszUY" alt="img"> <strong>Safe re-solving</strong>安全重解是一种技术，它仅根据先前（近似）解的摘要信息生成子博弈策略：玩家的范围和对手的反事实值。这是通过构建具有特定约束的辅助游戏来完成的。辅助博弈中的子博弈策略的生成方式保留了原始解决方案的可利用性保证，因此它们可以替换子博弈中的原始策略。在 [15] 和 [10, Section 4.1] 中可以找到辅助游戏构建的完整示例。 <strong>Continual re-solving</strong> 连续重求解是经典游戏搜索的一种类似物，适用于不完美信息游戏，它使用安全重求解的重复应用来玩游戏的一集 [55]。它首先解决以游戏开始为根的深度限制博弈树，搜索是解决问题的步骤。随着博弈的进行，对于某个信息状态 si 的每个后续决策，持续的重新求解将通过在 si 重新求解来优化当前策略。与其他搜索方法一样，它使用额外的计算来更彻底地探索玩家遇到的特定情况。 [55] 的连续重求解方法使用了一些扑克的一些属性，这在苏格兰场等其他游戏中是找不到的，因此我们使用了一种更通用的重求解方法，可以应用于更广泛的游戏类别。我们在附录 B.1 中讨论了这个更通用的重新求解变体的细节。 </p>
<h2 id="3-Player-of-Games-PoG"><a href="#3-Player-of-Games-PoG" class="headerlink" title="3 Player of Games (PoG)"></a>3 Player of Games (PoG)</h2><p>我们现在描述我们的主要算法。 由于 PoG 有多个组件，我们首先分别描述它们，然后在本节末尾描述它们是如何组合的。    为清楚起见，附录 B 中提供了许多细节（包括完整的伪代码)。 </p>
<h3 id="3-1-Counterfactual-Value-and-Policy-Networks"><a href="#3-1-Counterfactual-Value-and-Policy-Networks" class="headerlink" title="3.1 Counterfactual Value-and-Policy Networks"></a>3.1 Counterfactual Value-and-Policy Networks</h3><p>PoG 的第一个主要组件是具有参数 θ 的反事实价值与策略网络 (CVPN)，如图 4 所示。这些参数表示函数 fθ(β) &#x3D; (v, p)，其中输出 v 是反事实值（ 每个玩家的每个信息状态一个），以及先前策略 p，在公共状态 s_pub(h) 中，在某些play历史 h 中，对于acting玩家的每个信息状态一个。 在我们的实验中，我们使用标准的前馈网络和残差网络。 架构的细节在 B.3 节中描述。 </p>
<h3 id="3-2-Search-via-Growing-Tree-CFR"><a href="#3-2-Search-via-Growing-Tree-CFR" class="headerlink" title="3.2 Search via Growing-Tree CFR"></a>3.2 Search via Growing-Tree CFR</h3><p>生长树 CFR (GT-CFR) 是一种新算法，它在随时间递增的公共博弈树上运行 CFR 变体。 GT-CFR 以初始树 L0 开始，其中包含 β 及其所有子公共状态。 然后 GT-CFR 的每次迭代 t 由两个阶段组成： 1.<strong>后悔更新阶段</strong>（在3.2.1小节中详细描述）在当前树<a href="#">L^t</a>上运行几个公共树-CFR更新。 2. <strong>扩展阶段</strong>（在 3.2.2 小节中详细描述）通过基于模拟的扩展轨迹添加新的公共状态来扩展 <a href="#">L^t</a>，产生一个新的更大的树<a href="#">L^{t+1}</a>。 <img src="https://uploader.shimo.im/f/cC9Gos8EtlDYDGrW.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NDk2ODIyMDMsImciOiJXV3F3Q3ZSUjhXdFhRanRUIiwiaWF0IjoxNjQ5NjgxOTAzLCJ1c2VySWQiOjMyNzIxNjY5fQ.U9jNMkb0ZZcEMlHQ2fdRyY3GvN-Msz-GvMc4ftaszUY" alt="img">在报告结果时，我们使用符号 PoG(s, c) 来表示运行 GT-CFR 的 PoG 和 s 次总扩展模拟，以及每个后悔更新阶段的 c 次扩展模拟，因此 GT-CFR 迭代的总数为 [s&#x2F;\left<a href="#"> c \right]</a> 。 例如，PoG(8000, 10) 指的是 8000 次扩展模拟，每次后悔更新（800 次 GT-CFR 迭代)进行 10 次扩展。 c 可以是小数，因此例如 0.1 表示每 10 个后悔更新阶段就有一个新节点。 图 5 描绘了整个 GT-CFR 循环。 我们选择了这个特定的符号来直接比较总拓展模拟， s 与 AlphaZero。</p>
<h4 id="3-2-1-The-Regret-Update-Phase-of-Growing-Tree-CFR"><a href="#3-2-1-The-Regret-Update-Phase-of-Growing-Tree-CFR" class="headerlink" title="3.2.1 The Regret Update Phase of Growing-Tree CFR"></a>3.2.1 The Regret Update Phase of Growing-Tree CFR</h4><p>后悔更新阶段使用<strong>同步更新、后悔匹配+和线性加权策略平均</strong> [79] 在 Lt 上运行公共树 CFR 的 1&#x2F;c 更新（迭代）。 在公共树叶节点，对置信状态 β 的 CVPN 进行查询，其值 fθ(β’ ) &#x3D; (v, p) 用作以 β’ 为根的公共子博弈的反事实值的估计。 </p>
<h4 id="3-2-2-The-Expansion-Phase-of-Growing-Tree-CFR"><a href="#3-2-2-The-Expansion-Phase-of-Growing-Tree-CFR" class="headerlink" title="3.2.2 The Expansion Phase of Growing-Tree CFR"></a>3.2.2 The Expansion Phase of Growing-Tree CFR</h4><p>在扩展阶段，新的公共树节点被添加到 L。搜索统计信息，最初为空，在信息状态 si 上维护，在同一搜索内的所有扩展阶段累积。在<strong>每次模拟开始时</strong>，信息状态 si 从 βroot 中的信念中采样。然后，从 si 中采样一个世界状态 wroot，以及相关的历史 hroot。根据混合策略选择动作，该策略考虑了<strong>学习值</strong>（通过 πPUCT(si(h))）以及来自搜索<a href="#">π_{select}(si(h)) &#x3D; 1&#x2F;2 πPUCT(s_i(h)) + 1&#x2F;2 πCFR (s_i(h))</a>的<strong>当前活动策略 <a href="#">（πCFR(s_i(h))）</a></strong>。<strong>第一个策略</strong>由 PUCT [70] 使用反事实值 vi(si, a) 确定，该值由对手在 si 处的到达概率之和的归一化，类似于状态条件动作值，以及从查询中获得的先验策略 p。<strong>第二个</strong>是 CFR 在 si(h) 的当前政策。一旦模拟遇到信息状态<a href="#">s_i \in s_{pub}</a>使得<a href="#">s_{pub} \notin L</a>，模拟结束，将 spub 添加到 L，并且沿着轨迹期间访问的节点更新访问计数。与 AlphaZero [71] 类似，在一次 GT-CFR 迭代中进行 c 次模拟时，虚拟损失 [68] 被添加到 PUCT 统计数据中。 AlphaZero 总是在迭代结束时扩展单个动作&#x2F;节点（具有最高 UCB 分数的动作）。完美信息博弈中的最优策略可以是确定性的，因此扩展单个动作&#x2F;节点就足够了。在不完美信息博弈中，最优策略可能是随机的，对多个动作具有非零概率（这些动作的数量然后被称为支持大小）。游戏中的不确定性水平（就每个公共状态的信息状态而言）与支持大小之间存在直接联系 [66]。换句话说，最优策略可能需要的动作数量是每个公共状态的信息状态数量的函数，我们将这个数字称为最小支持大小 k。因此，PoG 不是扩展单个动作，而是扩展按先验排序的前 k 个动作。然后将与扩展动作对应的所有公共状态添加到树中（连同导致这些公共状态的所有动作)。当 PoG 扩展先前扩展的节点时，由于已经满足最小支持大小要求，因此仅额外扩展单个动作。请注意，对于完美信息游戏，扩展的作用与 AlphaZero 相同，因为支持大小 k &#x3D; 1，因此添加了具有最高先验的单个动作。 </p>
<h4 id="3-2-3-Convergence-Guarantees"><a href="#3-2-3-Convergence-Guarantees" class="headerlink" title="3.2.3 Convergence Guarantees"></a>3.2.3 Convergence Guarantees</h4><p>在 GT-CFR 中生长树<strong>允许搜索有选择地关注对局部决策很重要的空间部分</strong>。 从一棵小树开始，随着时间的推移添加节点在收敛方面没有额外的成本： <strong>Theorem 1</strong> 定理 1. 令 Lt 为时间 t 的公共树。 假设公共状态永远不会从前瞻树中删除，所以 <a href="#">L^t \subseteq L^{t+1}</a>。 对于任何给定的树 L，让 N (L) 是树的内部：GT-CFR 生成策略的所有非叶子、非终端公共状态。 令 F(L) 是 L 的边界，包含非终端叶子，其中 GT-CFR 使用反事实值的噪声估计。 设 U 是任何两种策略在任何信息状态下反事实值的最大差异，A 是任何信息状态下的最大动作数。 那么，玩家 i 在迭代 T 时的遗憾是有界的： 定理 1 中的遗憾 <a href="#">R^{T,full}</a> 是 GT-CFR 迭代与任何可能策略之间的性能差距。 定理 1 表明GT-CFR 返回的平均策略以 1&#x2F;√T 的速率收敛于纳什均衡，但由于价值函数中的 e-error 具有一些最小的可利用性。 当使用 GT-CFR 作为持续重新求解中每个重新求解搜索步骤的游戏求解算法时，也没有额外的成本： <strong>Theorem 2</strong> 定理 2. 假设我们玩了一个使用连续重求解的游戏，有一个初始求解和 D 重求解步骤。每个求解或重新求解步骤使用 e 噪声值函数通过 GT-CFR 的 T 次迭代找到一个近似的纳什均衡，公共状态永远不会从前瞻树中删除，最大内部大小 <a href="#">\sum_{s_{pub} \in N(L^T)} |S_i(S_{pub})|</a>所有前瞻树的边界N ，所有前瞻树的边界大小总和以 F 为界，任何信息集的最大动作数为 A，任何两个策略之间的最大差值为 U 。最终策略的可利用性受<a href="#">(5D + 2) (F + NU \sqrt{A &#x2F; T } )</a> 的限制。 定理 2 类似于 [55] 的定理 1，适用于 GT-CFR 并使用更详细的误差模型，该模型可以更准确地描述在近似均衡策略上训练的价值函数。它表明使用 GT-CFR 持续重新求解具有我们可能希望的一般特性：可利用性随着计算时间的增加和价值函数误差的减少而降低，并且不会随着游戏长度的增加而不受控制地增长。定理的证明在附录 E 中给出。  </p>
<h3 id="3-3-Data-Generation-via-Sound-Self-play"><a href="#3-3-Data-Generation-via-Sound-Self-play" class="headerlink" title="3.3 Data Generation via Sound Self-play"></a>3.3 Data Generation via Sound Self-play</h3><p>POG通过在每个决策点运行搜索，在自我对弈中生成数据片段。每个情节从对应于游戏开始的初始历史 h0 开始，并产生一系列历史 (h0, h1, · · · )。在时间 t，代理运行本地搜索，然后选择一个动作 at，通过在 ht 处采取动作，从环境中获得下一个历史记录 ht+1。<strong>用于训练 CVPN 的数据是通过产生的轨迹和个人搜索收集的。</strong>  在生成用于训练 CVPN 的数据时，重要的是在不同公共状态下执行的搜索与由 θ 表示的 CVPN 以及在先前公共状态沿相同轨迹进行的搜索保持一致（例如，两次搜索不应计算两个不同的最优策略）。这是可靠(sound)搜索的关键要求 [15, 55, 84]，我们将sound搜索算法在自我播放中生成数据的过程称sound自我播放。   为了实现健全的自我对弈，在数据生成期间执行的搜索，在标准安全解析辅助游戏（如第 2.3 节所述）上运行 GT-CFR。辅助博弈包括在初始决策时对手决定进入子博弈的选项，或取由 fθ(β) 返回的替代值。有关此解析过程的详细构造，请参阅第 B.1 节。 </p>
<h3 id="3-4-Training-Process"><a href="#3-4-Training-Process" class="headerlink" title="3.4 Training Process"></a>3.4 Training Process</h3><p>由 <strong>GT-CFR 生成的策略</strong>和由<strong>健全的自我对弈生成的数据</strong>的质量关键取决于 CVPN 返回的值。 因此，为了产生高性能搜索和生成高质量数据，估计准确很重要。 在本小节中，我们将描述用于训练 CVPN 的程序。 图 6 总结了该过程。<img src="https://uploader.shimo.im/f/5GPQGAoNThIIRPwV.png!thumbnail?accessToken=eyJhbGciOiJIUzI1NiIsImtpZCI6ImRlZmF1bHQiLCJ0eXAiOiJKV1QifQ.eyJhdWQiOiJhY2Nlc3NfcmVzb3VyY2UiLCJleHAiOjE2NDk2ODIyMDMsImciOiJXV3F3Q3ZSUjhXdFhRanRUIiwiaWF0IjoxNjQ5NjgxOTAzLCJ1c2VySWQiOjMyNzIxNjY5fQ.U9jNMkb0ZZcEMlHQ2fdRyY3GvN-Msz-GvMc4ftaszUY" alt="img"> </p>
<h4 id="3-4-1-Query-Collection"><a href="#3-4-1-Query-Collection" class="headerlink" title="3.4.1 Query Collection"></a>3.4.1 Query Collection</h4><p>如第 3.2 节和第 3.3 节所述，情节是由每个玩家从当前公共状态搜索 GT-CFR 生成的。 每次搜索都会从公共树叶节点 β（在图 6 中描绘为粉红色节点）产生许多网络查询。 训练过程通过监督学习改进了 CVPN。 使用基于值目标的 Huber 损失 [32] 训练值，并且策略损失是相对于目标策略的交叉熵。 将价值和策略目标添加到用于同时训练 CVPN 的训练数据的滑动窗口数据集中。 CVPN 在训练期间在参与者上异步更新。 </p>
<h4 id="3-4-2-Computing-Training-Targets"><a href="#3-4-2-Computing-Training-Targets" class="headerlink" title="3.4.2 Computing Training Targets"></a>3.4.2 Computing Training Targets</h4><p>策略目标是根据 3.3 中描述的sound-自我游戏产生的情节主线（在自我游戏中达到的历史）在公共状态开始的搜索组合而成的。具体来说，它们是根公共状态内所有信息状态的输出策略，在 GT-CFR 的遗憾更新阶段计算。 价值目标可以通过两种不同的方式获得。首先，游戏的结果被用作沿着由sound自我播放生成的情节主线的状态的 (TD(1)) 值目标。其次，价值目标也是通过引导获得的：从以输入查询为根的子博弈运行 GT-CFR 的实例。原则上，任何求解器都可以使用，因为任何以 β 为根的子博弈都有明确定义的值。因此，这一步通过 2.3 节中描述的分解来充当策略改进算子。具体来说，价值目标是在 GT-CFR 迭代 T 次后，对于发起搜索的公共状态中的所有信息状态的最终反事实值。分配不同值目标的具体方式由 B.5 节中的伪代码描述，并由 B.4 节中描述的超参数确定。 </p>
<h4 id="3-4-3-Recursive-Queries"><a href="#3-4-3-Recursive-Queries" class="headerlink" title="3.4.3 Recursive Queries"></a>3.4.3 Recursive Queries</h4><p>虽然求解器是查询的计算目标，但它也通过运行 GT-CFR 自己生成更多查询。其中一些递归查询也被添加到缓冲区中以备将来解决。因此，在任何给定时间，缓冲区可能包括由主自玩游戏中的搜索生成的查询或主线外求解器生成的查询。为了确保缓冲区不受递归查询的支配，我们将添加新递归查询的概率设置为小于 1（在我们的实验中，该值通常为 0.1 或 0.2；有关确切值，请参阅第 B.4 节）。 </p>
<h4 id="3-4-4-Consistency-of-Training-Process"><a href="#3-4-4-Consistency-of-Training-Process" class="headerlink" title="3.4.4 Consistency of Training Process"></a>3.4.4 Consistency of Training Process</h4><p>3.4.4 培训过程的一致性 </p>
<p>一个自然的问题是，训练过程是否或在什么情况下可以确保收敛到最佳值？答案是肯定的：训练过程逐渐收敛到最优值，随着 T → ∞ 并且具有非常大的（指数）内存。   非正式地，想象一个 oracle 函数 f (β)，它可以简单地记住特定 β 的值和策略，类似于表格值或策略迭代算法，除了连续键。对于以深度为 1 的某个 β 为根的任何子博弈（每个动作都会导致最终状态），可以在求解器的 T 次迭代之后为 β 计算和存储值和策略。然后可以归纳应用：由于 CFR 是确定性的，对于 GT-CFR 第一次迭代的任何子博弈，将生成有限数量的查询。这些查询中的每一个都将使用 GT-CFR 解决。最终，查询将是一个特定的查询，距离终端状态有一步，其值可以精确计算并存储在 f (β) 中。由于此值是在自游戏中或由查询求解器生成的，并且 CFR 是确定性的，因此它将产生另一个具有相同查询的自游戏游戏，除了它会从 f (β) 加载求解的值，并归纳这些值将自下而上传播。由于 CFR 是确定性的且 T 是有限的，因此尽管存在连续值键，但这些确保内存需求不是无限的。   实际上，训练过程的成功将取决于函数逼近（即神经网络架构）的表示能力和训练效率。 </p>
<h3 id="3-5-Bringing-it-all-Together-Full-Algorithm-Overview"><a href="#3-5-Bringing-it-all-Together-Full-Algorithm-Overview" class="headerlink" title="3.5 Bringing it all Together: Full Algorithm Overview"></a>3.5 Bringing it all Together: Full Algorithm Overview</h3><p>PoG 算法通过健全的自我对弈进行学习：每个玩家在面临要做出的决定时，使用配备反事实价值和策略网络的健全生长树 sound growing-tree CFR 搜索来生成策略，然后将其用于采样要采取的行动。这个过程生成两种类型的训练数据：<strong>搜索查询，然后单独解决（有时递归生成新查询）和完整游戏轨迹</strong>。训练过程以不同的方式使用数据：<strong>游戏的结果</strong>和<strong>解决的查询</strong>来训练网络的价值头，以及沿着主线搜索的策略输出来训练网络的策略头。在实践中，self-play 数据的生成和训练是并行发生的：actors 生成 self-play 数据（并解决查询)，而训练者学习新网络并定期更新 actor。   有关算法的完整详细描述，包括超参数值和上述每个过程的具体描述，请参见附录 B。 </p>
<h2 id="4-Evaluation"><a href="#4-Evaluation" class="headerlink" title="4 Evaluation"></a>4 Evaluation</h2><h2 id="5-Relate-Work"><a href="#5-Relate-Work" class="headerlink" title="5 Relate Work"></a>5 Relate Work</h2><p>​		游戏玩家建立在之前工作中开发的几个组件的基础上。在本节中，我们将描述这些过去最相关的作品以及它们与 PoG 的关系。   </p>
<p>​		PoG 结合了许多最初在 AlphaZero 及其前身以及 DeepStack 中提出的元素 [70, 72, 71, 55]。具体来说，PoG 使用来自 AlphaGo 和 DeepStack 的深度神经网络的组合搜索和学习，以及来自 DeepStack 的不完全信息游戏中的博弈论推理和搜索。在不完全信息游戏中使用公共信念状态和分解是无限注德州扑克取得成功的关键组成部分 [15, 10, 55, 11, 13, 12, 7]。与 AlphaZero 的主要区别在于 PoG 中的搜索和自我对弈训练也适用于不完美信息游戏和跨游戏类型的评估。与 DeepStack 的主要区别在于使用明显较少的领域知识：使用自我对弈（而不是特定于扑克的启发式）来生成训练数据和用于游戏所有阶段的单个网络。最密切相关的算法是基于循环信念的学习 (<strong>ReBeL</strong>) [7]。与 PoG 一样，ReBeL 通过自我对弈结合了搜索、学习和博弈论推理。主要区别在于 PoG 基于（安全）连续解析和sound self-play。为了实现 ReBeL 的保证，它的测试时间搜索必须使用与训练相同的算法进行，而 PoG 可以使用第 3.1 节中描述的形式的任何基于信念的价值和策略网络（类似于例如 AlphaZero，它训练使用 800 次模拟，但随后可以在测试时使用更大的模拟限制）。 PoG 在不同游戏类型的许多不同挑战游戏中也得到了实证验证。 </p>
<p> —-what     </p>
<p>​		在寻找不完美信息博弈方面已经有大量工作。在实践中非常成功的一种方法是确定性：在决策时，对一组候选世界状态进行采样，并执行某种形式的搜索 [19, 51]。事实上，PimBot [59, 58] 正是基于这些方法并在苏格兰场取得了最先进的成果。然而，这些方法不能保证随着时间的推移收敛到最佳策略。我们在第 C.4 节中证明了这种在实践中缺乏对常见搜索算法和标准 RL 基准的收敛性。相比之下，PoG 中的搜索基于博弈论推理。其他算法已提议在搜索中添加博弈论推理：Smooth UCT [28] 将 UCT [39] 与虚构游戏相结合，但其收敛特性尚不清楚。在线结果抽样 [48] 衍生出蒙特卡罗 CFR [42] 的 MCTS 变体；然而，OOS 只能保证在单一信息状态（局部一致性）下接近近似平衡，并且尚未在大型游戏中进行评估。 PoG 使用的 GT-CFR 使用基于分解的声音搜索，并且是全局一致的 [15, 84]。   </p>
<p>​		已经为<strong>两人零和游戏</strong>提出了许多 RL 算法：虚构的自我对弈 [29, 30]，策略空间响应预言机 (PSRO) [43, 56, 54]，双神经 CFR [46]，Deep CFR 和 DREAM [8, 76]，后悔策略梯度 [75]，可利用性下降 [50]，神经复制器动力学 (NeuRD) [31]，优势后悔匹配演员评论家 [26]，摩擦FoReL [60]、MAIO [57]、扩展式双甲骨文 (XDO) [53] 和神经自动课程 (NAC) [21]。这些方法使用于计算（近似）纳什均衡的经典算法适应具有采样经验和一般函数近似的 RL 设置。因此，它们结合了博弈论推理和学习。其中一些方法已显示出可扩展性：Pipeline PSRO 击败了 Stratego Barrage 中最好的公开可用代理； Deep CFR、DREAM 和 ARMAC 在大型扑克游戏中显示出可喜的结果。结合人类数据，AlphaStar 能够使用博弈论推理来创建大师级的实时策略策略 [83]。然而，他们都不能在测试时使用搜索来完善他们的策略。   </p>
<p>​		最后，有些作品将搜索、学习和&#x2F;或博弈论推理的某种组合应用于特定领域。神经网络已经通过 Q-learning 训练来学习玩苏格兰场 [20]；然而，由此产生的政策的整体发挥实力并没有直接与任何其他已知的苏格兰场经纪人进行比较。在扑克中，Supremus 对 DeepStack 提出了许多改进，并证明它们在与人类专家比赛时产生了很大的不同 [85]。另一项工作使用了一种受 DeepStack 启发的方法应用于 The Resistance [69]。在合作环境中，一些作品利用基于信念的学习（和搜索）使用公共子博弈分解 [22, 45, 73]，应用于 Hanabi [4]。搜索和强化学习相结合，产生了一个与最先进的机器人（WBridg e5) 和人类 [49]。 最近，学习和博弈论推理也被结合起来，在协作游戏 Overcooked [77] 中，在没有人类数据的情况下，产生了与人类一起玩得很好的代理。 值得注意的是（无新闻）外交游戏。 博弈论推理与最佳响应策略迭代中的学习相结合 [2]。 博弈论搜索和监督学习被用于 [25] 在两人变体上达到人类水平的表现。 最近，这三者结合在 DORA [3] 中，它学会了在没有人类数据的情况下玩外交，并且在两人变体上也达到了人类水平的表现。 PoG 与这些作品的主要区别在于它们专注于特定的游戏并利用特定领域的知识来获得强大的性能。 </p>
<h2 id="6-Conclusion"><a href="#6-Conclusion" class="headerlink" title="6 Conclusion"></a>6 Conclusion</h2><p>​		在本文中，我们描述了游戏玩家 **(PoG) 一种结合了搜索、学习和博弈论推理的统一算法。 PoG 由两个主要部分组成：一种新颖的生长树反事实后悔最小化（GT-CFR），以及通过自我博弈学习反事实价值和策略网络的健全自我博弈。**最值得注意的是，PoG 是一种适用于完美和不完美信息博弈的健全算法：随着计算资源的增加，PoG 可以保证产生更好的极小极大优化策略的近似。这一发现也在 Leduc 扑克（简易德州玩法)中得到了经验验证，与任何不使用搜索的纯强化学习算法不同，额外的搜索会导致测试时间近似的细化。   </p>
<p>​		PoG 是此类中第一个使用最少领域知识在挑战领域展示强大性能的合理算法。在国际象棋和围棋的完美信息游戏中，PoG 的性能达到人类专家或专业人士的水平，但在给定相同资源的情况下，其性能明显弱于此类游戏的专用算法，如 AlphaZero。在不完全信息游戏无限注德州扑克中，PoG 击败了 Slumbot，这是最好的公开可用的扑克代理，并且表明不会被使用特定于扑克的启发式的本地最佳响应代理利用。在苏格兰场，PoG 击败了最先进的代理人。   </p>
<p>​		PoG 有一些局限性值得在未来的工作中研究。首先，可以删除扑克中投注抽象的使用，以支持大型动作空间的一般动作减少策略。其次，PoG 目前需要枚举每个公共状态的信息状态，这在某些游戏中可能会非常昂贵；这可以通过一个生成模型来近似，该模型对世界状态进行采样并对采样的子集进行操作。最后，大量的计算资源用于在挑战领域获得强大的发挥；一个有趣的问题是，是否可以使用较少的计算资源来实现这种级别的游戏。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/12/06/Tools/Tools_sum/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/06/Tools/Tools_sum/" class="post-title-link" itemprop="url">Tools 常用工具解密</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-06 15:47:57" itemprop="dateCreated datePublished" datetime="2021-12-06T15:47:57+00:00">2021-12-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OS/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/OS/Linux/shell/" itemprop="url" rel="index"><span itemprop="name">shell</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Contents<br>[toc]</p>
<h3 id="beyond-compare-过期解决方法1"><a href="#beyond-compare-过期解决方法1" class="headerlink" title="beyond compare 过期解决方法1"></a>beyond compare 过期解决方法1</h3><p>1.window+R<strong>打开管理</strong></p>
<p>2.输入regedit后回车，则就会打开<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%B3%A8%E5%86%8C%E8%A1%A8&spm=1001.2101.3001.7020">注册表</a>编辑器</p>
<p>3.里面有一个<strong>cacaheId然后删掉，果断的删掉</strong></p>
<p>​    计算机\HKEY_CURRENT_USER\Software\ScooterSoftware\BeyondCompare\</p>
<p>4.找到他的老巢（安装路径）然后删除<strong>BCUnrar.dll</strong></p>
<p><strong>5.好了打开就可以用了</strong></p>
<hr>
<h3 id="beyond-Compare-30天过期后的处理办法2"><a href="#beyond-Compare-30天过期后的处理办法2" class="headerlink" title="beyond Compare 30天过期后的处理办法2"></a><a target="_blank" rel="noopener" href="https://www.cnblogs.com/musings/p/10812545.html">beyond Compare 30天过期后的处理办法2</a></h3><p>打开Beyond Compare 4，提示已经超出30天试用期限制，解决方法：</p>
<ol>
<li>修改C:\Program Files\Beyond Compare 4\BCUnrar.dll,这个文件重命名或者直接删除，则会新增30天试用期，再次打开提示还有28天试用期</li>
<li>一劳永逸，修改注册表</li>
</ol>
<p>　　　　1)在搜索栏中输入 regedit ，打开注册表</p>
<p>　　　　2) 删除项目：计算机\HKEY_CURRENT_USER\Software\ScooterSoftware\Beyond Compare 4\CacheId</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/yangruini_love/article/details/92840222">Ref:</a></p>
<h3 id="LINUX-BCompare-对比"><a href="#LINUX-BCompare-对比" class="headerlink" title="LINUX BCompare 对比"></a>LINUX BCompare 对比</h3><p>wget <a target="_blank" rel="noopener" href="https://www.scootersoftware.com/bcompare-4.4.2.26348_amd64.deb">https://www.scootersoftware.com/bcompare-4.4.2.26348_amd64.deb</a></p>
<p>过期处理：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /home/xxx/.config/bcompare/registry.dat</span><br></pre></td></tr></table></figure>

<h3 id="GitHub-Mirror"><a href="#GitHub-Mirror" class="headerlink" title="GitHub Mirror"></a>GitHub Mirror</h3><p><a target="_blank" rel="noopener" href="https://github.com.cnpmjs.org/">https://github.com.cnpmjs.org</a></p>
<p><a target="_blank" rel="noopener" href="https://hub.fastgit.org/">https://hub.fastgit.org</a></p>
<h3 id="压缩文件-穷举忘记的密码"><a href="#压缩文件-穷举忘记的密码" class="headerlink" title="压缩文件 穷举忘记的密码"></a>压缩文件 穷举忘记的密码</h3><h3 id="使用cRARk破解RAR密码"><a href="#使用cRARk破解RAR密码" class="headerlink" title="使用cRARk破解RAR密码"></a>使用cRARk破解RAR密码</h3><p>cRARk是为数不多的最快的RAR密码恢复工具之一。更重要的是，它完全免费使用。除了作为RAR密码恢复功能之外，cRARk还可用于不完整的密码和单词列表。它可以用字符补充单词表，这只是冰山一角。</p>
<p>由于其有趣的PCL语言，它使用一种强大的机制来恢复丢失或遗忘的RAR档案密码，并检查wordlist文件中的密码。尽管如此，这种方法在此列表中是最难的，并且不能在此完整地涵盖。</p>
<p>要使用此应用程序破解RAR密码，您需要……</p>
<p>1.首先，访问<a target="_blank" rel="noopener" href="http://www.crark.net下载windows或linux版本/">http://www.crark.net下载Windows或Linux版本</a></p>
<p>2.对于Windows用户，根据您的框架有两个版本：OpenCL和CUDA。</p>
<p>3.由于应用程序是命令行工具，您需要打开CMD窗口（Windows）或终端（Linux）并运行一些命令。</p>
<p>4.运行命令后，该工具会在几秒到几分钟内找到您的密码，具体取决于密码的长度。但是，如果找不到您的密码，它会通知您。</p>
<h4 id="设置Def文件"><a href="#设置Def文件" class="headerlink" title="设置Def文件"></a>设置Def文件</h4><p><img src="/2021/12/06/Tools/Tools_sum/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYzODExNA==,size_16,color_FFFFFF,t_70-16521481806613.png" alt="在这里插入图片描述"></p>
<p><img src="/2021/12/06/Tools/Tools_sum/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYzODExNA==,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p>
<h4 id="基本用法："><a href="#基本用法：" class="headerlink" title="基本用法："></a>基本用法：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cRARk -p<span class="string">&quot;password.def&quot;</span> rarpath</span><br></pre></td></tr></table></figure>

<p>rarpath 表示要破解的文件位置，password.def是修改好的password definition filename，注意-p后面没有空格，由于win命令行的特性，需要把password.def用引号括起来，不然password和def会分开识别产生错误。password.def的生成方法见上文GUI使用中。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cRARk.exe -l1 -g10 -p<span class="string">&quot;password.def&quot;</span> -n0 rarpath</span><br><span class="line"></span><br><span class="line"><span class="comment"># -l表示最小密码位数，-g表示最大密码位数，后面都没有空格。-n表示使用的显卡，我电脑是0，也可能是1，2，3等等。</span></span><br></pre></td></tr></table></figure>

<p>但是随着密码位数增长，密码排列组合的结果呈指数式增长，8位密码在我电脑上就需要4个小时了。再加上rar等压缩软件的密码不限于字母数字符号，还可能是汉字或者其他符号等等，因此这个软件比较鸡肋，不是所有的都能破解。<br>这个软件比较适合于位数比较少的，确定符号在字母数字符号之内的密码的破解，个人电脑使用最好不要超过10位（其实字母数字符号加一起的10位用现在最好的个人电脑恐怕也要算几个星期）。</p>
<h3 id="HashCode"><a href="#HashCode" class="headerlink" title="HashCode"></a>HashCode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">md5sum</span></span><br><span class="line"><span class="built_in">sha1sum</span> // 即可</span><br><span class="line"><span class="built_in">sha256sum</span></span><br><span class="line"><span class="built_in">sha512sum</span></span><br><span class="line">shasum</span><br><span class="line"><span class="built_in">sha224sum</span></span><br><span class="line"><span class="built_in">sha384sum</span></span><br></pre></td></tr></table></figure>

<h3 id="Capture"><a href="#Capture" class="headerlink" title="Capture"></a>Capture</h3><pre><code>- 录屏软件（免费）
</code></pre>
<h3 id="Typora（摒弃）"><a href="#Typora（摒弃）" class="headerlink" title="Typora（摒弃）"></a>Typora（摒弃）</h3><p>破解<br>del C:\Users\Simon\AppData\Roaming\Typora<br>    - typora.log<br>    - profile.data</p>
<p>方法2：<br>    regedit</p>
<h3 id="MarkText-免费Md编辑器，-Good"><a href="#MarkText-免费Md编辑器，-Good" class="headerlink" title="MarkText(免费Md编辑器， Good)"></a>MarkText(免费Md编辑器， Good)</h3><h3 id="Android虚拟机（夜神模拟器）与【Vmware冲突】"><a href="#Android虚拟机（夜神模拟器）与【Vmware冲突】" class="headerlink" title="Android虚拟机（夜神模拟器）与【Vmware冲突】"></a>Android虚拟机（夜神模拟器）与【Vmware冲突】</h3><ul>
<li><p>夜神模拟器需要关闭hyper-v(虚拟机平台)</p>
</li>
<li><p>Vmware则需要开启</p>
</li>
<li><p>Win_cmd：optionalFeatures–&gt;开启关闭此功能（需要重启）</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/12/03/AI/DL/Infrence/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/12/03/AI/DL/Infrence/" class="post-title-link" itemprop="url">Inference</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-03 21:00:00" itemprop="dateCreated datePublished" datetime="2021-12-03T21:00:00+00:00">2021-12-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:37" itemprop="dateModified" datetime="2025-08-06T08:16:37+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[toc]</p>
<h1 id="深度学习模型加速与压缩常用方法-总体介绍"><a href="#深度学习模型加速与压缩常用方法-总体介绍" class="headerlink" title="深度学习模型加速与压缩常用方法-总体介绍"></a>深度学习模型加速与压缩常用方法-总体介绍</h1><p>深度学习模型加速方向大致分为两种：</p>
<p>一、轻量化网络结构设计</p>
<ul>
<li>分组卷积（group convolution，典型的如ShuffleNet和MobileNet等）</li>
<li>分解卷积（inception结构等）</li>
<li>Bottleneck结构（通过1x1卷积进行降维和升维等操作）</li>
<li>神经网络结构搜索（Neural Architecture Search，简称NAS）</li>
<li>硬件适配</li>
</ul>
<p>二、模型压缩相关技术</p>
<ul>
<li>网络剪枝</li>
<li>知识蒸馏</li>
<li>参数量化</li>
</ul>
<p><img src="/2021/12/03/AI/DL/Infrence/v2-904e822bbfb2b1ad4945394d3a491bc1_720w.jpg" alt="img"></p>
<p>按照压缩过程对网络结构的破坏程度， 我们将模型压缩技术分为“前端压缩”与“后端缩”两部分。</p>
<p>所谓“前端压缩”，是指不改变原网络结构的压缩技术，主要包括知识蒸馏、紧凑的模型结构设计以及滤波器层面的剪枝等；而“后端压缩”则包括低秩近似、未加限制的剪枝、参数量化以及二值网络等，其目标在于尽可能地减少模型大小，因而会对原始网络结构造成极大程度的改造。</p>
<p>其中，由于“前端压缩”未改变原有的网络结构，仅仅只是在原模型的基础上减少了网络的层数或者滤波器的个数，其最终的模型可完美适配现有的深度学习库，如caffe等。相比之下，“后端压缩”为了追求极致的压缩比，不得不对原有的网络结构进行改造，如对参数进行量化表示等，而这样的改造往往是不可逆的。同时，为了获得理想的压缩效果，必须开发相配套的运行库，甚至是专门的硬件设备，其最终的结果往往是一种压缩技术对应于一套运行库，从而带来了巨大的维护成本。</p>
<p>ref: 	<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/150212141">https://zhuanlan.zhihu.com/p/150212141</a></p>
<h1 id="深度学习模型加速与压缩常用方法–剪枝"><a href="#深度学习模型加速与压缩常用方法–剪枝" class="headerlink" title="深度学习模型加速与压缩常用方法–剪枝"></a>深度学习模型加速与压缩常用方法–剪枝</h1><p>剪枝，模型量化，压缩，加速</p>
<h2 id="网络剪枝"><a href="#网络剪枝" class="headerlink" title="网络剪枝"></a>网络剪枝</h2><ul>
<li>unstructured pruning（非结构化剪枝）</li>
<li>structured pruning（<strong>结构化剪枝</strong>）</li>
</ul>
<p>unstructured pruning是指对于individual weights进行prune；structured pruning是指对于filter&#x2F;channel&#x2F;layer的prune。其中非结构化修剪方法（直接修剪权重）的一个缺点是所得到的权重矩阵是稀疏的，<strong>如果没有专用硬件&#x2F;库，则不能达到压缩和加速的效果</strong>。相反，结构化修剪方法在通道或层的层次上进行修剪。由于原始卷积结构仍然保留，因此<strong>不需要专用的硬件&#x2F;库来实现</strong>。在结构化修剪方法中，通道修剪是最受欢迎的，因为它在最细粒度的水平上运行，同时仍然适合传统的深度学习框架。</p>
<p>修建算法三阶段流程</p>
<img src="/2021/12/03/AI/DL/Infrence/image-20220407145114395.png" alt="image-20220407145114395" style="zoom:50%;">



<p><strong>训练</strong>：训练大型的过度参数化的模型，得到最佳网络性能，以此为基准；<strong>修剪</strong>：根据特定标准修剪训练的大模型，即重新调整网络结构中的通道或层数等，来得到一个精简的网络结构；<strong>微调</strong>：微调修剪的模型以重新获得丢失的性能，这里一般做法是将修剪后的大网络中的保留的（视为重要的）参数用来初始化修剪后的网络，即继承大网络学习到的重要参数，再在训练集上finetune几轮。</p>
<p>然而，在《Rethinking the value of network pruning》（ICLR 2019）这篇论文里，作者做出了几个与常见观点相矛盾的结论，通过测试目前六种最先进的剪枝算法得出以下结论：</p>
<ol>
<li>训练过度参数化的模型不是获得有效的最终模型所必需的; </li>
<li>学习的大型模型的“重要”权重不一定有助于修剪后的小型模型；</li>
<li>修剪的本质是网络体系结构本身，而不是一组继承的“重要”权重，来主导最终模型的效率优势，这表明一些修剪算法可以被视为表征网络架构探索。</li>
</ol>
<p>作者选择了三个数据集和三个标准的网络结构（数据集：CIFAR-10， CIFAR-100，ImageNet，网络结构：VGG， ResNet，DenseNet），并验证了6个网络裁剪方法，接下来分别介绍这几种当下流行的剪枝算法：</p>
<ul>
<li>L1-norm based Channel Pruning (Li et al., 2017)</li>
<li>ThiNet (Luo et al., 2017)</li>
<li>Regression based Feature Reconstruction (He et al., 2017b)</li>
<li>Network Slimming (Liu et al., 2017)</li>
<li>Sparse Structure Selection (Huang &amp; Wang, 2018) </li>
<li>Non-structured Weight Pruning (Han et al., 2015)</li>
</ul>
<p>作者：Alex Tian<br>链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/157562088">https://zhuanlan.zhihu.com/p/157562088</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h3 id="（一）L1-norm-based-Channel-Pruning"><a href="#（一）L1-norm-based-Channel-Pruning" class="headerlink" title="（一）L1-norm based Channel Pruning"></a>（一）L1-norm based Channel Pruning</h3><p>本方法出自论文《Pruning Filters For Efficient ConvNets》，论文提出了对卷积层（对Filters进行剪枝，以及Feature maps）进行剪枝操作，移除对于CNN精度影响很小的卷积核，然后进行retrain，不会造成稀疏连接（稀疏矩阵操作需要特殊的库等来处理）。</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-5801686de6f3e3de839d0785b6435cdd_720w.jpg" alt="img" style="zoom:50%;">

<p>卷积核剪枝原则：（即应该去掉哪些卷积核）</p>
<ol>
<li>对每个卷积核 $ Fi,j $  ,计算它的权重绝对值（L1正则)之和 $Sj&#x3D;\sum_{l&#x3D;1}^{ni}\sum_{}^{}{\left| Kl \right|}$ ;</li>
<li>根据 $$ Sj $$ 排序；</li>
<li>将m个权重绝对值之和最小的卷积核以及对应的feature maps剪掉。下一个卷积层中与剪掉的feature maps相关的核也要移除；</li>
<li>一个对于第i层和第i+1层的新的权重矩阵被创建，并且剩下的权重参数被复制到新模型中；</li>
</ol>
<p>相比于基于其他的标准来衡量卷积核的重要性（比如基于激活值的feature map剪枝），l1-norm是一个很好的选择卷积核的方法，认为如果一个filter的绝对值和比较小，说明该filter并不重要。之后的步骤就是retrain，论文指出对剪枝后的网络结构从头训练要比对重新训练剪枝后的网络（利用了未剪枝之前的权重）的结果差。</p>
<h3 id="（二）ThiNet"><a href="#（二）ThiNet" class="headerlink" title="（二）ThiNet"></a>（二）ThiNet</h3><p>本方法出自论文《ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression》，主要贡献：1）基于贪心策略与最小化重建误差，设计了ThiNet剪枝方法，并且是规整的通道剪枝方法；2）将网络剪枝视作优化问题，并利用下一层的输入输出关系获取统计信息，以决定当前层的剪枝；3）在ImageNet数据集上，获得了良好的剪枝效果（主要是Resnet50与VGG-16），并在其他任务上取得了良好的迁移效果。</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-894b664cd7aea311d502ed340bd9cef0_b.jpg" alt="img" style="zoom:50%;">

<p>ThiNet的剪枝步骤如上图所示，对于给定的预训练模型以及固定的剪枝率，逐层裁剪冗余的滤波器（3D filters或2D kernels），总体包括通道选择、通道剪枝与fine-tuning三个阶段：</p>
<ol>
<li>Channel Selection：利用第i+1 层的统计信息指导第i 层的剪枝，即从第i+1 层的输入特征中提取最优子集，用于估计第i+1的输出特征，而其余输入特征以及相对应的3D filters均可被删除；</li>
<li>Pruning：根据第一步通道选择的结果，剪除第i 层对应的3D filters以及第i+1 层的2D kernels，从而获得结构紧凑、纤瘦的模型（Thin-Net）；</li>
<li>Fine-tuning：完成第i 层的剪枝之后，在训练集上微调1~2个epochs，以恢复因剪枝丢失的精度。在完成整个模型的剪枝之后，通常需要微调更多的epochs；</li>
<li>回到第一步，完成第i+1 层的剪枝；</li>
</ol>
<p>通道选择原则：</p>
<p>寻找通道最优子集用于估计输出特征的Channel Selection，可表示为如下优化问题：</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-61d85ecc9d443f5e93c130a0a476918f_b.jpg" alt="img" style="zoom:33%;">

<p>等价而言，定义T 为需要移除的通道子集，其满足 <img src="/2021/12/03/AI/DL/Infrence/%7D.svg+xml" alt="[公式]"> and <img src="/2021/12/03/AI/DL/Infrence/oslash.svg+xml" alt="[公式]"> ，则最优化问题可重新写成：</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-16f711b33e4b6b241b29f2520d20bbd9_b.jpg" alt="img" style="zoom:33%;">

<p>上式亦可理解为，所构建的集合T , 其所包含元素的L2 norm最小。由于集合T 通常比集合S 小，因此求解上述等价问题，具有更高的实现效率。下图是采用贪心策略(Greedy Method)求解集合T 的描述，每次迭代往T 中所添加的元素，需要确保目标函数最小。从而确保完成样本集遍历、并达成目标剪枝率之后，能够删除最不重要的输入特征，最终完成Channel Selection。</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-df68fd36a28b739dda501a5b56a689c7_b.jpg" alt="img" style="zoom:50%;">

<p>以上为应用贪心策略选取需要删除的通道集合。</p>
<p>（三）Regression based Feature Reconstruction</p>
<p>本方法出自论文《Channel Pruning for Accelerating Very Deep Neural Networks》，本文采用了通道剪枝方法，同上一种方法思路一致，考虑减少输入feature maps中的若干channels信息，然后通过调整weights使整体output feature map的信息不会丢失太多。</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-02374da3b40bef79428306923216fffe_b.jpg" alt="img" style="zoom:50%;">

<p>如图所示，目标就是减少B 的feature map, 那么B中的channel被剪掉，会同时使得上游对应的卷积核个数减少，以及下游对应卷积核的通道数减少。关键在于通道选择，如何选择通道而不影响信息的传递很重要。为了进行channel selection ，作者引入了β作为mask ，目标变为 ：</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-ee7858f78ed4a81f7346afeb6df485d9_b.jpg" alt="img" style="zoom:33%;">

<p>β是一个列向量，如果βi&#x3D;0 则代表对应的通道被剪除，c ‘代表经过选择后的通道个数 c’&lt;&#x3D;c，因此作者分两步来优化，首先固定W，优化β ；然后固定β，优化W。而且为了增加β的稀疏度，将β的L1正则项加入优化函数；另外则增加了W的范数为1的强约束以让我们得到的W解不过于简单，原优化函数变为：</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-ef1fd51b3b3ea595f47f3461c1888d10_b.jpg" alt="img" style="zoom: 50%;">

<p>进而我们再将它变为两个分步骤的子优化问题：</p>
<p>(1).求参数β的子优化问题</p>
<p>首先，我们可固定W不变，寻求参数β的组合，即决定输入feature map的哪些input channels可以舍弃。这显然是个NP-hard的组合优化问题，作者使用了经典的启发式LASSO方式来迭代寻找最优的β值，如下公式所示:</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-ecd4502ac7f3c4b78e05065980a1b508_b.jpg" alt="img" style="zoom:50%;">

<p>(2).求参数W的子优化问题</p>
<p>然后我们再固定上面得到的β不变，再求解最优的W参数值，本质上就是求解如下的MSE问题:</p>
<img src="/2021/12/03/AI/DL/Infrence/v2-12d7ee9daae85f9a9c99b4953972f1e5_b.jpg" alt="img" style="zoom: 25%;">

<p>以上所介绍的方法为单个conv层pruning所使用的方法。而在将此方法应用于整个CNN model时，方法也类似，只需要sequentially将此它应用于每个层即可（当然某些特殊的多分支层需要稍稍特殊对待）。</p>
<h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><h2 id="量化（float-int）"><a href="#量化（float-int）" class="headerlink" title="量化（float-&gt;int）"></a>量化（float-&gt;int）</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/349678095">zhihu-量化</a></p>
<p>1、量化映射方法，也就是将float-32映射到Int数据类型，每个间隔是相等的还是不相等的，这里就是均匀量化(uniform quantization)和非均匀量化(non-uniform quantization)，也可以叫作线性量化和非线性量化</p>
<p>2、关于映射到整数是数值范围是有正负数，还是都是正数，这里就是对称量化(有正负数)和非对称量化(全是正数)，非对称量化就有zero-point，zero-point的主要作用是用于做padding。</p>
<p>3、原精度即浮float-32，量化到什么样的数据类型，这里就有float和int；到底要选择量化后的是多少个bit，这里就有1-bit(二值网络)、2-bit(三值网络)、3-bit、4-bit、5-bit、6-bit、7-bit、8-bit，这几种量化后的数值类型是整型。</p>
<p>4、是固定所有网络都是相同的bit-width，还是不同的，这里就有混合精度量化(Mixed precision)</p>
<p>5、是从一个已经训练好的模型再进行量化，还是有fine tune的过程或者直接是从头开始训练一个量化的模型，这里就有Post-training quantization(后量化，即将已经训练完的模型参数进行量化)、quantization-aware training(量化感知训练，即在从头开始训练中加入量化)和quantization-aware fine tune(在fine tune训练中加入量化)。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/09/10/Sub_Language/DL_Train/Tensorflow/Language-tf-slim/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/10/Sub_Language/DL_Train/Tensorflow/Language-tf-slim/" class="post-title-link" itemprop="url">Tensorflow Slim</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-10 20:05:51" itemprop="dateCreated datePublished" datetime="2021-09-10T20:05:51+00:00">2021-09-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h3 id="1-变量的定义"><a href="#1-变量的定义" class="headerlink" title="1.变量的定义"></a>1.变量的定义</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#模型变量</span></span><br><span class="line">weights = slim.model_variable(<span class="string">&#x27;weights&#x27;</span>,</span><br><span class="line">                              shape=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span> , <span class="number">3</span>],</span><br><span class="line">                              initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>),</span><br><span class="line">                              regularizer=slim.l2_regularizer(<span class="number">0.05</span>),</span><br><span class="line">                              device=<span class="string">&#x27;/GPU:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 局部变量</span></span><br><span class="line">my_var = slim.variable(<span class="string">&#x27;my_var&#x27;</span>,</span><br><span class="line">                       shape=[<span class="number">10</span>, <span class="number">1</span>],</span><br><span class="line">                       initializer=tf.zeros_initializer())</span><br><span class="line"></span><br><span class="line"><span class="comment">#get_variables 返回所有的变量 </span></span><br><span class="line">regular_variables_and_model_variables = slim.get_variables()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="built_in">print</span>(sess.run(weights))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(my_var))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(regular_variables_and_model_variables))</span><br><span class="line"></span><br><span class="line"><span class="comment">#而模型变量会再save的时候保存下来。 诸如global_step之类的就是局部变量。</span></span><br><span class="line"><span class="comment">#slim中可以写明变量存放的设备，正则和初始化规则。还有获取变量的函数也需要注意一下，get_variables是返回所有的变量。</span></span><br></pre></td></tr></table></figure>

<h3 id="2-卷积的操作"><a href="#2-卷积的操作" class="headerlink" title="2.卷积的操作"></a>2.卷积的操作</h3><h4 id="2-1-传统的卷积"><a href="#2-1-传统的卷积" class="headerlink" title="2.1 传统的卷积"></a>2.1 传统的卷积</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#传统的卷积</span></span><br><span class="line"><span class="built_in">input</span> = ...</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;conv1_1&#x27;</span>) <span class="keyword">as</span> scope:</span><br><span class="line">  kernel = tf.Variable(tf.truncated_normal([<span class="number">3</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">128</span>], dtype=tf.float32,</span><br><span class="line">                                           stddev=<span class="number">1e-1</span>), name=<span class="string">&#x27;weights&#x27;</span>)</span><br><span class="line">  conv = tf.nn.conv2d(<span class="built_in">input</span>, kernel, [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">  biases = tf.Variable(tf.constant(<span class="number">0.0</span>, shape=[<span class="number">128</span>], dtype=tf.float32),</span><br><span class="line">                       trainable=<span class="literal">True</span>, name=<span class="string">&#x27;biases&#x27;</span>)</span><br><span class="line">  bias = tf.nn.bias_add(conv, biases)</span><br><span class="line">  conv1 = tf.nn.relu(bias, name=scope)</span><br></pre></td></tr></table></figure>

<h4 id="2-2-slim的卷积"><a href="#2-2-slim的卷积" class="headerlink" title="2.2 slim的卷积"></a>2.2 slim的卷积</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"><span class="comment">#slim实现卷积</span></span><br><span class="line">net = slim.conv2d(<span class="built_in">input</span>, <span class="number">128</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1_1&#x27;</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    底层代码</span></span><br><span class="line"><span class="string">    @staticmethod</span></span><br><span class="line"><span class="string">    def conv2d(features, weight):</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;Produces a convolutional layer that filters an image subregion</span></span><br><span class="line"><span class="string">        :param features: The layer input.</span></span><br><span class="line"><span class="string">        :param weight: The size of the layer filter.</span></span><br><span class="line"><span class="string">        :return: Returns a convolutional layer.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        return tf.nn.conv2d(features, weight, strides=[1, 1, 1, 1], padding=&#x27;SAME&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span>     </span><br></pre></td></tr></table></figure>

<h4 id="2-3-slim定义相同层"><a href="#2-3-slim定义相同层" class="headerlink" title="2.3 slim定义相同层"></a>2.3 slim定义相同层</h4><ul>
<li>repeat操作  减少代码量</li>
<li>stack是处理卷积核或者输出不一样的情况</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">repeat操作  减少代码量</span></span><br><span class="line"><span class="string">stack是处理卷积核或者输出不一样的情况</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">假设定义三个相同的卷积层：</span></span><br><span class="line"><span class="string">input = slim.conv2d(input, 256, [3, 3], scope=&#x27;conv3_1&#x27;)</span></span><br><span class="line"><span class="string">input = slim.conv2d(input, 256, [3, 3], scope=&#x27;conv3_2&#x27;)</span></span><br><span class="line"><span class="string">input = slim.conv2d(input, 256, [3, 3], scope=&#x27;conv3_3&#x27;)</span></span><br><span class="line"><span class="string">input = slim.max_pool2d(input, [2, 2], scope=&#x27;pool2&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#在slim中的repeat操作可以减少代码量：</span></span><br><span class="line">net = slim.repeat(<span class="built_in">input</span>, <span class="number">3</span>, slim.conv2d, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line">net = slim.max_pool2d(<span class="built_in">input</span>, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#2.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    假设定义三层FC：</span></span><br><span class="line"><span class="string">        # Verbose way:</span></span><br><span class="line"><span class="string">        x = slim.fully_connected(x, 32, scope=&#x27;fc/fc_1&#x27;)</span></span><br><span class="line"><span class="string">        x = slim.fully_connected(x, 64, scope=&#x27;fc/fc_2&#x27;)</span></span><br><span class="line"><span class="string">        x = slim.fully_connected(x, 128, scope=&#x27;fc/fc_3&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#使用stack操作：</span></span><br><span class="line">slim.stack(x, slim.fully_connected, [<span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>], scope=<span class="string">&#x27;fc&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#3.</span></span><br><span class="line"><span class="comment"># 普通方法:</span></span><br><span class="line">x = slim.conv2d(x, <span class="number">32</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;core/core_1&#x27;</span>)</span><br><span class="line">x = slim.conv2d(x, <span class="number">32</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">&#x27;core/core_2&#x27;</span>)</span><br><span class="line">x = slim.conv2d(x, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;core/core_3&#x27;</span>)</span><br><span class="line">x = slim.conv2d(x, <span class="number">64</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">&#x27;core/core_4&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 简便方法:</span></span><br><span class="line">slim.stack(x, slim.conv2d, [(<span class="number">32</span>, [<span class="number">3</span>, <span class="number">3</span>]), (<span class="number">32</span>, [<span class="number">1</span>, <span class="number">1</span>]), (<span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>]), (<span class="number">64</span>, [<span class="number">1</span>, <span class="number">1</span>])], scope=<span class="string">&#x27;core&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="2-4-slim中的argscope"><a href="#2-4-slim中的argscope" class="headerlink" title="2.4 slim中的argscope"></a>2.4 slim中的argscope</h4><p>​    如果你的网络有大量相同的参数，如下：</p>
<ul>
<li>arg_scope操作   用scope提取相同的特征 </li>
<li>嵌套的使用  和多层的定义</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      argscope 定义参数，不重复的定义</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = slim.conv2d(inputs, <span class="number">64</span>, [<span class="number">11</span>, <span class="number">11</span>], <span class="number">4</span>, padding=<span class="string">&#x27;SAME&#x27;</span>,</span><br><span class="line">                  weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">                  weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>), scope=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">net = slim.conv2d(net, <span class="number">128</span>, [<span class="number">11</span>, <span class="number">11</span>], padding=<span class="string">&#x27;VALID&#x27;</span>,</span><br><span class="line">                  weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">                  weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>), scope=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">11</span>, <span class="number">11</span>], padding=<span class="string">&#x27;SAME&#x27;</span>,</span><br><span class="line">                  weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">                  weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>), scope=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#arg_scope操作   用scope提取相同的特征</span></span><br><span class="line"><span class="keyword">with</span> slim.arg_scope([slim.conv2d], padding=<span class="string">&#x27;SAME&#x27;</span>,</span><br><span class="line">                      weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>)</span><br><span class="line">                      weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>)):</span><br><span class="line">    net = slim.conv2d(inputs, <span class="number">64</span>, [<span class="number">11</span>, <span class="number">11</span>], scope=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">    net = slim.conv2d(net, <span class="number">128</span>, [<span class="number">11</span>, <span class="number">11</span>], padding=<span class="string">&#x27;VALID&#x27;</span>, scope=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">    net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">11</span>, <span class="number">11</span>], scope=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#嵌套的使用  和多层的定义</span></span><br><span class="line"><span class="keyword">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected],</span><br><span class="line">                      activation_fn=tf.nn.relu,</span><br><span class="line">                      weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">                      weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>)):</span><br><span class="line">  <span class="keyword">with</span> slim.arg_scope([slim.conv2d], stride=<span class="number">1</span>, padding=<span class="string">&#x27;SAME&#x27;</span>):</span><br><span class="line">    net = slim.conv2d(inputs, <span class="number">64</span>, [<span class="number">11</span>, <span class="number">11</span>], <span class="number">4</span>, padding=<span class="string">&#x27;VALID&#x27;</span>, scope=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">    net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">5</span>, <span class="number">5</span>],</span><br><span class="line">                      weights_initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.03</span>),</span><br><span class="line">                      scope=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">    net = slim.fully_connected(net, <span class="number">1000</span>, activation_fn=<span class="literal">None</span>, scope=<span class="string">&#x27;fc&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义VGG网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vgg16</span>(<span class="params">inputs</span>):</span><br><span class="line">  <span class="keyword">with</span> slim.arg_scope([slim.conv2d, slim.fully_connected],</span><br><span class="line">                      activation_fn=tf.nn.relu,</span><br><span class="line">                      weights_initializer=tf.truncated_normal_initializer(<span class="number">0.0</span>, <span class="number">0.01</span>),</span><br><span class="line">                      weights_regularizer=slim.l2_regularizer(<span class="number">0.0005</span>)):</span><br><span class="line">    net = slim.repeat(inputs, <span class="number">2</span>, slim.conv2d, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv1&#x27;</span>) <span class="comment"># 定义两个conv  卷积核为3*2</span></span><br><span class="line">    net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool1&#x27;</span>)  <span class="comment">#定义池化层  2*2</span></span><br><span class="line">    net = slim.repeat(net, <span class="number">2</span>, slim.conv2d, <span class="number">128</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">    net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool2&#x27;</span>)</span><br><span class="line">    net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line">    net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool3&#x27;</span>)</span><br><span class="line">    net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">512</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv4&#x27;</span>)</span><br><span class="line">    net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool4&#x27;</span>)</span><br><span class="line">    net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">512</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">&#x27;conv5&#x27;</span>)</span><br><span class="line">    net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">&#x27;pool5&#x27;</span>)</span><br><span class="line">    net = slim.fully_connected(net, <span class="number">4096</span>, scope=<span class="string">&#x27;fc6&#x27;</span>)  <span class="comment">#全连接网络</span></span><br><span class="line">    net = slim.dropout(net, <span class="number">0.5</span>, scope=<span class="string">&#x27;dropout6&#x27;</span>)</span><br><span class="line">    net = slim.fully_connected(net, <span class="number">4096</span>, scope=<span class="string">&#x27;fc7&#x27;</span>)</span><br><span class="line">    net = slim.dropout(net, <span class="number">0.5</span>, scope=<span class="string">&#x27;dropout7&#x27;</span>)  <span class="comment">#dropout</span></span><br><span class="line">    net = slim.fully_connected(net, <span class="number">1000</span>, activation_fn=<span class="literal">None</span>, scope=<span class="string">&#x27;fc8&#x27;</span>)</span><br><span class="line">  <span class="keyword">return</span> net</span><br></pre></td></tr></table></figure>

<h3 id="3-slim封装网络"><a href="#3-slim封装网络" class="headerlink" title="3. slim封装网络"></a>3. slim封装网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> alexnet</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> inception</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> overfeat</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> resnet_utils</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> resnet_v1</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> resnet_v2</span><br><span class="line"><span class="keyword">from</span> tensorflow.contrib.slim.python.slim.nets <span class="keyword">import</span> vgg</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.util.all_util <span class="keyword">import</span> make_all</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">vgg = tf.contrib.slim.nets.vgg</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the images and labels.</span></span><br><span class="line">images, labels = ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the model.</span></span><br><span class="line">predictions, _ = vgg.vgg_16(images)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the loss functions and get the total loss.</span></span><br><span class="line">loss = slim.losses.softmax_cross_entropy(predictions, labels)</span><br></pre></td></tr></table></figure>

<h3 id="4-loss"><a href="#4-loss" class="headerlink" title="4. loss"></a>4. loss</h3><p>损失函数定义了我们想要最小化的数量。 对于分类问题，这通常是跨分类的真实分布和预测概率分布之间的交叉熵。 对于回归问题，这通常是预测值和真值之间的平方和差异。</p>
<p>某些模型（如多任务学习模型）需要同时使用多个损失函数。 换句话说，最终被最小化的损失函数是各种其他损失函数的总和。 例如，考虑预测图像中的场景类型以及每个像素的相机深度的模型。 这个模型的损失函数将是分类损失和深度预测损失的总和。</p>
<p>TF-Slim提供了一个易于使用的机制，通过损失模块定义和跟踪损失功能。 考虑一下我们想要训练VGG网络的简单情况：</p>
<ul>
<li>classification_loss      &#x3D; slim.losses.softmax_cross_entropy(scene_predictions, scene_labels)</li>
</ul>
<ul>
<li><p>sum_of_squares_loss   &#x3D; slim.losses.sum_of_squares(depth_predictions, depth_labels)</p>
</li>
<li><p>regularization_loss        &#x3D;  slim.losses.get_regularization_losses()</p>
</li>
</ul>
<p>slim.losses.get_total_loss(add_regularization_losses&#x3D;False)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">vgg = tf.contrib.slim.nets.vgg</span><br><span class="line"></span><br><span class="line"># Load the images and labels.</span><br><span class="line">images, labels = ...</span><br><span class="line"></span><br><span class="line"># Create the model.</span><br><span class="line">predictions, _ = vgg.vgg_16(images)</span><br><span class="line"></span><br><span class="line"># Define the loss functions and get the total loss.</span><br><span class="line">loss = slim.losses.softmax_cross_entropy(predictions, labels)</span><br><span class="line">在这个例子中，我们首先创建模型（使用TF-Slim的VGG实现），并添加标准分类损失。 现在，让我们假设有一个多任务模型，产生多个输出的情况：</span><br><span class="line"></span><br><span class="line"># Load the images and labels.</span><br><span class="line">images, scene_labels, depth_labels = ...</span><br><span class="line"></span><br><span class="line"># Create the model.</span><br><span class="line">scene_predictions, depth_predictions = CreateMultiTaskModel(images)</span><br><span class="line"></span><br><span class="line"># Define the loss functions and get the total loss.</span><br><span class="line">classification_loss = slim.losses.softmax_cross_entropy(scene_predictions, scene_labels)</span><br><span class="line">sum_of_squares_loss = slim.losses.sum_of_squares(depth_predictions, depth_labels)</span><br><span class="line"></span><br><span class="line"># The following two lines have the same effect:</span><br><span class="line">total_loss = classification_loss + sum_of_squares_loss</span><br><span class="line">total_loss = slim.losses.get_total_loss(add_regularization_losses=False)</span><br><span class="line"></span><br><span class="line">在这个例子中，我们有两个损失，我们通过调用slim.losses.softmax_cross_entropy和slim.losses.sum_of_squares来添加。 我们可以通过将它们相加（total_loss）或调用slim.losses.get_total_loss（）来获得全部损失。 这是如何工作的？ 当您通过TF-Slim创建loss function时，TF-Slim将损失添加到损失函数中特殊的TensorFlow集合中。 这使您可以手动管理全部损失，或允许TF-Slim为您管理它们。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果你想让TF-Slim管理你的损失，通过一个自定义的损失函数呢？ loss_ops.py也有一个功能，把这个损失添加到TF-Slims集合中。 例如：</span><br><span class="line"></span><br><span class="line"># Load the images and labels.</span><br><span class="line">images, scene_labels, depth_labels, pose_labels = ...</span><br><span class="line"></span><br><span class="line"># Create the model.</span><br><span class="line">scene_predictions, depth_predictions, pose_predictions = CreateMultiTaskModel(images)</span><br><span class="line"></span><br><span class="line"># Define the loss functions and get the total loss.</span><br><span class="line">classification_loss = slim.losses.softmax_cross_entropy(scene_predictions, scene_labels)</span><br><span class="line">sum_of_squares_loss = slim.losses.sum_of_squares(depth_predictions, depth_labels)</span><br><span class="line">pose_loss = MyCustomLossFunction(pose_predictions, pose_labels)</span><br><span class="line">slim.losses.add_loss(pose_loss) # Letting TF-Slim know about the additional loss.</span><br><span class="line"></span><br><span class="line"># The following two ways to compute the total loss are equivalent: 【regularization_loss】</span><br><span class="line">regularization_loss = tf.add_n(slim.losses.get_regularization_losses())</span><br><span class="line">total_loss1 = classification_loss + sum_of_squares_loss + pose_loss + regularization_loss</span><br><span class="line"></span><br><span class="line"># (Regularization Loss is included in the total loss by default).</span><br><span class="line">total_loss2 = slim.losses.get_total_loss()</span><br><span class="line">在这个例子中，我们可以再次手动产生总损失函数，或者让TF-Slim知道额外的损失，让TF-Slim处理损失。</span><br></pre></td></tr></table></figure>

<h3 id="5-保存读取模型"><a href="#5-保存读取模型" class="headerlink" title="5. 保存读取模型"></a>5. 保存读取模型</h3><p>通过以下功能我们可以载入模型的部分变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># Create some variables.</span><br><span class="line">v1 = slim.variable(name=&quot;v1&quot;, ...)</span><br><span class="line">v2 = slim.variable(name=&quot;nested/v2&quot;, ...)</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"># Get list of variables to restore (which contains only &#x27;v2&#x27;).</span><br><span class="line">variables_to_restore = slim.get_variables_by_name(&quot;v2&quot;)</span><br><span class="line"></span><br><span class="line"># Create the saver which will be used to restore the variables.</span><br><span class="line">restorer = tf.train.Saver(variables_to_restore)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  # Restore variables from disk.</span><br><span class="line">  restorer.restore(sess, &quot;/tmp/model.ckpt&quot;)</span><br><span class="line">  print(&quot;Model restored.&quot;)</span><br><span class="line">除了这种部分变量加载的方法外，我们甚至还能加载到不同名字的变量中。</span><br><span class="line"></span><br><span class="line">假设我们定义的网络变量是conv1/weights，而从VGG加载的变量名为vgg16/conv1/weights，正常load肯定会报错（找不到变量名），但是可以这样：</span><br><span class="line"></span><br><span class="line">def name_in_checkpoint(var):</span><br><span class="line">  return &#x27;vgg16/&#x27; + var.op.name</span><br><span class="line"></span><br><span class="line">variables_to_restore = slim.get_model_variables()</span><br><span class="line">variables_to_restore = &#123;name_in_checkpoint(var):var for var in variables_to_restore&#125;</span><br><span class="line">restorer = tf.train.Saver(variables_to_restore)</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">  # Restore variables from disk.</span><br><span class="line">  restorer.restore(sess, &quot;/tmp/model.ckpt&quot;)</span><br></pre></td></tr></table></figure>

<p>通过这种方式我们可以加载不同变量名的变量！！</p>
<p>————————————————<br>版权声明：本文为CSDN博主「醉小义」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_30638831/article/details/81389533">https://blog.csdn.net/qq_30638831/article/details/81389533</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/09/09/Sub_Language/DL_Train/Tensorflow/Language-tf2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/09/Sub_Language/DL_Train/Tensorflow/Language-tf2/" class="post-title-link" itemprop="url">Tensorflow 2.x</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-09 21:05:51" itemprop="dateCreated datePublished" datetime="2021-09-09T21:05:51+00:00">2021-09-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="tensorflow2"><a href="#tensorflow2" class="headerlink" title="tensorflow2"></a>tensorflow2</h2><table>
<thead>
<tr>
<th></th>
<th>tf</th>
<th>keras</th>
<th>python</th>
<th>依赖</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>TF2.0</td>
<td>Keras2.3.1</td>
<td>3.6,3.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF2.1</td>
<td>Keras2.3.1</td>
<td>3.6,3.7</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF2.2</td>
<td>Keras2.3.1</td>
<td>3.6-3.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF2.3</td>
<td>Keras2.4.3</td>
<td>3.6-3.8</td>
<td>h5py&#x3D;2.10.0<br>hdf5&#x3D;1.10.4<br>numpy&#x3D;1.19.2</td>
</tr>
<tr>
<td></td>
<td>TF2.4</td>
<td>Keras2.4.3</td>
<td>3.6-3.8</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF2.5</td>
<td></td>
<td>3.6-3.9</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF2.6</td>
<td>Keras2.6</td>
<td>3.6-3.9</td>
<td></td>
</tr>
</tbody></table>
<h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p>CUDA11.1＋cuDNN8.0.5＋tensorflow-gpu2.4.1</p>
<p>CUDA11.1＋cuDNN8.0.5＋tensorflow-gpu2.4.1</p>
<p>CUDA11.1＋cuDNN8.0.5＋tensorflow-gpu2.4.1</p>
<h2 id="load"><a href="#load" class="headerlink" title="load"></a>load</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.saved_model.load(</span><br><span class="line">    export_dir, tags=<span class="literal">None</span>, options=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><em>Loading Keras models</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Model(...)</span><br><span class="line">tf.saved_model.save(model, path)</span><br><span class="line">imported = tf.saved_model.load(path)</span><br><span class="line">outputs = imported(inputs)</span><br></pre></td></tr></table></figure>

<h2 id="tf-gather-tf-gather-nd"><a href="#tf-gather-tf-gather-nd" class="headerlink" title="tf.gather  tf.gather_nd"></a>tf.gather  tf.gather_nd</h2><p>tf.gather和tf.gather_nd都是从tensor中取出index标注的部分，不同之处在于，gather一般只使用一个index来标注，而gather_nd可以使用多个index。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow.compat.v1 <span class="keyword">as</span> tf</span><br><span class="line">tf.disable_eager_execution()</span><br><span class="line"><span class="comment"># import tensorflow as tf</span></span><br><span class="line">params = tf.constant([[<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>], [<span class="string">&quot;c&quot;</span>, <span class="string">&quot;d&quot;</span>], [<span class="string">&quot;e&quot;</span>, <span class="string">&quot;f&quot;</span>]])</span><br><span class="line">gather = tf.constant([<span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">gather_nd = tf.constant([[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(tf.gather(params, gather).<span class="built_in">eval</span>())</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(tf.gather_nd(params, gather_nd).<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[[b<span class="string">&#x27;a&#x27;</span> b<span class="string">&#x27;b&#x27;</span>]</span><br><span class="line"> [b<span class="string">&#x27;e&#x27;</span> b<span class="string">&#x27;f&#x27;</span>]]</span><br><span class="line"></span><br><span class="line">[b<span class="string">&#x27;a&#x27;</span> b<span class="string">&#x27;d&#x27;</span>]</span><br></pre></td></tr></table></figure>

<h2 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Dense()</span><br><span class="line">tf.keras.layers.LSTM()</span><br></pre></td></tr></table></figure>

<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/layers/LSTM">https://www.tensorflow.org/versions/r2.3/api_docs/python/tf/keras/layers/LSTM</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.random.normal([<span class="number">32</span>, <span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>)</span><br><span class="line">output = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(output.shape)  <span class="comment">#(32,4)</span></span><br><span class="line"></span><br><span class="line">lstm = tf.keras.layers.LSTM(<span class="number">4</span>, return_sequences=<span class="literal">True</span>, return_state=<span class="literal">True</span>)</span><br><span class="line">whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)</span><br><span class="line"><span class="built_in">print</span>(whole_seq_output.shape)<span class="comment">#(32,10,4)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_memory_state.shape) <span class="comment">#(32,4)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_carry_state.shape) <span class="comment">#(32,4)</span></span><br></pre></td></tr></table></figure>

<h1 id="BUGS"><a href="#BUGS" class="headerlink" title="BUGS"></a>BUGS</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解决报错“ImportError: cannot import name &#x27;get_config&#x27; from &#x27;tensorflow.python.eager.context&#x27;”</span><br><span class="line">安装的tensorflow版本和keras版本可能不合适的时候，会出现报错</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">module <span class="string">&#x27;tensorflow_core.compat.v2&#x27;</span> has no attribute <span class="string">&#x27;__internal__&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line">--&gt;</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array.</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install -c anaconda h5py</span><br></pre></td></tr></table></figure>

<h3 id="LSTM-Dense报错"><a href="#LSTM-Dense报错" class="headerlink" title="LSTM+Dense报错"></a>LSTM+Dense报错</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NotImplementedError: Cannot convert a symbolic Tensor </span><br><span class="line">(lstm/strided_slice:0) to a numpy array. This error </span><br><span class="line">may indicate that you&#x27;re trying to pass a Tensor to a NumPy call, </span><br><span class="line">which is not supported</span><br></pre></td></tr></table></figure>

<p>解决：安装 numpy&#x3D;&#x3D;1.19.2，太高的numpy版本不行</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/09/09/Sub_Language/DL_Train/Tensorflow/Language-tf/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/09/Sub_Language/DL_Train/Tensorflow/Language-tf/" class="post-title-link" itemprop="url">Tensorflow 1.x</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-09 20:05:51" itemprop="dateCreated datePublished" datetime="2021-09-09T20:05:51+00:00">2021-09-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h2><table>
<thead>
<tr>
<th></th>
<th>TF</th>
<th>Keras</th>
<th>python</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>TF1.12</td>
<td>Keras2.2.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF1.13</td>
<td>Keras2.2.4</td>
<td></td>
</tr>
<tr>
<td></td>
<td>TF1.14</td>
<td>Keras2.2.5</td>
<td>3.6,3.7</td>
</tr>
<tr>
<td></td>
<td>TF1.15</td>
<td>Keras2.2.5</td>
<td></td>
</tr>
</tbody></table>
<p>resnet模型搭建</p>
<ul>
<li><input checked disabled type="checkbox"> eager keras resnet (转pb比较麻烦)</li>
<li><input checked disabled type="checkbox"> tf slim resnet（DDZ）</li>
<li><input disabled type="checkbox"> tf pure resnet (DDZ v2)</li>
<li><input disabled type="checkbox"> keras</li>
</ul>
<h2 id="TF-cmd-flags"><a href="#TF-cmd-flags" class="headerlink" title="TF cmd flags"></a>TF cmd flags</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">TF_CPP_MIN_LOG_LEVEL 取值 0 ： 0也是默认值，输出所有信息</span><br><span class="line">TF_CPP_MIN_LOG_LEVEL 取值 1 ： 屏蔽通知信息</span><br><span class="line">TF_CPP_MIN_LOG_LEVEL 取值 2 ： 屏蔽通知信息和警告信息</span><br><span class="line">TF_CPP_MIN_LOG_LEVEL 取值 3 ： 屏蔽通知信息、警告信息和报错信息</span><br></pre></td></tr></table></figure>

<h2 id="BN训练技巧"><a href="#BN训练技巧" class="headerlink" title="BN训练技巧"></a>BN训练技巧</h2><h3 id="demo1"><a href="#demo1" class="headerlink" title="demo1:"></a>demo1:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope)</span><br><span class="line">updates_op = tf.group(*update_ops)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([updates_op]):</span><br><span class="line">    losses = tf.get_collection(<span class="string">&#x27;losses&#x27;</span>, scope) <span class="comment"># 4</span></span><br><span class="line">    <span class="comment"># Calculate the total loss for the current tower.</span></span><br><span class="line">    total_loss = tf.add_n(losses, name=<span class="string">&#x27;total_loss&#x27;</span>) <span class="comment"># 5</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    train_op = opt.apply_gradients(mean_grads, global_step=global_step)</span><br></pre></td></tr></table></figure>

<h3 id="demo2"><a href="#demo2" class="headerlink" title="demo2:"></a>demo2:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.training <span class="keyword">import</span> moving_averages</span><br><span class="line"><span class="comment"># 为每个通道计算均值、标准差</span></span><br><span class="line">mean, variance = tf.nn.moments(x, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], name=<span class="string">&#x27;moments&#x27;</span>)</span><br><span class="line"><span class="comment"># 新建或建立测试阶段使用的batch均值、标准差</span></span><br><span class="line">moving_mean = tf.get_variable(<span class="string">&#x27;moving_mean&#x27;</span>, </span><br><span class="line">                              params_shape, tf.float32, </span><br><span class="line">                              initializer=tf.constant_initializer(<span class="number">0.0</span>, tf.float32), </span><br><span class="line">                              trainable=<span class="literal">False</span>)</span><br><span class="line">moving_variance = tf.get_variable(<span class="string">&#x27;moving_variance&#x27;</span>, </span><br><span class="line">                         params_shape, </span><br><span class="line">                         tf.float32,initializer=tf.constant_initializer(<span class="number">1.0</span>, tf.float32),</span><br><span class="line">                         trainable=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 添加batch均值和标准差的更新操作(滑动平均)</span></span><br><span class="line"><span class="comment"># moving_mean = moving_mean * decay + mean * (1 - decay)</span></span><br><span class="line"><span class="comment"># moving_variance = moving_variance * decay + variance * (1 - decay)</span></span><br><span class="line"><span class="variable language_">self</span>._extra_train_ops.append(moving_averages.assign_moving_average(</span><br><span class="line">                    moving_mean, mean, <span class="number">0.9</span>))</span><br><span class="line"><span class="variable language_">self</span>._extra_train_ops.append(moving_averages.assign_moving_average(</span><br><span class="line">                    moving_variance, variance, <span class="number">0.9</span>))</span><br></pre></td></tr></table></figure>

<h2 id="EMA"><a href="#EMA" class="headerlink" title="EMA"></a>EMA</h2><p>shadow_variable &#x3D; decay * shadow_variable + (1 - decay) * variable</p>
<h3 id="demo1-1"><a href="#demo1-1" class="headerlink" title="demo1:"></a>demo1:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py</span></span><br><span class="line"><span class="comment"># Track the moving averages of all trainable variables.</span></span><br><span class="line">variable_averages = tf.train.ExponentialMovingAverage(train_config.MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line">variables_averages_op = variable_averages.apply(tf.trainable_variables())</span><br><span class="line">train_op = tf.group(apply_gradient_op, variables_averages_op)</span><br></pre></td></tr></table></figure>

<h3 id="demo2-1"><a href="#demo2-1" class="headerlink" title="demo2:"></a>demo2:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置exponential moving average</span></span><br><span class="line">variable_averages = tf.train.ExponentialMovingAverage(<span class="number">0.999</span>, <span class="variable language_">self</span>.global_step, name=<span class="string">&#x27;avg&#x27;</span>)</span><br><span class="line">losses = tf.get_collection(<span class="string">&#x27;cost&#x27;</span>)</span><br><span class="line">variables_averages_op = variable_averages.apply(losses)</span><br><span class="line"><span class="comment"># 将所有的更新捆绑到一个训练操作中</span></span><br><span class="line">train_op = tf.group(apply_op, variables_averages_op)</span><br></pre></td></tr></table></figure>

<h2 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">next_img, next_label = iterator.get_next()</span><br><span class="line">image_splits = tf.split(next_img, num_gpus)</span><br><span class="line">label_splits = tf.split(next_label, num_gpus)</span><br><span class="line">tower_grads = []</span><br><span class="line">tower_loss = []</span><br><span class="line">counter = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> <span class="variable language_">self</span>.gpu_id:</span><br><span class="line">    <span class="keyword">with</span> tf.device(<span class="string">&#x27;/gpu:%s&#x27;</span> % d):</span><br><span class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">&#x27;%s_%s&#x27;</span> % (<span class="string">&#x27;tower&#x27;</span>, d)):</span><br><span class="line">            cross_entropy = build_train_model(image_splits[counter], label_splits[counter], for_training=<span class="literal">True</span>)</span><br><span class="line">            counter += <span class="number">1</span></span><br><span class="line">            <span class="keyword">with</span> tf.variable_scope(<span class="string">&quot;loss&quot;</span>):</span><br><span class="line">                grads = opt.compute_gradients(cross_entropy)</span><br><span class="line">                tower_grads.append(grads)</span><br><span class="line">                tower_loss.append(cross_entropy)</span><br><span class="line">                tf.get_variable_scope().reuse_variables()</span><br><span class="line"></span><br><span class="line">mean_loss = tf.stack(axis=<span class="number">0</span>, values=tower_loss)</span><br><span class="line">mean_loss = tf.reduce_mean(mean_loss, <span class="number">0</span>)</span><br><span class="line">mean_grads = util.average_gradients(tower_grads)</span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    train_op = opt.apply_gradients(mean_grads, global_step=global_step)</span><br></pre></td></tr></table></figure>

<h2 id="APIs"><a href="#APIs" class="headerlink" title="APIs"></a>APIs</h2><h3 id="accuracy"><a href="#accuracy" class="headerlink" title="accuracy"></a>accuracy</h3><blockquote>
<p> accuracy, update_op &#x3D; tf.metrics.accuracy(labels&#x3D;x, predictions&#x3D;y) </p>
</blockquote>
<p>tf.metrics.accuracy**返回**两个值，**accuracy**为到上一个batch为止的准确度，**update_op**为更新本批次后的准确度。</p>
<h3 id="BN"><a href="#BN" class="headerlink" title="BN:"></a>BN:</h3><p>tf.layers.BatchNormalization</p>
<p>tf.layers.batch_normalization</p>
<p>tf.keras.layers.BatchNormalization</p>
<p>tf.nn.batch_normalization</p>
<p>① tf.nn.moments  这个函数的输出就是BN需要的mean和variance。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tensorflow中实现BN算法的各种函数</span><br><span class="line"></span><br><span class="line">tf.nn.batch_normalization()是一个低级的操作函数,调用者需要自己处理张量的平均值和方差</span><br><span class="line"></span><br><span class="line">tf.nn.fused_batch_norm是另一个低级的操作函数,和前者十分相似,不同之处在于它针对4维输入张量进行了优化,这是卷积神经网络中常见的情况,而前者tf.nn.batch_normalization则接受任何等级大于1的张量</span><br><span class="line"></span><br><span class="line">tf.layers.batch_normalization是对先前操作的高级封装,最大的不同在于它负责创建和管理运行张量的均值和方差,并尽可可能地快速融合计算,通常,这个函数应该是你的默认选择</span><br><span class="line"></span><br><span class="line">tf.contrib.layers.batch_norm是batch_norm的早期实现,其升级的核心api版本为(tf.layers.batch_normalization),不推荐使用它,因为它可能会在未来的版本中丢失.</span><br><span class="line"></span><br><span class="line">tf.nn.batch_norm_with_global_normalization是另一个被弃用的操作,现在这个函数会委托给tf.nn.batch_normalization执行,在未来这个函数会被放弃</span><br><span class="line"></span><br><span class="line">keras.layers.BatchNormalization是BN算法的keras实现,这个函数在后端会调用tensorflow的tf.nn.batch_normalization函数</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">————————————————</span><br><span class="line">版权声明：本文为CSDN博主「wanghua609」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</span><br><span class="line">原文链接：https://blog.csdn.net/weixin_38145317/article/details/96132250</span><br></pre></td></tr></table></figure>

<p>ref:</p>
<p>tensorflow 中batch normalize 的使用(Slim.BN) <a target="_blank" rel="noopener" href="https://blog.csdn.net/jiruiyang/article/details/77202674">https://blog.csdn.net/jiruiyang/article/details/77202674</a></p>
<p>BN 详解和使用Tensorflow实现（参数理解）<a target="_blank" rel="noopener" href="https://www.cnblogs.com/WSX1994/p/10949079.html">https://www.cnblogs.com/WSX1994/p/10949079.html</a></p>
<h1 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h1><h3 id="BN-1"><a href="#BN-1" class="headerlink" title="BN"></a>BN</h3><p>is_training</p>
<p>tf.GraphKeys.UPDATE_OPS</p>
<p>EMA</p>
<h3 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h3><p>l2_loss</p>
<p>tower_loss</p>
<h3 id="grad"><a href="#grad" class="headerlink" title="grad"></a>grad</h3><p>average_grad</p>
<h2 id="ISSUEs"><a href="#ISSUEs" class="headerlink" title="ISSUEs"></a>ISSUEs</h2><h3 id="1、tf-gradients-VS-tf-train-Optimizer-computer-gradients"><a href="#1、tf-gradients-VS-tf-train-Optimizer-computer-gradients" class="headerlink" title="1、tf.gradients VS tf.train.Optimizer.computer_gradients"></a>1、tf.gradients VS tf.train.Optimizer.computer_gradients</h3><p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/gradients"><code>tf.gradients</code></a>不允许您计算雅可比矩阵，它会汇总每个输出的梯度（类似于实际雅可比矩阵的每列的总和）。事实上，在TensorFlow中没有“好”的计算Jacobians的方法（基本上你必须每个输出调用<code>tf.gradients</code>一次，<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/issues/675">see this issue</a>）。</p>
<p>关于<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#compute_gradients"><code>tf.train.Optimizer.compute_gradients</code></a>，是的，其结果基本相同，但是自动处理一些细节并以稍微方便的输出格式。如果你看看<a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py">the implementation</a>，你会发现它的核心是对<code>tf.gradients</code>（在这种情况下是别名<code>gradients.gradients</code>）的调用，但是对于优化器实现来说已经实现了周围的逻辑非常有用。另外，将它作为一种方法允许子类中的可扩展行为，以实现某种优化策略（不太可能在步骤<code>compute_gradients</code>步骤中）或辅助目的（如跟踪或调试）。</p>
<h3 id="2、梯度裁剪"><a href="#2、梯度裁剪" class="headerlink" title="2、梯度裁剪"></a>2、梯度裁剪</h3><blockquote>
<p>tf.clip_by_global_norm(gradients, max_gradient_norm)</p>
<ol>
<li>t_list 表示梯度张量</li>
<li>clip_norm是截取的比率</li>
</ol>
<p>global_norm &#x3D; sqrt(sum(l2norm(t)**2 for t in t_list)) </p>
<p>t_list[i] &#x3D; t_list[i] * clip_norm &#x2F; max(global_norm, clip_norm)</p>
<p>也就是分为两步：</p>
<ol>
<li>计算所有梯度的平方和global_norm</li>
<li>如果梯度平方和 global_norm 超过我们指定的clip_norm，那么就对梯度进行缩放；否则就按照原本的计算结果，这个应该很好理解。</li>
</ol>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://bigquant.com/community/t/topic/121493">https://bigquant.com/community/t/topic/121493</a></p>
<h1 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#from tensorflow.keras.layers import Layer</span></span><br><span class="line"><span class="comment">#换成</span></span><br><span class="line">from tensorflow.python.keras.layers import Layer</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/06/12/Sub_Language/DL_Train/Pytorch/models/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/12/Sub_Language/DL_Train/Pytorch/models/" class="post-title-link" itemprop="url">Pytorch pth to onnx</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-06-12 15:30:32" itemprop="dateCreated datePublished" datetime="2021-06-12T15:30:32+00:00">2021-06-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/pytorch/onnx/" itemprop="url" rel="index"><span itemprop="name">onnx</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="ONNX环境配置"><a href="#ONNX环境配置" class="headerlink" title="ONNX环境配置"></a>ONNX环境配置</h1><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># CPU版本</span><br><span class="line">pip install onnxruntime</span><br><span class="line"># GPU版本</span><br><span class="line">pip install onnxruntime-gpu</span><br></pre></td></tr></table></figure>

<h2 id="OnnxRun"><a href="#OnnxRun" class="headerlink" title="OnnxRun"></a>OnnxRun</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> onnxruntime</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>onnxruntime.get_device()</span><br><span class="line"><span class="string">&#x27;GPU&#x27;</span>  <span class="comment">#表示GPU可用</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>onnxruntime.get_available_providers()</span><br><span class="line">[<span class="string">&#x27;TensorrtExecutionProvider&#x27;</span>, <span class="string">&#x27;CUDAExecutionProvider&#x27;</span>, <span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p>如果GPU不可用，可以在 <code>~/.bashrc</code> 中添加下面两行内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/local/cuda/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64:<span class="variable">$LD_LIBRARY_PATH</span></span><br></pre></td></tr></table></figure>

<p>Demo:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxruntime</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">device_name = <span class="string">&#x27;cuda:0&#x27;</span> <span class="comment"># or &#x27;cpu&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(onnxruntime.get_available)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> device_name == <span class="string">&#x27;cpu&#x27;</span>:</span><br><span class="line">    providers = [<span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br><span class="line"><span class="keyword">elif</span> device_name == <span class="string">&#x27;cuda:0&#x27;</span>:</span><br><span class="line">    providers = [<span class="string">&#x27;CUDAExecutionProvider&#x27;</span>, <span class="string">&#x27;CPUExecutionProvider&#x27;</span>]</span><br><span class="line"><span class="comment"># Create inference session</span></span><br><span class="line">onnx_model = onnxruntime.InferenceSession(<span class="string">&#x27;slowfast.onnx&#x27;</span>, providers=providers)</span><br><span class="line"><span class="comment"># Create the input（这里的输入对应slowfast的输入）</span></span><br><span class="line">data = np.random.rand(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">256</span>, <span class="number">256</span>).astype(np.float32)</span><br><span class="line"><span class="comment"># Inference</span></span><br><span class="line">onnx_input = &#123;onnx_model.get_inputs()[<span class="number">0</span>].name: data&#125;</span><br><span class="line">outputs = onnx_model.run(<span class="literal">None</span>, onnx_input)</span><br></pre></td></tr></table></figure>

<h1 id="pth导出onnx"><a href="#pth导出onnx" class="headerlink" title="pth导出onnx"></a>pth导出onnx</h1><h2 id="多输入模型"><a href="#多输入模型" class="headerlink" title="多输入模型"></a>多输入模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dummy_input0 = torch.LongTensor(Batch_size, seg_length).to(torch.device(<span class="string">&quot;cuda&quot;</span>))</span><br><span class="line">dummy_input1 = torch.LongTensor(Batch_size, seg_length).to(torch.device(<span class="string">&quot;cuda&quot;</span>))</span><br><span class="line">dummy_input2 = torch.LongTensor(Batch_size, seg_length).to(torch.device(<span class="string">&quot;cuda&quot;</span>))</span><br><span class="line">torch.onnx.export(model. (dummy_input0, dummy_input1, dummy_input2), filepath)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38003892/article/details/89543299">https://blog.csdn.net/qq_38003892/article/details/89543299</a></p>
<h2 id="固定batchsize导出ONNX模型"><a href="#固定batchsize导出ONNX模型" class="headerlink" title="固定batchsize导出ONNX模型"></a>固定batchsize导出ONNX模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.onnx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> nets.yolo4_tiny <span class="keyword">import</span> YoloBody</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pth_to_onnx</span>(<span class="params">checkpoint, onnx_path, input_names=[<span class="string">&#x27;input&#x27;</span>], </span></span><br><span class="line"><span class="params">                output_names=[<span class="string">&#x27;output&#x27;</span>], device=<span class="string">&#x27;cpu&#x27;</span></span>):</span><br><span class="line">    <span class="comment">#加载模型</span></span><br><span class="line">    model = YoloBody(<span class="number">3</span>, <span class="number">16</span>).<span class="built_in">eval</span>()</span><br><span class="line">    model.load_state_dict(torch.load(checkpoint))</span><br><span class="line">    <span class="comment">#将模型切换到推理状态</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建输入张量</span></span><br><span class="line">    <span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">416</span>, <span class="number">416</span>)</span><br><span class="line">    torch.onnx.export(model, <span class="built_in">input</span>, onnx_path, verbose=<span class="literal">True</span>, </span><br><span class="line">                      input_names=input_names, </span><br><span class="line">                      output_names=output_names)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Exporting .pth model to onnx model has been successful!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    checkpoint = <span class="string">&#x27;D:/pycharm/tinyyolov4/model_data/yolo4_tiny_weights_100epoch.pth&#x27;</span></span><br><span class="line">    onnx_path = <span class="string">&#x27;D:/pycharm/tinyyolov4/model_data/yolo4_tiny_weights_100epoch.onnx&#x27;</span>  </span><br><span class="line">    <span class="comment"># device = torch.device(&quot;cuda:2&quot; if torch.cuda.is_available() else &#x27;cpu&#x27;)</span></span><br><span class="line">    pth_to_onnx(checkpoint, onnx_path)</span><br></pre></td></tr></table></figure>

<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_51004308/article/details/116152611">https://blog.csdn.net/m0_51004308/article/details/116152611</a></p>
<h2 id="多batchsize导出ONNX模型"><a href="#多batchsize导出ONNX模型" class="headerlink" title="多batchsize导出ONNX模型"></a>多batchsize导出ONNX模型</h2><h3 id="Demo1"><a href="#Demo1" class="headerlink" title="Demo1"></a>Demo1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">b, h, w, c = model.shape</span><br><span class="line">str_w = <span class="built_in">str</span>(w)</span><br><span class="line">str_h = <span class="built_in">str</span>(h)</span><br><span class="line">str_c = <span class="built_in">str</span>(c)</span><br><span class="line">dynamic_axes = &#123;<span class="string">&#x27;input&#x27;</span>: &#123;<span class="number">0</span>: <span class="string">&#x27;batch&#x27;</span>, <span class="number">1</span>: str_h, <span class="number">2</span>: str_w, <span class="number">3</span>: str_c&#125;&#125;                   </span><br><span class="line">torch.onnx.export(model,                              <span class="comment"># model being run</span></span><br><span class="line">                  x,                                  <span class="comment"># model input (or a tuple for multiple inputs)</span></span><br><span class="line">                  <span class="string">&quot;model.onnx&quot;</span>,                      <span class="comment"># where to save the model (can be a file or file-like object)</span></span><br><span class="line">                  export_params=<span class="literal">True</span>,                  <span class="comment"># store the trained parameter weights inside the model file</span></span><br><span class="line">                  opset_version=<span class="number">11</span>,                  <span class="comment"># the ONNX version to export the model to</span></span><br><span class="line">                  do_constant_folding=<span class="literal">True</span>,         <span class="comment"># whether to execute constant folding for optimization</span></span><br><span class="line">                  input_names=[<span class="string">&#x27;input&#x27;</span>],              <span class="comment"># the model&#x27;s input names</span></span><br><span class="line">                  output_names=[<span class="string">&#x27;output&#x27;</span>],          <span class="comment"># the model&#x27;s output names</span></span><br><span class="line">                  dynamic_axes=dynamic_axes)</span><br><span class="line"></span><br><span class="line">原文链接：https://blog.csdn.net/wuqingshan2010/article/details/<span class="number">105686906</span></span><br></pre></td></tr></table></figure>

<h3 id="Demo2"><a href="#Demo2" class="headerlink" title="Demo2"></a>Demo2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> rt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> mmcv <span class="keyword">import</span> DictAction</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.core <span class="keyword">import</span> (build_model_from_cfg, generate_inputs_and_wrap_model,</span><br><span class="line">                        preprocess_example_input)</span><br><span class="line"><span class="keyword">from</span> onnxsim <span class="keyword">import</span> simplify</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line"></span><br><span class="line">    config_path = <span class="string">&quot;configs/fcos/fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_1x_coco.py&quot;</span></span><br><span class="line">    checkpoint_path = <span class="string">&quot;checkpoints/fcos_center-normbbox-centeronreg-giou_r50_caffe_fpn_gn-head_1x_coco-0a0d75a8.pth&quot;</span></span><br><span class="line">    output_file = <span class="string">&#x27;fcos_ori.onnx&#x27;</span></span><br><span class="line"></span><br><span class="line">    orig_model = build_model_from_cfg(config_path, checkpoint_path)</span><br><span class="line"></span><br><span class="line">    normalize_cfg = &#123;<span class="string">&#x27;mean&#x27;</span>: [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>], <span class="string">&#x27;std&#x27;</span>: [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]&#125;</span><br><span class="line">    input_config = &#123;</span><br><span class="line">        <span class="string">&#x27;input_shape&#x27;</span>: (<span class="number">1</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">256</span>),</span><br><span class="line">        <span class="string">&#x27;input_path&#x27;</span>: <span class="string">&#x27;tests/data/color.jpg&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;normalize_cfg&#x27;</span>: normalize_cfg</span><br><span class="line">    &#125;</span><br><span class="line">    model, tensor_data = generate_inputs_and_wrap_model(config_path, checkpoint_path, input_config)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># dynamic_ax = &#123;&#x27;images&#x27;: &#123;0:&quot;batch_size&quot;, 2: &quot;image_height&quot;, 3: &quot;image_width&quot;&#125;,</span></span><br><span class="line">    <span class="comment">#               &quot;fm1&quot;: &#123;0:&quot;batch_size&quot;, 2: &quot;fm1_height&quot;, 3: &quot;fm1_width&quot;&#125;,</span></span><br><span class="line">    <span class="comment">#               &quot;fm2&quot;: &#123;0:&quot;batch_size&quot;, 2: &quot;fm2_height&quot;, 3: &quot;fm2_width&quot;&#125;,</span></span><br><span class="line">    <span class="comment">#               &quot;fm3&quot;: &#123;0:&quot;batch_size&quot;, 2: &quot;fm3_height&quot;, 3: &quot;fm3_width&quot;&#125;,</span></span><br><span class="line">    <span class="comment">#               &quot;fm4&quot;: &#123;0:&quot;batch_size&quot;, 2: &quot;fm4_height&quot;, 3: &quot;fm4_width&quot;&#125;,</span></span><br><span class="line">    <span class="comment">#               &quot;fm5&quot;: &#123;0:&quot;batch_size&quot;, 2: &quot;fm5_height&quot;, 3: &quot;fm5_width&quot;&#125;&#125;</span></span><br><span class="line">    dynamic_ax = &#123;<span class="string">&#x27;input&#x27;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">&quot;fm1&quot;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">&quot;fm2&quot;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">&quot;fm3&quot;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">&quot;fm4&quot;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>],<span class="string">&quot;fm5&quot;</span>:[<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>]&#125;</span><br><span class="line">    input_names = [<span class="string">&quot;input&quot;</span>]</span><br><span class="line">    output_names = [<span class="string">&quot;fm1&quot;</span>,<span class="string">&quot;fm2&quot;</span>,<span class="string">&quot;fm3&quot;</span>,<span class="string">&quot;fm4&quot;</span>,<span class="string">&quot;fm5&quot;</span>]</span><br><span class="line">    torch.onnx.export(</span><br><span class="line">        model,</span><br><span class="line">        tensor_data,</span><br><span class="line">        output_file,</span><br><span class="line">        input_names=input_names,</span><br><span class="line">        output_names=output_names,</span><br><span class="line">        export_params=<span class="literal">True</span>,</span><br><span class="line">        keep_initializers_as_inputs=<span class="literal">True</span>,</span><br><span class="line">        do_constant_folding=<span class="literal">True</span>,</span><br><span class="line">        verbose=<span class="literal">False</span>,</span><br><span class="line">        opset_version=<span class="number">11</span>,</span><br><span class="line">        dynamic_axes=dynamic_ax)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;convert to onnx success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># model_simp, ok = simplify(onnx.load(output_file))</span></span><br><span class="line">    <span class="comment"># assert ok,&quot;simp failed!&quot;</span></span><br><span class="line">    <span class="comment"># onnx.save(model_simp,&quot;fcos_simp.onnx&quot;)</span></span><br></pre></td></tr></table></figure>

<h4 id="Run"><a href="#Run" class="headerlink" title="Run"></a>Run</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxruntime <span class="keyword">as</span> ort</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">sess = ort.InferenceSession(<span class="string">&quot;D:/tmp/fcos_ori.onnx&quot;</span>)</span><br><span class="line"><span class="comment"># x = np.random.randn(1,3,256,256).astype(np.float32)</span></span><br><span class="line">shapes = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">256</span>],[<span class="number">10</span>,<span class="number">3</span>,<span class="number">256</span>,<span class="number">256</span>],[<span class="number">1</span>,<span class="number">3</span>,<span class="number">1024</span>,<span class="number">1024</span>],[<span class="number">10</span>,<span class="number">3</span>,<span class="number">1024</span>,<span class="number">1024</span>]]</span><br><span class="line"></span><br><span class="line">s = time()</span><br><span class="line"><span class="keyword">for</span> shape <span class="keyword">in</span> shapes:</span><br><span class="line">    x = np.random.randn(*shape).astype(np.float32)</span><br><span class="line">    output = sess.run(<span class="literal">None</span>,&#123;<span class="string">&quot;input&quot;</span>:x&#125;)</span><br><span class="line">    <span class="keyword">for</span> o <span class="keyword">in</span> output:</span><br><span class="line">        <span class="built_in">print</span>(o.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span>*<span class="number">30</span>)</span><br><span class="line">e = time()</span><br><span class="line"><span class="built_in">print</span>(e-s)</span><br><span class="line"><span class="built_in">print</span>()</span><br></pre></td></tr></table></figure>

<p>存在的问题，动态输入的onnx模型简化是失败，但是可以转tensorrt</p>
<p>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_17127427/article/details/115749006">https://blog.csdn.net/qq_17127427/article/details/115749006</a></p>
<h3 id="Demo3"><a href="#Demo3" class="headerlink" title="Demo3"></a>Demo3</h3><p><a target="_blank" rel="noopener" href="https://www.freesion.com/article/2565433278/">https://www.freesion.com/article/2565433278/</a></p>
<h1 id="pth-导出TRT"><a href="#pth-导出TRT" class="headerlink" title="pth 导出TRT"></a>pth 导出TRT</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="ONNX导出TensorRT"><a href="#ONNX导出TensorRT" class="headerlink" title="ONNX导出TensorRT"></a>ONNX导出TensorRT</h1><h3 id="场景1"><a href="#场景1" class="headerlink" title="场景1"></a>场景1</h3><p><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=PyTorch&spm=1001.2101.3001.7020">PyTorch</a> 1.3，TensorRT 6.0，ONNX 1.5</p>
<p>PyTorch 训练好的 CRNN 模型，转换为 ONNX 之后无法转为 TensorRT</p>
<p>原因:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/onnx/onnx-tensorrt/blob/master/operators.md">https://github.com/onnx/onnx-tensorrt/blob/master/operators.md</a></p>
<p>↑ onnx-tensorrt 支持的操作列表，根本就不支持 <a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=RNN&spm=1001.2101.3001.7020">RNN</a>，包括 LSTM、GRU 等都不支持</p>
<p>解决<br><a target="_blank" rel="noopener" href="https://s0docs0nvidia0com.icopy.site/deeplearning/sdk/tensorrt-developer-guide/index.html#create_network_python">https://s0docs0nvidia0com.icopy.site/deeplearning/sdk/tensorrt-developer-guide/index.html#create_network_python</a></p>
<p><a target="_blank" rel="noopener" href="https://s0docs0nvidia0com.icopy.site/deeplearning/sdk/tensorrt-api/python_api/infer/Graph/Network.html">https://s0docs0nvidia0com.icopy.site/deeplearning/sdk/tensorrt-api/python_api/infer/Graph/Network.html</a></p>
<p>用 TensorRT 重新构建网络，并载入训练好的权重<br>————————————————<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/tsukumo99/article/details/103498390">https://blog.csdn.net/tsukumo99/article/details/103498390</a></p>
<h1 id="Pth不同版本的模型之间转换"><a href="#Pth不同版本的模型之间转换" class="headerlink" title="Pth不同版本的模型之间转换"></a>Pth不同版本的模型之间转换</h1><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010454261/article/details/114936724">https://blog.csdn.net/u010454261/article/details/114936724</a></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/379287312">【TensorRT系列】1.TensorRT安装教程</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/380950900">【TensorRT系列】2.ONNX-TensorRT安装教程</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395590559">【TensorRT系列】3.一个例子：PyTorch-&gt;ONNX-&gt;TensorRT</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/20/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><span class="page-number current">21</span><a class="page-number" href="/page/22/">22</a><span class="space">&hellip;</span><a class="page-number" href="/page/33/">33</a><a class="extend next" rel="next" href="/page/22/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon Shi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">322</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">269</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Simon Shi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
