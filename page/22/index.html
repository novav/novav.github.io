<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"novav.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Simon Shi的小站">
<meta property="og:url" content="https://novav.github.io/page/22/index.html">
<meta property="og:site_name" content="Simon Shi的小站">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Simon Shi">
<meta property="article:tag" content="AI,Machine Learning, Deep Learning">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://novav.github.io/page/22/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Simon Shi的小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Simon Shi的小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能，机器学习， 强化学习，大模型，自动驾驶</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/05/23/Sub_Language/DL_Train/Tensorflow/TF-keras/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/23/Sub_Language/DL_Train/Tensorflow/TF-keras/" class="post-title-link" itemprop="url">TF使用Keras</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-23 13:00:01" itemprop="dateCreated datePublished" datetime="2021-05-23T13:00:01+00:00">2021-05-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/" itemprop="url" rel="index"><span itemprop="name">DNN_platform</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DNN-platform/Keras/" itemprop="url" rel="index"><span itemprop="name">Keras</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="APIS"><a href="#APIS" class="headerlink" title="APIS"></a>APIS</h3><h4 id="compile参数介绍"><a href="#compile参数介绍" class="headerlink" title="compile参数介绍"></a>compile参数介绍</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">   optimizer, </span><br><span class="line">   loss = <span class="literal">None</span>, </span><br><span class="line">   metrics = <span class="literal">None</span>, </span><br><span class="line">   loss_weights = <span class="literal">None</span>, </span><br><span class="line">   sample_weight_mode = <span class="literal">None</span>, </span><br><span class="line">   weighted_metrics = <span class="literal">None</span>, </span><br><span class="line">   target_tensors = <span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>optimizer：优化器，用于控制梯度裁剪。必选项<br>loss：损失函数（或称目标函数、优化评分函数）。必选项<br>metrics：评价函数用于评估当前训练模型的性能。当模型编译后（compile），评价函数应该作为 metrics 的参数来输入。评价函数和损失函数相似，只不过评价函数的结果不会用于训练过程中。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/huang1024rui/article/details/120055487">https://blog.csdn.net/huang1024rui/article/details/120055487</a></p>
<h3 id="TF2-3-Keras-Sequential-顺序模型"><a href="#TF2-3-Keras-Sequential-顺序模型" class="headerlink" title="TF2.3-Keras Sequential 顺序模型"></a>TF2.3-Keras Sequential 顺序模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Activation</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)),</span><br><span class="line">    Activation(<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    Dense(<span class="number">10</span>),</span><br><span class="line">    Activation(<span class="string">&#x27;softmax&#x27;</span>),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">784</span>))</span><br><span class="line">model.add(Activation(<span class="string">&#x27;relu&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="输入数据"><a href="#输入数据" class="headerlink" title="输入数据"></a>输入数据</h3><p>等价片段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_shape=(<span class="number">784</span>,)))</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, input_dim=<span class="number">784</span>))</span><br></pre></td></tr></table></figure>

<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多分类问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二分类问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 均方误差回归问题</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义评估标准函数</span></span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_pred</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> K.mean(y_pred)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>, mean_pred])</span><br></pre></td></tr></table></figure>

<h2 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于具有 2 个类的单输入模型（二进制分类）：</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_dim=<span class="number">100</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">100</span>))</span><br><span class="line">labels = np.random.randint(<span class="number">2</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型，以 32 个样本为一个 batch 进行迭代</span></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于具有 10 个类的单输入模型（多分类分类）：</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_dim=<span class="number">100</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">100</span>))</span><br><span class="line">labels = np.random.randint(<span class="number">10</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签转换为分类的 one-hot 编码</span></span><br><span class="line">one_hot_labels = keras.utils.to_categorical(labels, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型，以 32 个样本为一个 batch 进行迭代</span></span><br><span class="line">model.fit(data, one_hot_labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><h3 id="基于多层感知器-MLP-的-softmax-多分类："><a href="#基于多层感知器-MLP-的-softmax-多分类：" class="headerlink" title="基于多层感知器 (MLP) 的 softmax 多分类："></a>基于多层感知器 (MLP) 的 softmax 多分类：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Activation</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x_train = np.random.random((<span class="number">1000</span>, <span class="number">20</span>))</span><br><span class="line">y_train = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">1000</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line">x_test = np.random.random((<span class="number">100</span>, <span class="number">20</span>))</span><br><span class="line">y_test = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">100</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># Dense(64) 是一个具有 64 个隐藏神经元的全连接层。</span></span><br><span class="line"><span class="comment"># 在第一层必须指定所期望的输入数据尺寸：</span></span><br><span class="line"><span class="comment"># 在这里，是一个 20 维的向量。</span></span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_dim=<span class="number">20</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">sgd = SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=sgd,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          batch_size=<span class="number">128</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">128</span>)</span><br></pre></td></tr></table></figure>

<h3 id="二分类"><a href="#二分类" class="headerlink" title="二分类"></a>二分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line">x_train = np.random.random((<span class="number">1000</span>, <span class="number">20</span>))</span><br><span class="line">y_train = np.random.randint(<span class="number">2</span>, size=(<span class="number">1000</span>, <span class="number">1</span>))</span><br><span class="line">x_test = np.random.random((<span class="number">100</span>, <span class="number">20</span>))</span><br><span class="line">y_test = np.random.randint(<span class="number">2</span>, size=(<span class="number">100</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">64</span>, input_dim=<span class="number">20</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          batch_size=<span class="number">128</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">128</span>)</span><br></pre></td></tr></table></figure>

<p>VGG类CNN</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟数据</span></span><br><span class="line">x_train = np.random.random((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">y_train = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">100</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line">x_test = np.random.random((<span class="number">20</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">y_test = keras.utils.to_categorical(np.random.randint(<span class="number">10</span>, size=(<span class="number">20</span>, <span class="number">1</span>)), num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 输入: 3 通道 100x100 像素图像 -&gt; (100, 100, 3) 张量。</span></span><br><span class="line"><span class="comment"># 使用 32 个大小为 3x3 的卷积滤波器。</span></span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">sgd = SGD(lr=<span class="number">0.01</span>, decay=<span class="number">1e-6</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=sgd)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">10</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"></span><br><span class="line">max_features = <span class="number">1024</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(max_features, output_dim=<span class="number">256</span>))</span><br><span class="line">model.add(LSTM(<span class="number">128</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">16</span>, epochs=<span class="number">10</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1D卷积序列分类"><a href="#1D卷积序列分类" class="headerlink" title="1D卷积序列分类"></a>1D卷积序列分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv1D, GlobalAveragePooling1D, MaxPooling1D</span><br><span class="line"></span><br><span class="line">seq_length = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv1D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(seq_length, <span class="number">100</span>)))</span><br><span class="line">model.add(Conv1D(<span class="number">64</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling1D(<span class="number">3</span>))</span><br><span class="line">model.add(Conv1D(<span class="number">128</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Conv1D(<span class="number">128</span>, <span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(GlobalAveragePooling1D())</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">16</span>, epochs=<span class="number">10</span>)</span><br><span class="line">score = model.evaluate(x_test, y_test, batch_size=<span class="number">16</span>)</span><br></pre></td></tr></table></figure>

<h3 id="基于栈式-LSTM-的序列分类"><a href="#基于栈式-LSTM-的序列分类" class="headerlink" title="基于栈式 LSTM 的序列分类"></a>基于栈式 LSTM 的序列分类</h3><p>在这个模型中，我们将 3 个 LSTM 层叠在一起，使模型能够学习更高层次的时间表示。</p>
<p>前两个 LSTM 返回完整的输出序列，但最后一个只返回输出序列的最后一步，从而降低了时间维度（即将输入序列转换成单个向量）。</p>
<p><img src="https://ask.qcloudimg.com/http-save/7774426/fhiiha2z1m.png?imageView2/2/w/1620"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM, Dense</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data_dim = <span class="number">16</span></span><br><span class="line">timesteps = <span class="number">8</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输入数据尺寸: (batch_size, timesteps, data_dim)</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>,</span><br><span class="line">               input_shape=(timesteps, data_dim)))  <span class="comment"># 返回维度为 32 的向量序列</span></span><br><span class="line">model.add(LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>))  <span class="comment"># 返回维度为 32 的向量序列</span></span><br><span class="line">model.add(LSTM(<span class="number">32</span>))  <span class="comment"># 返回维度为 32 的单个向量</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟训练数据</span></span><br><span class="line">x_train = np.random.random((<span class="number">1000</span>, timesteps, data_dim))</span><br><span class="line">y_train = np.random.random((<span class="number">1000</span>, num_classes))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟验证数据</span></span><br><span class="line">x_val = np.random.random((<span class="number">100</span>, timesteps, data_dim))</span><br><span class="line">y_val = np.random.random((<span class="number">100</span>, num_classes))</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=<span class="number">64</span>, epochs=<span class="number">5</span>,</span><br><span class="line">          validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>

<h3 id="“stateful”-渲染的的栈式-LSTM-模型"><a href="#“stateful”-渲染的的栈式-LSTM-模型" class="headerlink" title="“stateful” 渲染的的栈式 LSTM 模型"></a>“stateful” 渲染的的栈式 LSTM 模型</h3><p>有状态 (stateful) 的循环神经网络模型中，在一个 batch 的样本处理完成后，其内部状态（记忆）会被记录并作为下一个 batch 的样本的初始状态。这允许处理更长的序列，同时保持计算复杂度的可控性。</p>
<p><a target="_blank" rel="noopener" href="https://keras.io/getting-started/faq/#how-can-i-use-stateful-rnns">你可以在 FAQ 中查找更多关于 stateful RNNs 的信息。</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM, Dense</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data_dim = <span class="number">16</span></span><br><span class="line">timesteps = <span class="number">8</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 期望输入数据尺寸: (batch_size, timesteps, data_dim)</span></span><br><span class="line"><span class="comment"># 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。</span></span><br><span class="line"><span class="comment"># 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>, stateful=<span class="literal">True</span>,</span><br><span class="line">               batch_input_shape=(batch_size, timesteps, data_dim)))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, return_sequences=<span class="literal">True</span>, stateful=<span class="literal">True</span>))</span><br><span class="line">model.add(LSTM(<span class="number">32</span>, stateful=<span class="literal">True</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟训练数据</span></span><br><span class="line">x_train = np.random.random((batch_size * <span class="number">10</span>, timesteps, data_dim))</span><br><span class="line">y_train = np.random.random((batch_size * <span class="number">10</span>, num_classes))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成虚拟验证数据</span></span><br><span class="line">x_val = np.random.random((batch_size * <span class="number">3</span>, timesteps, data_dim))</span><br><span class="line">y_val = np.random.random((batch_size * <span class="number">3</span>, num_classes))</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=batch_size, epochs=<span class="number">5</span>, shuffle=<span class="literal">False</span>,</span><br><span class="line">          validation_data=(x_val, y_val))</span><br></pre></td></tr></table></figure>

<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1747191">Keras 学习笔记（三）Keras Sequential 顺序模型 - 腾讯云开发者社区-腾讯云</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/02/05/Paper/Paper-CV-NET-Mask_RCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/02/05/Paper/Paper-CV-NET-Mask_RCNN/" class="post-title-link" itemprop="url">Mask RCNN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-02-05 10:00:12" itemprop="dateCreated datePublished" datetime="2021-02-05T10:00:12+00:00">2021-02-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/BaseWork/" itemprop="url" rel="index"><span itemprop="name">BaseWork</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/BaseWork/Segmentation/" itemprop="url" rel="index"><span itemprop="name">Segmentation</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><img src="/2021/02/05/Paper/Paper-CV-NET-Mask_RCNN/mask_rcnn.png" alt="img"></p>
<p>Mask R-CNN是在Faster R-CNN的基础上添加了一个预测分割mask的分支，如上图所示。其中黑色部分为原来的Faster-RCNN，红色部分为在Faster-RCNN网络上的修改。将RoI Pooling 层替换成了RoIAlign层；添加了并列的FCN层（mask层）。</p>
<p>Mask RCNN库的使用</p>
<h3 id="环境安装："><a href="#环境安装：" class="headerlink" title="环境安装："></a>环境安装：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Installation</span><br><span class="line">1.Clone this repository</span><br><span class="line"></span><br><span class="line">2.Install dependencies</span><br><span class="line">	pip3 install -r requirements.txt</span><br><span class="line"></span><br><span class="line">3.Run setup from the repository root directory</span><br><span class="line">	python3 setup.py install</span><br><span class="line"></span><br><span class="line">4.Download pre-trained COCO weights (mask_rcnn_coco.h5) from the releases page.(https://github.com/matterport/Mask_RCNN/releases)</span><br><span class="line"></span><br><span class="line">5.(Optional) To train or test on MS COCO install pycocotools from one of these repos. They are forks of the original pycocotools with fixes for Python3 and Windows (the official repo doesn&#x27;t seem to be active anymore).</span><br><span class="line">    Linux: https://github.com/waleedka/coco</span><br><span class="line">    Windows: https://github.com/philferriere/cocoapi. You must have the Visual C++ 2015 build tools on your path (see the repo for additional details)</span><br></pre></td></tr></table></figure>



<h3 id="语义分割使用："><a href="#语义分割使用：" class="headerlink" title="语义分割使用："></a>语义分割使用：</h3><p><a target="_blank" rel="noopener" href="https://github.com/matterport/Mask_RCNN/blob/master/samples/demo.ipynb">https://github.com/matterport/Mask_RCNN/blob/master/samples/demo.ipynb</a></p>
<p>Ref：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37392244/article/details/88844681">https://blog.csdn.net/qq_37392244/article/details/88844681</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/01/29/CV/CV-Datasets-2D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/29/CV/CV-Datasets-2D/" class="post-title-link" itemprop="url">计算机视觉--视觉2D数据库</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-29 16:36:57" itemprop="dateCreated datePublished" datetime="2021-01-29T16:36:57+00:00">2021-01-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/Datasets/" itemprop="url" rel="index"><span itemprop="name">Datasets</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="人脸数据"><a href="#人脸数据" class="headerlink" title="人脸数据"></a>人脸数据</h3><h4 id="PubFiG"><a href="#PubFiG" class="headerlink" title="PubFiG"></a>PubFiG</h4><p>这是哥伦比亚大学的公众人物脸部数据集，包含有200个人的58k+人脸图像，主要用于非限制场景下的人脸识别。</p>
<h4 id="Multi-Task-Facial-Landmark-MTFL-dataset"><a href="#Multi-Task-Facial-Landmark-MTFL-dataset" class="headerlink" title="Multi-Task Facial Landmark (MTFL) dataset"></a><a href="https://link.zhihu.com/?target=http://mmlab.ie.cuhk.edu.hk/projects/TCDCN.html">Multi-Task Facial Landmark (MTFL) dataset</a></h4><p>该数据集包含了将近13000张人脸图片，均采自网络。</p>
<h4 id="BioID-Face-Database-FaceDB"><a href="#BioID-Face-Database-FaceDB" class="headerlink" title="BioID Face Database - FaceDB"></a><a href="https://link.zhihu.com/?target=https://www.bioid.com/About/BioID-Face-Database">BioID Face Database - FaceDB</a></h4><p>这个数据集包含了1521幅分辨率为384x286像素的灰度图像。 每一幅图像来自于23个不同的测试人员的正面角度的人脸。为了便于做比较，这个数据集也包含了对人脸图像对应的手工标注的人眼位置文件。 图像以 “BioID_xxxx.pgm”的格式命名，其中xxxx代表当前图像的索引(从0开始)。类似的，形如”BioID_xxxx.eye”的文件包含了对应图像中眼睛的位置。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-02a4e6b8ee4b8f85c32424b3d6fde933_hd.jpg" alt="img"></p>
<h4 id="Labeled-Faces-in-the-Wild-Home-LFW"><a href="#Labeled-Faces-in-the-Wild-Home-LFW" class="headerlink" title="Labeled Faces in the Wild Home (LFW)"></a><a href="https://link.zhihu.com/?target=http://vis-www.cs.umass.edu/lfw/">Labeled Faces in the Wild Home (LFW)</a></h4><p><em>More than 13,000 images of faces collected from the web. Each face has been labeled with the name of the person pictured. 1680 of the people pictured have two or more distinct photos in the data set.</em></p>
<p>LFW数据集是为了研究非限制环境下的人脸识别问题而建立的。这个数据集包含超过13，000张人脸图像，均采集于Internet。</p>
<p>每个人脸均被标准了一个人名。其中，大约1680个人包含两个以上的人脸。</p>
<p>这个集合被广泛应用于评价Face Verification算法的性能。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-8499ca4c7e0d2ee2d42be0cf40d363cb_hd.jpg" alt="img"></p>
<h4 id="CelebA-HQ"><a href="#CelebA-HQ" class="headerlink" title="CelebA_HQ"></a>CelebA_HQ</h4><p>30000张，512*512人脸图片 下载链接(含百度云等)见<a target="_blank" rel="noopener" href="https://github.com/switchablenorms/CelebAMask-HQ">https://github.com/switchablenorms/CelebAMask-HQ</a></p>
<h4 id="FFHQ"><a href="#FFHQ" class="headerlink" title="FFHQ"></a>FFHQ</h4><p><a target="_blank" rel="noopener" href="https://github.com/NVlabs/ffhq-dataset">https://github.com/NVlabs/ffhq-dataset</a></p>
<p>Google: <a target="_blank" rel="noopener" href="https://github.com/NVlabs/ffhq-dataset">https://github.com/NVlabs/ffhq-dataset</a></p>
<p>百度网盘：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_37867534/article/details/90404660">https://blog.csdn.net/qq_37867534/article/details/90404660</a></p>
<h4 id="CMU-人脸数据"><a href="#CMU-人脸数据" class="headerlink" title="CMU 人脸数据"></a>CMU 人脸数据</h4><h4 id="CMUVASC-PIE-Face-dataset"><a href="#CMUVASC-PIE-Face-dataset" class="headerlink" title="CMUVASC &amp; PIE Face dataset"></a><a href="https://link.zhihu.com/?target=http://vasc.ri.cmu.edu/idb/html/face/index.html">CMUVASC &amp; PIE Face dataset</a></h4><p><em>The face datasets were provided by the face reserch group at CMU.</em></p>
<p>CMU PIE人脸库建立于2000年11月，它包括来自68个人的40000张照片，其中包括了每个人的13种姿态条件，43种光照条件和4种表情下的照片，现有的多姿态人脸识别的文献基本上都是在CMU PIE人脸库上测试的。</p>
<h4 id="YouTube-Faces"><a href="#YouTube-Faces" class="headerlink" title="YouTube Faces"></a><a href="https://link.zhihu.com/?target=http://www.cs.tau.ac.il/~wolf/ytfaces/">YouTube Faces</a></h4><p><em>The data set contains 3,425 videos of 1,595 different people. The shortest clip duration is 48 frames, the longest clip is 6,070 frames, and the average length of a video clip is 181.3 frames.</em></p>
<p>YouTube Video Faces是用来做人脸验证的。在这个数据集下，算法需要判断两段视频里面是不是同一个人。有不少在照片上有效的方法，在视频上未必有效&#x2F;高效。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-70bed021c7dcb17140e9cc85e85cf3d5_hd.jpg" alt="img"></p>
<h4 id="CASIA-FaceV5"><a href="#CASIA-FaceV5" class="headerlink" title="CASIA-FaceV5"></a><a href="https://link.zhihu.com/?target=http://biometrics.idealtest.org/dbDetailForUser.do?id=9">CASIA-FaceV5</a></h4><p><em>CASIA Face Image Database Version 5.0 (or CASIA-FaceV5) contains 2,500 color facial images of 500 subjects.</em></p>
<p>该数据集包含了来自500个人的2500张亚洲人脸图片.</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-064d5695a7ccd9f39e6748dca537dfd7_hd.jpg" alt="img"></p>
<h4 id="The-CNBC-Face-Database"><a href="#The-CNBC-Face-Database" class="headerlink" title="The CNBC Face Database"></a><a href="https://link.zhihu.com/?target=http://wiki.cnbc.cmu.edu/Face_Place">The CNBC Face Database</a></h4><p><em>This database includes multiple images for over 200 individuals of many different races with consistent lighting, multiple views, real emotions, and disguises (and some participants returned for a second session several weeks later with a haircut, or a new beard, etc.).</em></p>
<p>该数据集采集了200个人在不同状态下（不同的神情，装扮，发型等）的人脸照片。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-e8473e026640d6152841c102a4b91ebb_hd.jpg" alt="img"></p>
<h4 id="CASIA-3D-FaceV1"><a href="#CASIA-3D-FaceV1" class="headerlink" title="CASIA-3D FaceV1"></a><a href="https://link.zhihu.com/?target=http://biometrics.idealtest.org/dbDetailForUser.do?id=8">CASIA-3D FaceV1</a></h4><p><em>4624 scans of 123 persons using the non-contact 3D digitizer, Minolta Vivid 910, as shown in figure.</em></p>
<p>该数据集包含了来自123个人的4624张人脸图片，所有图片均由下图的仪器进行拍摄。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-93b16a445805b3368ea5a51048d7e7e9_hd.jpg" alt="img"></p>
<h4 id="IMDB-WIKI"><a href="#IMDB-WIKI" class="headerlink" title="IMDB-WIKI"></a><a href="https://link.zhihu.com/?target=https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/">IMDB-WIKI</a></h4><p><em>In total we obtained 460,723 face images from 20,284 celebrities from IMDb and 62,328 from Wikipedia, thus 523,051 in total.</em></p>
<p>IMDB-WIKI人脸数据库是有IMDB数据库和Wikipedia数据库组成，其中IMDB人脸数据库包含了460,723张人脸图片，而Wikipedia人脸数据库包含了62,328张人脸数据库，总共523,051张人脸数据库，IMDB-WIKI人脸数据库中的每张图片都被标注了人的年龄和性别，对于年龄识别和性别识别的研究有着重要的意义。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-8a9da43b318b684b96f4c027218665d6_hd.jpg" alt="img"></p>
<h4 id="FDDB"><a href="#FDDB" class="headerlink" title="FDDB"></a><a href="https://link.zhihu.com/?target=http://vis-www.cs.umass.edu/fddb/index.html">FDDB</a></h4><p><em>A data set of face regions designed for studying the problem of unconstrained face detection. This data set contains the annotations for 5171 faces in a set of 2845 images taken from the Faces in the Wild data set.</em></p>
<p>FDDB是UMass的数据集，被用来做人脸检测(Face Detection)。这个数据集比较大，比较有挑战性。而且作者提供了程序用来评估检测结果，所以在这个数据上面比较算法也相对公平。</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-2d63fade755c5f60918599a2855e018b_hd.jpg" alt="img"></p>
<h4 id="Caltech人脸数据库"><a href="#Caltech人脸数据库" class="headerlink" title="Caltech人脸数据库"></a><a href="https://link.zhihu.com/?target=http://www.vision.caltech.edu/Image_Datasets/Caltech_10K_WebFaces/%23Description">Caltech人脸数据库</a></h4><p><em>The dataset contains images of people collected from the web by typing common given names into Google Image Search. The coordinates of the eyes, the nose and the center of the mouth for each frontal face are provided in a ground truth file. This information can be used to align and crop the human faces or as a ground truth for a face detection algorithm. The dataset has 10,524 human faces of various resolutions and in different settings, e.g. portrait images, groups of people, etc. Profile faces or very low resolution faces are not labeled.</em></p>
<p>10k+人脸，提供双眼和嘴巴的坐标位置</p>
<p><img src="/2021/01/29/CV/CV-Datasets-2D/v2-5855e777e5e7cbf71dafadc07899acf3_hd.jpg" alt="img"></p>
<h4 id="The-Japanese-Female-Facial-Expression-JAFFE-Database"><a href="#The-Japanese-Female-Facial-Expression-JAFFE-Database" class="headerlink" title="The Japanese Female Facial Expression (JAFFE) Database"></a><a href="https://link.zhihu.com/?target=http://www.kasrl.org/jaffe.html">The Japanese Female Facial Expression (JAFFE) Database</a></h4><p><em>The database contains 213 images of 7 facial expressions (6 basic facial expressions + 1 neutral) posed by 10 Japanese female models. Each image has been rated on 6 emotion adjectives by 60 Japanese subjects. The database was planned and assembled by Michael Lyons, Miyuki Kamachi, and Jiro Gyoba. We thank Reiko Kubota for her help as a research assistant. The photos were taken at the Psychology Department in Kyushu University.</em></p>
<p>该数据库是由10位日本女性在实验环境下根据指示做出各种表情，再由照相机拍摄获取的人脸表情图像。整个数据库一共有213张图像，10个人，全部都是女性，每个人做出7种表情，这7种表情分别是： sad, happy, angry, disgust, surprise, fear, neutral. 每个人为一组，每一组都含有7种表情，每种表情大概有3,4张样图。</p>
<h4 id="AAF"><a href="#AAF" class="headerlink" title="AAF"></a>AAF</h4><p>全年龄（AAF）数据集包含分布在所有年龄段（2至80岁）的13322人脸图像（大部分为亚洲人）</p>
<p>Download link (baidu): <a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1WtHQsb73rLa-cZpBLi2dtg">https://pan.baidu.com/s/1WtHQsb73rLa-cZpBLi2dtg</a><br>Download link (dropbox): [<a target="_blank" rel="noopener" href="https://www.dropbox.com/s/a0lj1ddd54ns8qy/All-Age-Faces%20Dataset.zip?dl=0%5D">https://www.dropbox.com/s/a0lj1ddd54ns8qy/All-Age-Faces%20Dataset.zip?dl=0]</a>(<a target="_blank" rel="noopener" href="https://www.dropbox.com/s/a0lj1ddd54ns8qy/All-Age-Faces">https://www.dropbox.com/s/a0lj1ddd54ns8qy/All-Age-Faces</a> Dataset.zip?dl&#x3D;0)</p>
<h4 id="gender-and-age-classification"><a href="#gender-and-age-classification" class="headerlink" title="gender and age classification"></a>gender and age classification</h4><p><a target="_blank" rel="noopener" href="https://talhassner.github.io/home/projects/Adience/Adience-data.html#agegender">https://talhassner.github.io/home/projects/Adience/Adience-data.html#agegender</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Adience Faces</span><br><span class="line">Thanks for allowing us to keep in touch!</span><br><span class="line"></span><br><span class="line">User: adiencedb</span><br><span class="line">Password: adience</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="全身数据"><a href="#全身数据" class="headerlink" title="全身数据"></a>全身数据</h3><p>ref:</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ansang/p/8137413.html">人脸识别常用数据集大全（12&#x2F;20更新） </a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/01/19/CV/CV-SR-Impainting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/19/CV/CV-SR-Impainting/" class="post-title-link" itemprop="url">图像修复+高清</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-19 16:17:39" itemprop="dateCreated datePublished" datetime="2021-01-19T16:17:39+00:00">2021-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV-Apply/" itemprop="url" rel="index"><span itemprop="name">CV_Apply</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV-Apply/SR/" itemprop="url" rel="index"><span itemprop="name">SR</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2020-08-25-9"><strong>AI还原的朱元璋、兵马俑来了！杜甫激燃演唱奥特曼主题曲，B站Up主大谷新作</strong></a></p>
<p>Denis 在这一视频中所使用的修复技术有五种，分别是 Face-Image-Motion-Model、StyleGAN2-Face-Modificator、DAIN、ESRGAN 和 Artbreeder。</p>
<h3 id="Face-Image-Motion-Model"><a href="#Face-Image-Motion-Model" class="headerlink" title="Face-Image-Motion-Model"></a><strong>Face-Image-Motion-Model</strong></h3><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/tg-bomze/Face-Image-Motion-Model">https://github.com/tg-bomze/Face-Image-Motion-Model</a></p>
<p>该模型基于「First Order Motion」这一核心模型，方法来源于 NeurIPS 2019 论文《First Order Motion Model for Image Animation》。机器之心此前介绍过的视频会议换脸软件「<a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650785496&idx=3&sn=b6a4c9478e6eb751b976d768d9ae30dd&chksm=871a02a6b06d8bb0dc3f008f3ded2c9698980dcd5a80ee5e14294ddeeeaa7a24541f0e07ebf6&scene=21#wechat_redirect">Avatarify</a>」，也是基于这一技术实现人脸处理的。</p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation.pdf">https://papers.nips.cc/paper/8935-first-order-motion-model-for-image-animation.pdf</a></p>
<p>「First Order Motion」框架由两个主要模块组成：「运动估计模块」和「图像生成模块」。运动估计模块的目的在于预测密集的运动场，此处假设存在一个抽象的参考坐标，并预估存在「from reference to source」和「from reference to driving」两种转换。因此可以独立处理源帧和驱动帧。做这样的处理是因为模型在测试时会接收从不同视频中采样的源图像帧和驱动帧的组，从视觉上来说可能会很不同。</p>
<h3 id="StyleGAN2-Face-Modificator"><a href="#StyleGAN2-Face-Modificator" class="headerlink" title="StyleGAN2-Face-Modificator"></a><strong>StyleGAN2-Face-Modificator</strong></h3><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/tg-bomze/StyleGAN2-Face-Modificator">https://github.com/tg-bomze/StyleGAN2-Face-Modificator</a></p>
<p><a target="_blank" rel="noopener" href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650776906&idx=2&sn=ca493a8979c9510d5ae901d00075fe8e&chksm=871a6134b06de8229a6824b16c2b5997cf0c6e33ce00079b285ef9306dfa0cbb8dc1d315886e&scene=21#wechat_redirect">StyleGAN2</a> 是英伟达在 2019 年 12 月开源的高分辨率图像生成方法，相比于前辈「StyleGAN」，它在解决生成图像伪影问题的同时，还能得到细节更好的高质量图像。「StyleGAN2-Face-Modificator」则是基于这一技术开发的人脸编辑器工具。</p>
<p> <img src="https://image.jiqizhixin.com/uploads/editor/abb5520e-3d60-42c1-b10f-78841acaf542/640.png" alt="img"> </p>
<h3 id="DAIN-CVPR2019"><a href="#DAIN-CVPR2019" class="headerlink" title="DAIN CVPR2019"></a><strong>DAIN</strong> CVPR2019</h3><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/baowenbo/DAIN">https://github.com/baowenbo/DAIN</a></p>
<p>DAIN 模型来源于 CVPR 2019 论文《Depth-Aware Video Frame Interpolation》，在这一研究中，上海交通大学、加州大学默塞德分校、谷歌等机构的研究者，针对基于深度学习的视频插帧任务中的常见问题进行了优化，<strong>提出了一种利用深度信息检测遮挡的视频帧插值方法。Denis 在多个修复视频中都使用了这一技术</strong>。</p>
<p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.00830.pdf">https://arxiv.org/pdf/1904.00830.pdf</a></p>
<p> <img src="https://image.jiqizhixin.com/uploads/editor/06b418d0-7734-49d0-98d6-587165588c5b/640.png" alt="img"> </p>
<h3 id="ESRGAN-ECCV2018"><a href="#ESRGAN-ECCV2018" class="headerlink" title="ESRGAN-ECCV2018"></a><strong>ESRGAN</strong>-ECCV2018</h3><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/xinntao/ESRGAN">https://github.com/xinntao/ESRGAN</a></p>
<p>Denis Shiryaev 视频中所用到的分辨率扩增方法为「ESRGAN」，该方法来源于 ECCV 2018 Workshop 论文《ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks》，研究者在 * *SRGAN 的基础上进行了改进，包括改进网络的结构、判别器的判别形式，以及更换了一个用于计算感知域损失的预训练网络，提出了一种 Residual-in-Residual Dense Block (RRDB) 的网络单元。</p>
<p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1809.00219.pdf">https://arxiv.org/pdf/1809.00219.pdf</a></p>
<p> <img src="https://image.jiqizhixin.com/uploads/editor/e160c7d2-308c-43b2-b793-4056e6f0f489/640.png" alt="img"> </p>
<h3 id="Artbreeder"><a href="#Artbreeder" class="headerlink" title="Artbreeder"></a><strong>Artbreeder</strong></h3><p>Artbreeder 是一款在线生成程序，该网站拥有大量不同风格的面部图像，用户可以手动进行调整，将不同的图像混合在一起，生成全新的图像。</p>
<p>近日，设计师 Daniel Voshart 利用 Artbreeder，结合手动调整，修复了 800 张罗马皇帝半身像的照片，在社交网络上引起热议。</p>
<p>网站地址：<a target="_blank" rel="noopener" href="http://artbreeder.com/">http://artbreeder.com/</a> </p>
<p>此外，Denis Shiryaev 还在自己的 YouTube 频道发布了许多修复视频，如果你有兴趣的话，可以在他的网站观看更多作品：<a target="_blank" rel="noopener" href="https://neural.love/">https://neural.love/</a></p>
<h3 id="相关论文"><a href="#相关论文" class="headerlink" title="相关论文"></a>相关论文</h3><p><a href="../Paper/Paper-CV-SuperResolution.md">..&#x2F;Paper&#x2F;Paper-CV-SuperResolution.md</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/01/19/AI/DL/Few_shot_learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/19/AI/DL/Few_shot_learning/" class="post-title-link" itemprop="url">Few Shot Learning(小样本学习)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-19 11:49:03" itemprop="dateCreated datePublished" datetime="2021-01-19T11:49:03+00:00">2021-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:37" itemprop="dateModified" datetime="2025-08-06T08:16:37+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/DeepLearning/" itemprop="url" rel="index"><span itemprop="name">DeepLearning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h1 id="小样本学习"><a href="#小样本学习" class="headerlink" title="小样本学习"></a>小样本学习</h1><p>原文：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/61215293">https://zhuanlan.zhihu.com/p/61215293</a></p>
<p><strong>作者丨耿瑞莹、李永彬、黎槟华</strong></p>
<p><strong>单位丨阿里巴巴智能服务事业部小蜜北京团队</strong></p>
<p>分类非常常见，但如果每个类只有几个标注样本，怎么办呢？</p>
<p>笔者所在的阿里巴巴小蜜北京团队就面临这个挑战。我们打造了一个智能对话开发平台——Dialog Studio，以赋能第三方开发者来开发各自业务场景中的任务型对话，其中一个重要功能就是对意图进行分类。大量平台用户在创建一个新对话任务时，并没有大量标注数据，每个意图往往只有几个或十几个样本。</p>
<p>**面对这类问题，有一个专门的机器学习分支——Few-shot Learning 来进行研究和解决。**过去一年，我们对 Few-shot Learning 进行了系统的梳理和研究，将 Few-shot Learning 和 Capsule Network 融合，提出了 Induction Network，在文本分类上做到了新的 state-of-the-art。创新总是基于对已有成果的梳理和思考，这篇综述算是一个小结，写出来和大家一起分享，一起讨论。</p>
<p>本文先介绍 Few-shot Learning 定义；由于最近几年 Few-shot Learning 在图像领域的进展领先于在自然语言处理领域，所以第二部分结合其在图像处理领域的研究进展，详细介绍 Few-shot Learning 的三类典型方法及每种方法的代表性模型；接下来介绍在自然语言处理领域的研究进展以及我们对 metric-based 的方法进行系统总结后提出的 few-shot learning framework。</p>
<h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a><strong>问题定义</strong></h2><p>人类非常擅长通过极少量的样本识别一个新物体，比如小孩子只需要书中的一些图片就可以认识什么是“斑马”，什么是“犀牛”。在人类的快速学习能力的启发下，研究人员希望机器学习模型在学习了一定类别的大量数据后，对于新的类别，只需要少量的样本就能快速学习，这就是 Few-shot Learning 要解决的问题。</p>
<p><strong>Few-shot Learning 是</strong> **Meta Learning 在监督学习领域的应用。**Meta Learning，又称为 learning to learn，在 meta training 阶段将数据集分解为不同的 meta task，去学习类别变化的情况下模型的泛化能力，在 meta testing 阶段，面对全新的类别，不需要变动已有的模型，就可以完成分类。</p>
<p>形式化来说，few-shot 的训练集中包含了很多的类别，每个类别中有多个样本。在训练阶段，会在训练集中随机抽取 C 个类别，每个类别 K 个样本（总共 CK 个数据），构建一个 meta-task，作为模型的支撑集（support set）输入；再从这 C 个类中剩余的数据中抽取一批（batch）样本作为模型的预测对象（batch set）。即要求模型从 C*K 个数据中学会如何区分这 C 个类别，<strong>这样的任务被称为 C-way K-shot 问题。</strong></p>
<p>训练过程中，每次训练（episode）都会采样得到不同 meta-task，所以总体来看，训练包含了不同的类别组合，这种机制使得模型学会不同 meta-task 中的共性部分，比如如何提取重要特征及比较样本相似等，忘掉 meta-task 中 task 相关部分。通过这种学习机制学到的模型，在面对新的未见过的 meta-task 时，也能较好地进行分类。</p>
<p>图 1 展示的是一个 2-way 5-shot 的示例，可以看到 meta training 阶段构建了一系列 meta-task 来让模型学习如何根据 support set 预测 batch set 中的样本的标签；meta testing 阶段的输入数据的形式与训练阶段一致（2-way 5-shot），但是会在全新的类别上构建 support set 和 batch。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-52-27-image.png"></p>
<p>▲ 图1：Few-shot Learning示例</p>
<h2 id="在图像领域的研究现状"><a href="#在图像领域的研究现状" class="headerlink" title="在图像领域的研究现状"></a><strong>在图像领域的研究现状</strong></h2><p>早期的 Few-shot Learning 算法研究多集中在图像领域，如图 2 所示，<strong>Few-shot Learning</strong> **模型大致可分为三类：**Mode Based，Metric Based 和 Optimization Based。</p>
<p> <img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-52-47-image.png"> </p>
<p>  Model Based 方法旨在通过模型结构的设计快速在少量样本上更新参数，直接建立输入 x 和预测值 P 的映射函数；Metric Based 方法通过度量 batch 集中的样本和 support 集中样本的距离，借助最近邻的思想完成分类；Optimization Based 方法认为普通的梯度下降方法难以在 few-shot 场景下拟合，因此通过调整优化方法来完成小样本分类的任务。 </p>
<h3 id="Model-Based方法"><a href="#Model-Based方法" class="headerlink" title="Model Based方法"></a><strong>Model Based方法</strong></h3><p><strong>Santoro 等人</strong> [3] 提出使用记忆增强的方法来解决 Few-shot Learning 任务。基于记忆的神经网络方法早在 2001 年被证明可以用于 meta-learning。他们通过权重更新来调节 bias，并且通过学习将表达快速缓存到记忆中来调节输出。</p>
<p>然而，利用循环神经网络的内部记忆单元无法扩展到需要对大量新信息进行编码的新任务上。因此，需要让存储在记忆中的表达既要稳定又要是元素粒度访问的，前者是说当需要时就能可靠地访问，后者是说可选择性地访问相关的信息；另外，参数数量不能被内存的大小束缚。神经图灵机（NTMs）和记忆网络就符合这种必要条件。</p>
<p>文章基于神经网络图灵机（NTMs）的思想，因为 NTMs 能通过外部存储（external memory）进行短时记忆，并能通过缓慢权值更新来进行长时记忆，NTMs 可以学习将表达存入记忆的策略，并如何用这些表达来进行预测。由此，文章方法可以快速准确地预测那些只出现过一次的数据。</p>
<p>文章基于 LSTM 等 RNN 的模型，将数据看成序列来训练，在测试时输入新的类的样本进行分类。</p>
<p>具体地，在 t 时刻，模型输入 <img src="https://www.zhihu.com/equation?tex=(x_%7Bt%7D,y_%7Bt-1%7D)" alt="[公式]"> ，也就是在当前时刻预测输入样本的类别，并在下一时刻给出真实的 label，并且添加了 external memory 存储上一次的 x 输入，这使得下一次输入后进行反向传播时，可以让 y (label) 和 x 建立联系，使得之后的 x 能够通过外部记忆获取相关图像进行比对来实现更好的预测。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-53-14-image.png">▲ 图3：Memory Augmented Model</p>
<p><em><strong>Meta Network</strong></em> [12] 的快速泛化能力源自其“快速权重”的机制，在训练过程中产生的梯度被用来作为快速权重的生成。模型包含一个 meta learner 和一个 base learner，meta learner 用于学习 meta task 之间的泛化信息，并使用 memory 机制保存这种信息，base learner 用于快速适应新的 task，并和 meta learner 交互产生预测输出。</p>
<h3 id="Metric-Based方法"><a href="#Metric-Based方法" class="headerlink" title="Metric Based方法"></a><strong>Metric Based方法</strong></h3><p>如果在 Few-shot Learning 的任务中去训练普通的基于 cross-entropy 的神经网络分类器，那么几乎肯定是会过拟合，因为神经网络分类器中有数以万计的参数需要优化。</p>
<p>相反，很多非参数化的方法（最近邻、K-近邻、Kmeans）是不需要优化参数的，因此可以在 meta-learning 的框架下构造一种可以端到端训练的 few-shot 分类器。该方法是对样本间距离分布进行建模，使得同类样本靠近，异类样本远离。下面介绍相关的方法。</p>
<p>如图 4 所示，<strong>孪生网络（Siamese Network）</strong>[4] 通过有监督的方式训练孪生网络来学习，然后重用网络所提取的特征进行 one&#x2F;few-shot 学习。</p>
<p> <img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-53-35-image.png"> </p>
<p>具体的网络是一个双路的神经网络，训练时，通过组合的方式构造不同的成对样本，输入网络进行训练，在最上层通过样本对的距离判断他们是否属于同一个类，并产生对应的概率分布。在预测阶段，孪生网络处理测试样本和支撑集之间每一个样本对，最终预测结果为支撑集上概率最高的类别。</p>
<p>相比孪生网络，<strong>匹配网络（Match Network）</strong>[2] 为支撑集和 Batch 集构建不同的编码器，最终分类器的输出是支撑集样本和 query 之间预测值的加权求和。</p>
<p>如图 5 所示，该文章也是在不改变网络模型的前提下能对未知类别生成标签，其主要创新体现在建模过程和训练过程上。对于建模过程的创新，文章提出了基于 memory 和 attention 的 matching nets，使得可以快速学习。</p>
<p>对于训练过程的创新，文章基于传统机器学习的一个原则，即训练和测试是要在同样条件下进行的，提出在训练的时候不断地让网络只看每一类的少量样本，这将和测试的过程是一致的。</p>
<p>具体地，它显式的定义一个基于支撑集 <img src="https://www.zhihu.com/equation?tex=S=%5Cleft%5C%7B+(x_%7Bi%7D,y_%7Bi%7D)+%5Cright%5C%7D_%7Bi=1%7D%5E%7B%5Cleft%7C+S+%5Cright%7C%7D" alt="[公式]"> 的分类器，对于一个新的数据 <img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D" alt="[公式]"> ，其分类概率由<img src="https://www.zhihu.com/equation?tex=%5Chat%7Bx%7D" alt="[公式]">与支撑集 S 之间的距离度量得出：</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-54-07-image.png"></p>
<p>其中 a 是基于距离度量的 attention score：</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-54-21-image.png"></p>
<p>进一步，支撑集样本 embedding 模型 g 能继续优化，并且支撑集样本应该可以用来修改测试样本的 embedding 模型 f。</p>
<p>这个可以通过如下两个方面来解决，即：<strong>1）基于双向 LSTM 学习训练集的 embedding</strong>，使得每个支撑样本的 embedding 是其它训练样本的函数；<strong>2）基于 attention-LSTM 来对测试样本 embedding</strong>，使得每个 Query 样本的 embedding 是支撑集 embedding 的函数。文章称其为 FCE (fully-conditional embedding)。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-54-44-image.png"></p>
<p>▲ 图5：Match Network</p>
<p><strong>原型网络（Prototype Network）</strong>[5] 基于这样的想法：每个类别都存在一个原型表达，该类的原型是 support set 在 embedding 空间中的均值。然后，分类问题变成在 embedding 空间中的最近邻。</p>
<p>如图 6 所示，c1、c2、c3 分别是三个类别的均值中心（称 Prototype），将测试样本 x 进行 embedding 后，与这 3 个中心进行距离计算，从而获得 x 的类别。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-54-56-image.png"></p>
<p>▲ 图6：Prototype Network</p>
<p>文章采用在 Bregman 散度下的指数族分布的混合密度估计，文章在训练时采用相对测试时更多的类别数，即训练时每个 episodes 采用 20 个类（20 way），而测试对在 5 个类（5 way）中进行，其效果相对训练时也采用 5 way 的提升了 2.5 个百分点。</p>
<p>前面介绍的几个网络结构在最终的距离度量上都使用了固定的度量方式，如 cosine，欧式距离等，这种模型结构下所有的学习过程都发生在样本的 embedding 阶段。</p>
<p>而 <em><strong>Relation Network</strong></em> [6] 认为度量方式也是网络中非常重要的一环，需要对其进行建模，所以该网络不满足单一且固定的距离度量方式，而是训练一个网络来学习（例如 CNN）距离的度量方式，在 loss 方面也有所改变，考虑到 relation network 更多的关注 relation score，更像一种回归，而非 0&#x2F;1 分类，所以使用了 MSE 取代了 cross-entropy。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-55-08-image.png"></p>
<p>▲ 图7：Relation Networks</p>
<h3 id="Optimization-Based方法"><a href="#Optimization-Based方法" class="headerlink" title="Optimization Based方法"></a><strong>Optimization Based方法</strong></h3><p><strong>Ravi 等人</strong> [7] 研究了在少量数据下，基于梯度的优化算法失败的原因，即无法直接用于 meta learning。</p>
<p>首先，这些梯度优化算法包括 momentum, adagrad, adadelta, ADAM 等，无法在几步内完成优化，特别是在非凸的问题上，多种超参的选取无法保证收敛的速度。</p>
<p>其次，不同任务分别随机初始化会影响任务收敛到好的解上。虽然 finetune 这种迁移学习能缓解这个问题，但当新数据相对原始数据偏差比较大时，迁移学习的性能会大大下降。我们需要一个系统的学习通用初始化，使得训练从一个好的点开始，它和迁移学习不同的是，它能保证该初始化能让 finetune 从一个好的点开始。</p>
<p>文章学习的是一个模型参数的更新函数或更新规则。它不是在多轮的 episodes 学习一个单模型，而是在每个 episode 学习特定的模型。</p>
<p>具体地，学习基于梯度下降的参数更新算法，采用 LSTM 表达 meta learner，用其状态表达目标分类器的参数的更新，最终学会如何在新的分类任务上，对分类器网络（learner）进行初始化和参数更新。这个优化算法同时考虑一个任务的短时知识和跨多个任务的长时知识。</p>
<p>文章设定目标为通过少量的迭代步骤捕获优化算法的泛化能力，由此 meta learner 可以训练让 learner 在每个任务上收敛到一个好的解。另外，通过捕获所有任务之前共享的基础知识，进而更好地初始化 learner。</p>
<p>以训练 miniImage 数据集为例，训练过程中，从训练集（64 个类，每类 600 个样本）中随机采样 5 个类，每个类 5 个样本，构成支撑集，去学习 learner；然后从训练集的样本（采出的 5 个类，每类剩下的样本）中采样构成 Batch 集，集合中每类有 15 个样本，用来获得 learner 的 loss，去学习 meta leaner。</p>
<p>测试时的流程一样，从测试集（16 个类，每类 600 个样本）中随机采样 5 个类，每个类 5 个样本，构成支撑集 Support Set，去学习 learner；然后从测试集剩余的样本（采出的 5 个类，每类剩下的样本）中采样构成 Batch 集，集合中每类有 15 个样本，用来获得 learner 的参数，进而得到预测的类别概率。这两个过程分别如图 8 中虚线左侧和右侧。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-55-19-image.png"></p>
<p>▲ 图8：Optimization as a model</p>
<p>meta learner 的目标是在各种不同的学习任务上学出一个模型，使得可以仅用少量的样本就能解决一些新的学习任务。这种任务的挑战是模型需要结合之前的经验和当前新任务的少量样本信息，并避免在新数据上过拟合。</p>
<p><em><strong>Finn</strong></em> [8] 提出的方法使得可以在小量样本上，用少量的迭代步骤就可以获得较好的泛化性能，而且模型是容易 fine-tine 的。而且这个方法无需关心模型的形式，也不需要为 meta learning 增加新的参数，直接用梯度下降来训练 learner。</p>
<p>文章的核心思想是学习模型的初始化参数使得在一步或几步迭代后在新任务上的精度最大化。它学的不是模型参数的更新函数或是规则，它不局限于参数的规模和模型架构（比如用 RNN 或 siamese）。它本质上也是学习一个好的特征使得可以适合很多任务（包括分类、回归、增强学习），并通过 fine-tune 来获得好的效果。</p>
<p>文章提出的方法，可以学习任意标准模型的参数，并让该模型能快速适配。他们认为，一些中间表达更加适合迁移，比如神经网络的内部特征。因此面向泛化性的表达是有益的。因为我们会基于梯度下降策略在新的任务上进行 finetune，所以目标是学习这样一个模型，它能对新的任务从之前任务上快速地进行梯度下降，而不会过拟合。事实上，是要找到一些对任务变化敏感的参数，使得当改变梯度方向，小的参数改动也会产生较大的 loss。</p>
<h2 id="在自然语言处理的研究现状"><a href="#在自然语言处理的研究现状" class="headerlink" title="在自然语言处理的研究现状"></a><strong>在自然语言处理的研究现状</strong></h2><p>早期的 Few-shot Learning 算法研究主要集中在小样本图像识别的任务上，以 MiniImage 和 Omnigraffle 两个数据集为代表。</p>
<p>近年来，在自然语言处理领域也开始出现 Few-shot Learning 的数据集和模型，相比于图像，文本的语义中包含更多的变化和噪声，我们将在本节从数据集和模型两个方面介绍 Few-shot Learning 在自然语言处理领域的进展，以及我们团队基于对话工厂平台所做的探索。</p>
<p><strong>数据集</strong></p>
<p>\1. <strong>FewRel</strong> <strong>数据集</strong> [11] 由Han等人在EMNLP 2018提出，是一个小样本关系分类数据集，包含64种关系用于训练，16种关系用于验证和20种关系用于测试，每种关系下包含700个样本。</p>
<p>\2. <strong>ARSC 数据集</strong> [10] 由 Yu 等人在 NAACL 2018 提出，取自亚马逊多领域情感分类数据，该数据集包含 23 种亚马逊商品的评论数据，对于每一种商品，构建三个二分类任务，将其评论按分数分为 5、4、 2 三档，每一档视为一个二分类任务，则产生 23<em>3&#x3D;69 个 task，然后取其中 12 个 task（4</em>3）作为测试集，其余 57 个 task 作为训练集。</p>
<p>\3. <strong>ODIC 数据集</strong>来自阿里巴巴对话工厂平台的线上日志，用户会向平台提交多种不同的对话任务，和多种不同的意图，但是每种意图只有极少数的标注数据，这形成了一个典型的 Few-shot Learning 任务，该数据集包含 216 个意图，其中 159 个用于训练，57 个用于测试。</p>
<p><strong>主要模型</strong></p>
<p><strong>Gao</strong> [9] 等人提出文本与图像的一大区别在于其多样性和噪音更大，因此提出一种基于混合注意力的原型网络结构，如图 9 所示，首先使用 instance-level 的 attention 从支撑集中选出和 query 更为贴近的实例，同时降低噪声实例所带来的影响。</p>
<p>然后 feature-level 的实例能够衡量特征空间中的哪些维度对分类更为重要，从而为每种不同的关系都生成相适应的距离度量函数，从而使模型能够有效处理特征稀疏的问题。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-55-29-image.png"></p>
<p>▲ 图9：基于混合注意力的原型网络</p>
<p><strong>Yu</strong> [10] 等人指出在图像领域的 Few-shot Learning 任务中，比如 Omniglot 和 miniImage 数据集，所有的数据都是从同一个大的数据集采样而来，也就是说所有的 meta-task 都是来自同一个领域，所以相关性是很强的。</p>
<p>所以之前的 Few-shot Learning 方法只需使用一个 meta model 即可解决剩余的 few-shot 任务。但是在现实场景当中，不同的 meta task 可能来自完全不同的领域，因此使用单独的度量方式不足以衡量所有的 meta task。</p>
<p>在这种场景下，Yu 提出使用多种度量方式融合来解跨领域的 Few-shot Learning 问题。在训练阶段，meta learner 通过任务聚类选择和结合多种度量方式来学习目标任务，不同领域的 meta task 首先通过聚类来划分，因此同一个簇内的 task 可以认为是相关的，然后在该簇中训练一个深度神经网络作为度量函数，这种机制保证了只有在同一个簇中的 task 才会共享度量函数。</p>
<p>在测试阶段，为每个 test task 使用所有度量函数的线性组合作为任务适应的度量方式。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-55-42-image.png"></p>
<h3 id="在对话工厂平台的研究和应用"><a href="#在对话工厂平台的研究和应用" class="headerlink" title="在对话工厂平台的研究和应用"></a><strong>在对话工厂平台的研究和应用</strong></h3><p>我们团队基于目前 Metric Based 方法，提出了 Encoder-Induction-Relation 的三级框架，如图 10 所示，Encoder 模块用于获取每个样本的语义表示，可以使用典型的 CNN、LSTM、Transformer 等结构，Induction 模块用于从支撑集的样本语义中归纳出类别特征，Relation 模块用于度量 query 和类别之间的语义关系，进而完成分类。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-55-58-image.png"></p>
<p>▲ 图10：Encoder-Induction-Relation三级框架</p>
<p>如表 1 所示，之前的工作往往致力于学习不同的距离度量方式，而忽视了从样本表示到类表示的建模。而在自然语言当中，由于每个人的语言习惯不同，同一个类别的不同表述往往有很多种，如果仅仅是简单加和或取平均来作为类别的表示，这些与分类无关的干扰信息就会累加，影响最终的效果。</p>
<p>因此我们的工作显式的建模了从样本表示到类表示这一能力，在 ODIC 和 ARSC 两个数据集上，超过了之前的 state-of-the-art 的模型，实验结果如表 2 所示。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-56-21-image.png"></p>
<p>▲ 表1：Metric Based方法对比</p>
<p>▲ 表2：ODIC数据集实验结果</p>
<p>此外，我们在 ODIC 数据集上逐渐增加训练数据的类别数，如图 11，在测试集上得到的效果会逐渐提升，这满足了平台级的语言理解所需要的可泛化、可持续学习的需求。</p>
<p><img src="/2021/01/19/AI/DL/Few_shot_learning/2024-03-27-09-56-33-image.png"></p>
<p>▲ 图11：ODIC数据集变化趋势</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>本文从对话工厂平台的实际问题出发，对小样本学习方法进行了系统梳理和研究，给出了 Few-shot Learning 的定义，综述了其在图像和 NLP 领域的研究现状。</p>
<p>针对 Metric Based 系列方法，我们提出了统一的 Encode-Induction-Relation 描述框架，介绍了我们团队在使用 Few-shot Learning 解决平台级自然语言理解所做的工作，即显式建模从样本表示到类表示的归纳能力。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><strong>参考文献</strong></h2><p>[1] Brenden M. Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua B. Tenenbaum. One shot learning of simple visual concepts. In CogSci, 2011.</p>
<p>[2] Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. In Advances in Neural Information Processing Systems, pages 3630–3638, 2016.</p>
<p>[3] Santoro A, Bartunov S, Botvinick M, et al. One-shot learning with memory-augmented neural networks[J]. arXiv preprint arXiv:1605.06065, [![Add to Citavi project by ArXiv ID] 2016.</p>
<p>[4] Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. “Siamese neural networks for one-shot image recognition.” ICML Deep Learning Workshop. Vol. 2. 2015.</p>
<p>[5] Snell, Jake, Kevin Swersky, and Richard Zemel. “Prototypical networks for few-shot learning.” Advances in Neural Information Processing Systems. 2017.</p>
<p>[6] Sung, Flood, et al. “Learning to compare: Relation network for few-shot learning.” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.</p>
<p>[7] Ravi, Sachin, and Hugo Larochelle. “Optimization as a model for few-shot learning.” (2016).</p>
<p>[8] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. “Model-agnostic meta-learning for fast adaptation of deep networks.” Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.</p>
<p>[9] Gao, Tianyu, et al. “Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification.” (2019).</p>
<p>[10] Yu, Mo, et al. “Diverse few-shot text classification with multiple metrics.” arXiv preprint arXiv:1805.07513 [![Add to Citavi project by ArXiv ID].</p>
<p>[11] Han, Xu, et al. “FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation.” arXiv preprint arXiv:1810.10147 [![Add to Citavi project by ArXiv ID].</p>
<p>[12] Munkhdalai, Tsendsuren, and Hong Yu. “Meta networks.” Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.</p>
<p>[13] Geng R, Li B, Li Y, et al. Few-Shot Text Classification with Induction Network[J]. arXiv preprint arXiv:1902.10482, [![Add to Citavi project by ArXiv ID] 2019.</p>
<p>[14] <a href="https://link.zhihu.com/?target=https://blog.csdn.net/qq_16234613/article/details/79902085">https://blog.csdn.net/qq_16234613&#x2F;article&#x2F;details&#x2F;79902085</a></p>
<p>[15] <a href="https://link.zhihu.com/?target=https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html%23learner-and-meta-learner">https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html#learner-and-meta-learner</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/01/19/AR_demo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/19/AR_demo/" class="post-title-link" itemprop="url">AR Demo</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-19 10:18:30" itemprop="dateCreated datePublished" datetime="2021-01-19T10:18:30+00:00">2021-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AR/" itemprop="url" rel="index"><span itemprop="name">AR</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://www.sohu.com/a/194963856_99984275">仅需6分钟，教你快速学会制作AR增强现实APP[数艺网] </a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/88871028">WebAR优秀作品分享（持续更新）</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2021/01/11/ResearchRecord/2020_AI_research/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/01/11/ResearchRecord/2020_AI_research/" class="post-title-link" itemprop="url">AI Rewind 2020</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-01-11 15:47:57" itemprop="dateCreated datePublished" datetime="2021-01-11T15:47:57+00:00">2021-01-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Annual-report/" itemprop="url" rel="index"><span itemprop="name">Annual report</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="2020-AI-Review-A-Year-of-Amazing-Papers-The-future-of-AI"><a href="#2020-AI-Review-A-Year-of-Amazing-Papers-The-future-of-AI" class="headerlink" title="2020 AI Review _ A Year of Amazing Papers _ The future of AI"></a>2020 AI Review _ A Year of Amazing Papers _ The future of AI</h2><p><a target="_blank" rel="noopener" href="https://youtu.be/DHBclF-8KwE">https://youtu.be/DHBclF-8KwE</a></p>
<p><video src="2020_AI_research/AI Rewind 2020_ A Year of Amazing Papers _ The future of AI.mp4"></video></p>
<p>[1] YOLOv4: Optimal Speed and Accuracy of Object Detection</p>
<p>[2] DeepFAceDrawing</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111101536947.png" alt="image-20210111101536947" style="zoom:33%;">

<p>[3] Learning to simulate Dynamic Enviroments with GameGAN</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185612235.png" alt="image-20210111185612235" style="zoom:33%;">

<p>4[] PULSE: self-supervised photo upsamling via latent space exploration of Generative Models</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185513008.png" alt="image-20210111185513008" style="zoom:33%;">

<p>5 Unsupervised Translate of program </p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185455091.png" alt="image-20210111185455091" style="zoom:33%;">

<p>6、PIFUHD</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185637326.png" alt="image-20210111185637326" style="zoom:33%;">

<p>7 High-resolution nerual face Wrapping of visual Effiects</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185708298.png" alt="image-20210111185708298" style="zoom:33%;">

<p>8 Swapping autoencoder for Deep image Manipulation</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185732945.png" alt="image-20210111185732945" style="zoom:33%;">

<p>9 GPT-3： language models  are few-short learning</p>
<p><img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185824064.png" alt="image-20210111185824064" style="zoom:33%;"><img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185824064.png" alt="image-20210111185824064" style="zoom:33%;"></p>
<p>10 Learning joint spatial-temporal transform for video impating (隐身术)</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185859683.png" alt="image-20210111185859683" style="zoom:33%;">

<p>11 Image GPT-Generative Pretraining from Pixers</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185916953.png" alt="image-20210111185916953" style="zoom:33%;">

<p>12 Learning  to cartoonize using White-box cartoon representations </p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185931387.png" alt="image-20210111185931387" style="zoom:50%;">

<p>13 FreezeG: freeze the discriminator : a simple baseline for fine-tuning GANs</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111185953578.png" alt="image-20210111185953578" style="zoom:33%;">

<p>14 Neral re-redner of human from a Singal Image</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190013398.png" alt="image-20210111190013398" style="zoom:33%;">

<p>15 I2L-MeshNet: Image-to-Lixel Predication Network for Accurate 3D human Pose and Mesh Estimation from  a Singal RGB Image</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190028236.png" alt="image-20210111190028236" style="zoom:33%;">

<p>16 Beyond the Nav-Graph: vision-and-language Navigation in Continuous Environments</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190053738.png" alt="image-20210111190053738" style="zoom:33%;">

<p>17 RAFT: recurrent ALL-Pairs Field Transforms for Optial Flow</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190122568.png" alt="image-20210111190122568" style="zoom:50%;">

<p>18 Crowdsampling the Plenoptic Function </p>
<p><img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190147669.png" alt="image-20210111190147669" style="zoom:33%;"><img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190147669.png" alt="image-20210111190147669" style="zoom:33%;"></p>
<p>静态图转动态角度变化gif</p>
<p>19 Old Photo Restore via Deep Latent Space Translation </p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190506154.png" alt="image-20210111190506154" style="zoom:33%;">

<p>20 Neural circuit policies enabling auditable autonomy</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190532713.png" alt="image-20210111190532713" style="zoom:33%;">

<p>21 Lifespan Age transformation Synthesis </p>
<ul>
<li>生成人脸的照片，从小孩–中年–老年</li>
</ul>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190600396.png" alt="image-20210111190600396" style="zoom:33%;">

<p>22 DeOldify</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190444872.png" alt="image-20210111190444872" style="zoom:33%;">

<p>23 COOT : Cooperative Hierarchical Transformer for Video-text representation Learning</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190654058.png" alt="image-20210111190654058" style="zoom:33%;">

<p>24 Stylized Neural Painting (图转绘画)</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190853191.png" alt="image-20210111190853191" style="zoom:33%;">

<p>25 Is a Green Screen Really Necessary for real-time Portrait Matting </p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190913375.png" alt="image-20210111190913375" style="zoom:33%;">

<p>26 ADA. Training Generative Adversarial Networks with Limited Data</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190836942.png" alt="image-20210111190836942" style="zoom:33%;">

<p>27 Improving data-driven Global weather predication using deep convolutional neural networks on a cubed Sphere</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190732275.png" alt="image-20210111190732275" style="zoom:33%;">

<p>28 BeRV: Neural Reflectance and visibility fields for relighting and view Synthesis</p>
<img src="/2021/01/11/ResearchRecord/2020_AI_research/image-20210111190716741.png" alt="image-20210111190716741" style="zoom:33%;">

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2020/12/30/ResearchRecord/Papers-Log-2020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/12/30/ResearchRecord/Papers-Log-2020/" class="post-title-link" itemprop="url">Papers-Log 2020</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-12-30 09:50:45" itemprop="dateCreated datePublished" datetime="2020-12-30T09:50:45+00:00">2020-12-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:40" itemprop="dateModified" datetime="2025-08-06T08:16:40+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Papers/" itemprop="url" rel="index"><span itemprop="name">Papers</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Papers/Years/" itemprop="url" rel="index"><span itemprop="name">Years</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>[TOC]</p>
<h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN:"></a>GAN:</h2><ul>
<li><p>StyelGAN</p>
</li>
<li><p>StyelGAN2</p>
</li>
<li></li>
</ul>
<h2 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h2><ul>
<li>FGVC</li>
</ul>
<h2 id="3D"><a href="#3D" class="headerlink" title="3D:"></a>3D:</h2><h3 id="3DFace"><a href="#3DFace" class="headerlink" title="3DFace:"></a>3DFace:</h3><p>《A Morphable Model For The Synthesis Of 3D Faces》:1999年的论文，3D 纹理人脸重建的开山之作</p>
<p>3DMM: 《Basel Face Model》 2009</p>
<p>PRNet:《Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network》</p>
<p>2DASL:《Joint 3D Face Reconstruction and Dense Face Alignment from A Single Image with 2D-Assisted Self-Supervised Learning》2019</p>
<p>《Face Alignment Across Large Poses: A 3D Solution（3DDFA）》<br>        论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.07212.pdf">https://arxiv.org/pdf/1511.07212.pdf</a><br>        代码链接：<a target="_blank" rel="noopener" href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/">http://www.cbsr.ia.ac.cn/users/xiangyuzhu/</a></p>
<p>《Multiview face capture using polarized spherical gradient illumination.》<br>《AvatarMe: Realistically Renderable 3D Facial Reconstruction “in-the-wild”》2020</p>
<p>PiFUHD:</p>
<p>【l2ZNet】Self-Supervised Adaptation of High-Fidelity Face Models for Monocular Performance Tracking</p>
<p>ref: <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_29462849/article/details/103764724">https://blog.csdn.net/qq_29462849/article/details/103764724</a></p>
<h3 id="3DBody"><a href="#3DBody" class="headerlink" title="3DBody:"></a>3DBody:</h3><p>Allen et al. 2006 《Learning a Correlated Model of Identity and Pose-dependent Body Shape Variation for Realtime Synthesis 》</p>
<p>《Mano 》MANO是一个人手的模型</p>
<p>SMPL</p>
<p>SMPL-h</p>
<p>SMPL-X</p>
<p>MGN《Multi-Garment Net: Learning to Dress 3D People from Images》</p>
<p>《3D Human Body Reconstruction from a Single Image via Volumetric Regression》</p>
<p>《Learning to Reconstruct People in Clothing From a Single RGB Camera》</p>
<p>1903.05885 [octopus]  Learning to Reconstruct People in Clothing From a Single RGB Camera.pdf</p>
<p>360tex: 《》</p>
<p>tex2Shape《》</p>
<p><a target="_blank" rel="noopener" href="http://blog.providencezhang.cn/2019/01/04/%E5%85%B3%E4%BA%8E%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA%E7%9A%84%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/#2019-11-25">关于三维重建的文献综述</a></p>
<h3 id="3D-AI"><a href="#3D-AI" class="headerlink" title="3D + AI"></a>3D + AI</h3><p>《Face-to-Parameter Translation for Game Character Auto-Creation》 网易伏羲</p>
<p><strong>当前3D换脸的技术路线思考:</strong></p>
<ul>
<li>目前的人脸复原技术，跟身体重建技术存在一定的误差，需要使用3D操作算法进行人脸的对齐</li>
<li>目前的主要技术难点是3d物体的对齐技术</li>
<li>人体重建技术SMPL(2015)，SMPL-H(2016), SMPLX(2019)等一些列最新的研究成果，偏重于身体形状的重建</li>
<li>Octopus(2019)，MGN(2019)，peelnet(2020) 等偏重于3D扫描效果的重建。（我们需要的身体重建纹理复原技术，最好是穿比基尼&#x2F;内衣情况下的重建技术，这样在进行换衣服的效果的时候，才能有效的贴合人体，并且不被上一件衣服所影响。）</li>
<li>目前还没有找到类似的研究成果，如果没有，则需要我们基于MGN&#x2F;SMPL的技术，采集我们的独有的数据库，进行专门的训练模型。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2020/11/19/Games/Paper-Game-DouZero/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/19/Games/Paper-Game-DouZero/" class="post-title-link" itemprop="url">Game DouZero Paper Learning(Todo)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-19 11:39:58" itemprop="dateCreated datePublished" datetime="2020-11-19T11:39:58+00:00">2020-11-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:39" itemprop="dateModified" datetime="2025-08-06T08:16:39+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/" itemprop="url" rel="index"><span itemprop="name">Game</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/Imperfect-Information-Game/" itemprop="url" rel="index"><span itemprop="name">Imperfect Information Game</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/DouDiZhu/" itemprop="url" rel="index"><span itemprop="name">DouDiZhu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="DouZero"><a href="#DouZero" class="headerlink" title="DouZero"></a>DouZero</h2><h3 id="DMC"><a href="#DMC" class="headerlink" title="DMC"></a>DMC</h3><p>MC + DNN(Q-table) &#x3D; &gt; DMC</p>
<h4 id="Sample-Represent"><a href="#Sample-Represent" class="headerlink" title="Sample Represent"></a>Sample Represent</h4><img title src="/2020/11/19/Games/Paper-Game-DouZero/2023-08-02-16-39-22-image.png" alt width="210">

<h4 id="Q-Net"><a href="#Q-Net" class="headerlink" title="Q-Net"></a>Q-Net</h4><img title src="/2020/11/19/Games/Paper-Game-DouZero/2023-08-02-16-33-07-image.png" alt width="279">

<h2 id="DouZero-1"><a href="#DouZero-1" class="headerlink" title="DouZero+"></a>DouZero+</h2><ul>
<li><p><strong>对手建模</strong>，对对手手牌的情况进行估计，确定对手手牌的近似概率分布。背后直觉是人类玩家会尝试预测对手卡牌来帮助他们自己做策略。由于斗地主的复杂性，在做决策时，很多行动可能是合适的。在这种情况下，分析对手的手牌将是非常重要的，因为掌握了这个信息，可以帮助智能体选择最佳的动作。</p>
</li>
<li><p><strong>教练指导</strong>，构建一个新型的教练网络来选择是否进行对局，使模型可以从更有价值的数据中进行学习，而避免浪费时间。背后直觉是斗地主的结果很大程度上依赖于自身的手牌，如果一个玩家在一开始就获得了很强大的手牌，只要他在游戏中不犯错就很难输掉对局，因此智能体很难从这种对局中学到知识。</p>
</li>
</ul>
<p><img src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-11-39-image.png"></p>
<img title src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-11-53-image.png" alt width="318">

<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="A-Opponent-Modeling"><a href="#A-Opponent-Modeling" class="headerlink" title="A Opponent Modeling"></a>A Opponent Modeling</h4><p>在DouZero框架的基础上加了预测模型，模型的输入是state，输出是下一个玩家手牌的概率。motivation很简单直接：人类玩家对弈的时候一般会猜牌，所以这里会对对手建模。</p>
<ul>
<li>(a)Decision Model就是DouZero框架后面那一部分(  a &#x3D; argmax(Q))</li>
<li>(b)Legal Label是根据局面信息（自己的手牌和已经打出来的牌），据此可以过滤掉不可能的状态</li>
</ul>
<p>作者首先做了一个预实验，将下一个玩家的手牌直接添加到状态特征中，其结果如图所示。</p>
<p><img src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-35-01-image.png"></p>
<p>可以看出，将下一个玩家的手牌加入到状态特征中确实可以提高智能体的表现，尤其是对农民玩家来说。作者认为农民的明显进步是由于了解下一个玩家的手牌不仅可以帮助农民选择地主要不起的手牌，而且还可以帮助农民选择可以更好地配合队友的手牌。而对于地主来说，知道下一个玩家的手牌确实有助于做出决定，但如果手很弱，即使拥有这样的信息也没有很大的帮助。综上所述，本研究的预实验结果表明，引入下一个玩家的手牌的显式表示可以提高斗地主人工智能的性能。（特别是农民角色） </p>
<h4 id="B-Coach-Network"><a href="#B-Coach-Network" class="headerlink" title="B Coach Network"></a>B Coach Network</h4><h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><h4 id="Oppo-Modeling"><a href="#Oppo-Modeling" class="headerlink" title="Oppo Modeling"></a>Oppo Modeling</h4><p><img src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-36-52-image.png"></p>
<h4 id="CoachNet"><a href="#CoachNet" class="headerlink" title="CoachNet"></a>CoachNet</h4><p><img src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-37-06-image.png"></p>
<h4 id="Both方法"><a href="#Both方法" class="headerlink" title="Both方法"></a>Both方法</h4><p><img src="/2020/11/19/Games/Paper-Game-DouZero/2023-10-25-15-40-27-image.png"></p>
<h3 id="ref"><a href="#ref" class="headerlink" title="ref"></a>ref</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41960890/article/details/127471648">【论文阅读】DouZero+: Improving DouDizhu AI by Opponent Modeling and Coach-guided Learning_见见大魔王的博客-CSDN博客</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/498150267">[知乎]斗地主AI：DouZero+</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2020/11/09/Games/Paper-Game-DDZ-DeltaDou/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/11/09/Games/Paper-Game-DDZ-DeltaDou/" class="post-title-link" itemprop="url">Game - DouDiZhu DeltaDou (Todo)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-09 11:39:58" itemprop="dateCreated datePublished" datetime="2020-11-09T11:39:58+00:00">2020-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:39" itemprop="dateModified" datetime="2025-08-06T08:16:39+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/" itemprop="url" rel="index"><span itemprop="name">Game</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/DouDiZhu/" itemprop="url" rel="index"><span itemprop="name">DouDiZhu</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>DeltaDou</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/21/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/21/">21</a><span class="page-number current">22</span><a class="page-number" href="/page/23/">23</a><span class="space">&hellip;</span><a class="page-number" href="/page/33/">33</a><a class="extend next" rel="next" href="/page/23/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon Shi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">322</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">269</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Simon Shi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
