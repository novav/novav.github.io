<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"novav.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="[TOC] 计算机视觉领域 https:&#x2F;&#x2F;www.paperswithcode.com&#x2F;area&#x2F;computer-vision UMD Faces 面部数据集UMD Faces DatasetUMD Faces Dataset 是一个面部数据集，主要用于身份鉴定研究，它拥有 8501 个主题共计 367,920 个面孔。该数据集分为静止图像和视频帧两部分，其中静止图像包含 367,888 张图">
<meta property="og:type" content="article">
<meta property="og:title" content="计算机视觉--视觉3D数据库">
<meta property="og:url" content="https://novav.github.io/2020/04/07/CV/CV-datasets/index.html">
<meta property="og:site_name" content="Simon Shi的小站">
<meta property="og:description" content="[TOC] 计算机视觉领域 https:&#x2F;&#x2F;www.paperswithcode.com&#x2F;area&#x2F;computer-vision UMD Faces 面部数据集UMD Faces DatasetUMD Faces Dataset 是一个面部数据集，主要用于身份鉴定研究，它拥有 8501 个主题共计 367,920 个面孔。该数据集分为静止图像和视频帧两部分，其中静止图像包含 367,888 张图">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://novav.github.io/2020/04/07/CV/CV-datasets/image00040.jpg">
<meta property="article:published_time" content="2020-04-07T16:36:57.000Z">
<meta property="article:modified_time" content="2025-08-06T08:16:38.277Z">
<meta property="article:author" content="Simon Shi">
<meta property="article:tag" content="CV">
<meta property="article:tag" content="Face Recongnition">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://novav.github.io/2020/04/07/CV/CV-datasets/image00040.jpg">

<link rel="canonical" href="https://novav.github.io/2020/04/07/CV/CV-datasets/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>计算机视觉--视觉3D数据库 | Simon Shi的小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Simon Shi的小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能，机器学习， 强化学习，大模型，自动驾驶</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2020/04/07/CV/CV-datasets/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          计算机视觉--视觉3D数据库
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-07 16:36:57" itemprop="dateCreated datePublished" datetime="2020-04-07T16:36:57+00:00">2020-04-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index"><span itemprop="name">CV</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Datasets/" itemprop="url" rel="index"><span itemprop="name">Datasets</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/Datasets/" itemprop="url" rel="index"><span itemprop="name">Datasets</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/Datasets/3D/" itemprop="url" rel="index"><span itemprop="name">3D</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>[TOC]</p>
<p>计算机视觉领域</p>
<p><a target="_blank" rel="noopener" href="https://www.paperswithcode.com/area/computer-vision">https://www.paperswithcode.com/area/computer-vision</a></p>
<h2 id="UMD-Faces-面部数据集"><a href="#UMD-Faces-面部数据集" class="headerlink" title="UMD Faces 面部数据集"></a>UMD Faces 面部数据集</h2><h3 id="UMD-Faces-Dataset"><a href="#UMD-Faces-Dataset" class="headerlink" title="UMD Faces Dataset"></a>UMD Faces Dataset</h3><p>UMD Faces Dataset 是一个面部数据集，主要用于身份鉴定研究，它拥有 8501 个主题共计 367,920 个面孔。该数据集分为静止图像和视频帧两部分，其中静止图像包含 367,888 张图，共计 8277 个主题；视频帧则包含 22,000 个主题视频，共计 370 万个带注释的视频帧。</p>
<p><a target="_blank" rel="noopener" href="https://hyper.ai/datasets/5537">https://hyper.ai/datasets/5537</a></p>
<h2 id="3D-Face"><a href="#3D-Face" class="headerlink" title="3D Face"></a>3D Face</h2><h3 id="300W"><a href="#300W" class="headerlink" title="300W"></a>300W</h3><p>300 Faces In-the-Wild Challenge (300-W)</p>
<p>官网介绍：<a target="_blank" rel="noopener" href="https://ibug.doc.ic.ac.uk/resources/300-W/">https://ibug.doc.ic.ac.uk/resources/300-W/</a></p>
<p>中文介绍：<a target="_blank" rel="noopener" href="https://blog.csdn.net/lgh0824/article/details/88536215">https://blog.csdn.net/lgh0824/article/details/88536215</a></p>
<h3 id="3DDFA的生成数据"><a href="#3DDFA的生成数据" class="headerlink" title="3DDFA的生成数据"></a>3DDFA的生成数据</h3><p><a target="_blank" rel="noopener" href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm">http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm</a></p>
<p>300W-3D<br>300W-3D-Face</p>
<p>300W-LP 合成了300W的大姿态人脸图像。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[300W-3D]: https://drive.google.com/file/d/0B7OEHD3T4eCkRFRPSXdFWEhRdlE/view?usp=sharing </span><br><span class="line">[300W-3D-Face]: https://drive.google.com/file/d/0B7OEHD3T4eCkZmgzUWZfd2FVVWs/view?usp=sharing </span><br><span class="line">[300W-LP]: https://drive.google.com/file/d/0B7OEHD3T4eCkVGs0TkhUWFN6N1k/view?usp=sharing</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/Database/AFLW2000-3D.zip">AFLW2000-3D</a> </p>
<ul>
<li><p>项目：3DDFA</p>
<p>  AFLW2000-3D由AFLW数据库的前2000张图片及其三维信息组成。三维信息由3DMM重建（Blanz et.al A morphable model for the synthesis of 3d faces, SIGGRAPH’99）得到，并且包含68个特征点的三维信息。该数据库的三维数据精准度存在争议。<br>  ————————————————</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/media/simon/新加卷1/dataset/3d_face/AFLW2000/</span><br><span class="line">image00040.jpg</span><br><span class="line">image00040.mat</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">具体包含以下内容：</span><br><span class="line"></span><br><span class="line">1）pt2d：21个二维点</span><br><span class="line">2）Illum_Para：1×10 光照参数</span><br><span class="line">3）Color_Para：1×7 颜色参数</span><br><span class="line">4）Tex_Para： 199×1 纹理参数</span><br><span class="line">5）Shape Para： 199×1 形状参数</span><br><span class="line">6）Exp_Para： 29×1 表情参数</span><br><span class="line">7）Pose： 1×7 姿态参数，分别为：pitch， yaw， roll， translation(dx，dy，dz)，scale</span><br><span class="line">8）pt3d_68： 3×68 三维特征点</span><br><span class="line">————————————————</span><br><span class="line">原文链接：https://blog.csdn.net/AuntieLee/article/details/105940291</span><br></pre></td></tr></table></figure>

<p><img src="/2020/04/07/CV/CV-datasets/image00040.jpg" title alt="image00040" width="196">image00040.mat</p>
<h2 id="3D-Body"><a href="#3D-Body" class="headerlink" title="3D Body"></a>3D Body</h2><h3 id="Human-3-6M"><a href="#Human-3-6M" class="headerlink" title="Human 3.6M"></a>Human 3.6M</h3><ul>
<li><p>常用于3D人体姿态估计</p>
</li>
<li><p>11个人</p>
</li>
</ul>
<p>Diversity and Size</p>
<ul>
<li>• 3.6 million 3D human poses and corresponding images</li>
<li>• 11 professional actors (6 male, 5 female)</li>
<li>• 17 scenarios (discussion, smoking, taking photo, talking on the phone…)</li>
</ul>
<p>Accurate Capture and Synchronization</p>
<ul>
<li>• High-resolution 50Hz video from 4 calibrated cameras</li>
<li>• Accurate 3D joint positions and joint angles from high-speed motion capture system</li>
<li>• Pixel-level 24 body part labels for each configuration</li>
<li>• Time-of-flight range data</li>
<li>• 3D laser scans of the actors</li>
<li>• Accurate background subtraction, person bounding boxes</li>
</ul>
<p>Support for Development</p>
<ul>
<li>• Precomputed image descriptors</li>
<li>• Software for visualization and discriminative human pose prediction</li>
<li>• Performance evaluation on withheld test set</li>
</ul>
<h3 id="FAUST-2014"><a href="#FAUST-2014" class="headerlink" title="FAUST 2014"></a>FAUST 2014</h3><ul>
<li>300个2D扫描人体数据</li>
</ul>
<table>
<thead>
<tr>
<th>数据库</th>
<th>网址</th>
<th>header 2</th>
</tr>
</thead>
<tbody><tr>
<td>FAUST</td>
<td><a target="_blank" rel="noopener" href="http://faust.is.tue.mpg.de/">http://faust.is.tue.mpg.de/</a></td>
<td>A data set containing 300 real, high-resolution human scans, with automatically computed ground-truth correspondences. <strong>一个包含300个真实</strong>，高分辨率人体扫描的数据集，具有自动计算的地面实况对应关系（Max Planck Tubingen）</td>
</tr>
<tr>
<td>Dynamic FAUST</td>
<td></td>
<td>3D人体动态数据库, 提供40,000个原始网格和对齐网格的数据集</td>
</tr>
</tbody></table>
<h3 id="SAESAR"><a href="#SAESAR" class="headerlink" title="SAESAR"></a>SAESAR</h3><p>SMPL使用的数据集</p>
<p>CAESAR <a target="_blank" rel="noopener" href="http://store.sae.org/caesar/">http://store.sae.org/caesar/</a> 美国和欧洲的表面人体测量资源项目<br>10,000美元，2,400名男性和女性</p>
<h3 id="Dyma"><a href="#Dyma" class="headerlink" title="Dyma"></a>Dyma</h3><p><a target="_blank" rel="noopener" href="http://dyna.is.tue.mpg.de/">http://dyna.is.tue.mpg.de/</a></p>
<p>使用十个对象的40,000多次扫描</p>
<h3 id="TOSCA"><a href="#TOSCA" class="headerlink" title="TOSCA"></a>TOSCA</h3><p>dataset contains synthetic meshes of fixed topology with artist-defined deformations.</p>
<p>数据集包含具有艺术家定义的变形的固定拓扑的合成网格。</p>
<p> synthetic dataset that is widely used for evaluation of mesh registration methods. It provides 80 artificially created meshes of <strong>animals and people</strong> (with 3 subjects in a dozen different poses each). </p>
<h3 id="SHREC"><a href="#SHREC" class="headerlink" title="SHREC"></a>SHREC</h3><p>为TOSCA添加了各种⼈造噪声⽹格，</p>
<h3 id="SCAPE"><a href="#SCAPE" class="headerlink" title="SCAPE"></a>SCAPE</h3><h3 id="Buff"><a href="#Buff" class="headerlink" title="Buff"></a>Buff</h3><p><a target="_blank" rel="noopener" href="http://buff.is.tue.mpg.de/">http://buff.is.tue.mpg.de/</a></p>
<p>Given static 3D scans or 3D scan sequences (in pink), we estimate the naked shape under clothing (beige)</p>
<p>给定3D扫描序列，我们的模型评估不穿衣服的人体。</p>
<p>includes high resolution 3D scan sequences of 3 males and 3 females in different clothing styles.</p>
<p>3男3女的高分辨率的穿不同衣服的数据集。</p>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><h3 id="开源数据库统计："><a href="#开源数据库统计：" class="headerlink" title="开源数据库统计："></a>开源数据库统计：</h3><p> <a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_37570854/article/details/88736189">https://blog.csdn.net/m0_37570854/article/details/88736189</a></p>
<h3 id="3D人体重建技术："><a href="#3D人体重建技术：" class="headerlink" title="3D人体重建技术："></a>3D人体重建技术：</h3><p><a target="_blank" rel="noopener" href="https://graphics.soe.ucsc.edu/data/BodyModels/index.html">https://graphics.soe.ucsc.edu/data/BodyModels/index.html</a></p>
<ul>
<li>SCAPE - (<a target="_blank" rel="noopener" href="http://ai.stanford.edu/~drago/Projects/scape/scape.html">paper website</a>) (<a target="_blank" rel="noopener" href="https://graphics.soe.ucsc.edu/private/data/SCAPE/index.html">data</a>) - The correspondence between the meshes above is identical to that in SCAPE</li>
<li>FAUST - (<a target="_blank" rel="noopener" href="http://faust.is.tue.mpg.de/overview">website-data-code</a>) - different people in different poses</li>
<li>BodyLabs - (<a target="_blank" rel="noopener" href="http://www.bodylabs.com/technology.html">web</a>) - Company commercializing body model tools</li>
<li>MPI - (<a target="_blank" rel="noopener" href="http://gvvperfcapeva.mpi-inf.mpg.de/public/ScanDB/">website-data-code</a>) - different people in different poses from a different MPI lab</li>
<li>MPII Human Shape (<a target="_blank" rel="noopener" href="http://humanshape.mpi-inf.mpg.de/">website-data-code</a>) - CAESAE dataset processed by MPI</li>
<li><strong>CAESAR</strong> - (<a target="_blank" rel="noopener" href="http://store.sae.org/caesar/">website-data</a>) - Sells complete CAESAR dataset with more measurements and authorized to provide commercial license.</li>
<li>other - (<a target="_blank" rel="noopener" href="https://graphics.soe.ucsc.edu/data/">web</a>) - Other data I find around my lab that might be helpful to someone</li>
</ul>
<h1 id="Web-Face-Recognition-Training-Datasets-Updating"><a href="#Web-Face-Recognition-Training-Datasets-Updating" class="headerlink" title="Web Face Recognition Training Datasets (Updating)"></a>Web Face Recognition Training Datasets (Updating)</h1><p><a target="_blank" rel="noopener" href="https://github.com/deepinsight/insightface/wiki/Dataset-Zoo">Github-DatasetZoo</a></p>
<h3 id="CASIA-Webface-10K-ids-0-5M-images-1"><a href="#CASIA-Webface-10K-ids-0-5M-images-1" class="headerlink" title="CASIA-Webface (10K ids&#x2F;0.5M images) [1]"></a>CASIA-Webface (10K ids&#x2F;0.5M images) [1]</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1AfHdPsxJZBD8kBJeIhmq1w">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/lfluom5ybqqln02/faces_CASIA_112x112.zip?dl=0">dropbox</a></p>
<h3 id="CelebA-10K-ids-0-2M-images-2"><a href="#CelebA-10K-ids-0-2M-images-2" class="headerlink" title="CelebA (10K ids&#x2F;0.2M images) [2]"></a>CelebA (10K ids&#x2F;0.2M images) [2]</h3><h3 id="UMDFace-8K-ids-0-37M-images-3"><a href="#UMDFace-8K-ids-0-37M-images-3" class="headerlink" title="UMDFace (8K ids&#x2F;0.37M images) [3]"></a>UMDFace (8K ids&#x2F;0.37M images) [3]</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1aGutJwNWpV-lA0f_7eNsGQ">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/fv0y30mawsejweu/faces_umd.zip?dl=0">dropbox</a></p>
<h3 id="VGG2-9K-ids-3-31M-images-4"><a href="#VGG2-9K-ids-3-31M-images-4" class="headerlink" title="VGG2 (9K ids&#x2F;3.31M images) [4]"></a>VGG2 (9K ids&#x2F;3.31M images) [4]</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1c3KeLzy">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/m9pm1it7vsw3gj0/faces_vgg2_112x112.zip?dl=0">dropbox</a></p>
<h3 id="VGG2-Face-HD"><a href="#VGG2-Face-HD" class="headerlink" title="VGG2-Face HD()"></a>VGG2-Face HD()</h3><p>90G</p>
<h3 id="MS1M-IBUG-85K-ids-3-8M-images-5-6"><a href="#MS1M-IBUG-85K-ids-3-8M-images-5-6" class="headerlink" title="MS1M-IBUG (85K ids&#x2F;3.8M images) [5,6]"></a>MS1M-IBUG (85K ids&#x2F;3.8M images) [5,6]</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1nxmSCch">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/4de5ogqj4vargsw/faces_ms1m-refine-v1_112x112.zip?dl=0">dropbox</a></p>
<h3 id="MS1M-ArcFace-85K-ids-5-8M-images-5-7-Recommend"><a href="#MS1M-ArcFace-85K-ids-5-8M-images-5-7-Recommend" class="headerlink" title="MS1M-ArcFace (85K ids&#x2F;5.8M images) [5,7] (Recommend)"></a>MS1M-ArcFace (85K ids&#x2F;5.8M images) [5,7] (Recommend)</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1S6LJZGdqcZRle1vlcMzHOQ">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/wpx6tqjf0y5mf6r/faces_ms1m-refine-v2_112x112.zip?dl=0">dropbox</a></p>
<h3 id="Asian-Celeb-94K-ids-2-8M-images-8-Recommend"><a href="#Asian-Celeb-94K-ids-2-8M-images-8-Recommend" class="headerlink" title="Asian-Celeb (94K ids&#x2F;2.8M images)[8] (Recommend)"></a>Asian-Celeb (94K ids&#x2F;2.8M images)[8] (Recommend)</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/12wSgofDy1flFf6lOyAxJRg">baidu</a> faces_glintasia.zip</p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/5cd1ppfqprjluaq/faces_glintasia.zip?dl=0">dropbox</a> faces_glintasia.zip</p>
<h3 id="DeepGlint-181K-ids-6-75M-images-8-Recommend"><a href="#DeepGlint-181K-ids-6-75M-images-8-Recommend" class="headerlink" title="DeepGlint (181K ids&#x2F;6.75M images) [8] (Recommend)"></a>DeepGlint (181K ids&#x2F;6.75M images) [8] (Recommend)</h3><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1yApUbklBgRgOyOV4o3J8Eg">baidu</a></p>
<p><a target="_blank" rel="noopener" href="https://www.dropbox.com/s/4x39o2x40rewl5l/faces_glint.zip?dl=0">dropbox</a></p>
<h3 id="IMDB-Face-59K-ids-1-7M-images-9"><a href="#IMDB-Face-59K-ids-1-7M-images-9" class="headerlink" title="IMDB-Face (59K ids&#x2F;1.7M images) [9]"></a>IMDB-Face (59K ids&#x2F;1.7M images) [9]</h3><h3 id="Celeb500k-500K-ids-50M-images-10"><a href="#Celeb500k-500K-ids-50M-images-10" class="headerlink" title="Celeb500k (500K ids&#x2F;50M images) [10]"></a>Celeb500k (500K ids&#x2F;50M images) [10]</h3><h3 id="MegaFace-672K-ids-4-7M-images-11"><a href="#MegaFace-672K-ids-4-7M-images-11" class="headerlink" title="MegaFace (672K ids&#x2F;4.7M images) [11]"></a>MegaFace (672K ids&#x2F;4.7M images) [11]</h3><h1 id="Face-Recognition-Validation-Datasets"><a href="#Face-Recognition-Validation-Datasets" class="headerlink" title="Face Recognition Validation Datasets"></a>Face Recognition Validation Datasets</h1><h3 id="CFP-FP-500-ids-7K-images-7K-pairs-12"><a href="#CFP-FP-500-ids-7K-images-7K-pairs-12" class="headerlink" title="CFP-FP (500 ids&#x2F;7K images&#x2F;7K pairs)[12]"></a>CFP-FP (500 ids&#x2F;7K images&#x2F;7K pairs)[12]</h3><h3 id="AgeDB-30-570-ids-12-240-images-6K-pairs-13-6"><a href="#AgeDB-30-570-ids-12-240-images-6K-pairs-13-6" class="headerlink" title="AgeDB-30 (570 ids&#x2F;12,240 images&#x2F;6K pairs)[13,6]"></a>AgeDB-30 (570 ids&#x2F;12,240 images&#x2F;6K pairs)[13,6]</h3><h3 id="LFW-5749-ids-13233-images-6K-pairs-14"><a href="#LFW-5749-ids-13233-images-6K-pairs-14" class="headerlink" title="LFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[14]"></a>LFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[14]</h3><h3 id="CALFW-5749-ids-13233-images-6K-pairs-15"><a href="#CALFW-5749-ids-13233-images-6K-pairs-15" class="headerlink" title="CALFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[15]"></a>CALFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[15]</h3><h3 id="CPLFW-5749-ids-13233-images-6K-pairs-16"><a href="#CPLFW-5749-ids-13233-images-6K-pairs-16" class="headerlink" title="CPLFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[16]"></a>CPLFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[16]</h3><h1 id="Face-Recognition-Image-Test-Datasets"><a href="#Face-Recognition-Image-Test-Datasets" class="headerlink" title="Face Recognition Image Test Datasets"></a>Face Recognition Image Test Datasets</h1><h3 id="MegaFace"><a href="#MegaFace" class="headerlink" title="MegaFace"></a>MegaFace</h3><h3 id="IJB-IJB-B-IJB-C"><a href="#IJB-IJB-B-IJB-C" class="headerlink" title="IJB (IJB-B, IJB-C)"></a>IJB (IJB-B, IJB-C)</h3><h3 id="TrillionPairs"><a href="#TrillionPairs" class="headerlink" title="TrillionPairs"></a>TrillionPairs</h3><h3 id="NIST"><a href="#NIST" class="headerlink" title="NIST"></a>NIST</h3><h1 id="Face-Recognition-Video-Test-Datasets"><a href="#Face-Recognition-Video-Test-Datasets" class="headerlink" title="Face Recognition Video Test Datasets"></a>Face Recognition Video Test Datasets</h1><h3 id="YTF"><a href="#YTF" class="headerlink" title="YTF"></a>YTF</h3><h3 id="IQIYI"><a href="#IQIYI" class="headerlink" title="IQIYI"></a>IQIYI</h3><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>[1] Dong Yi, Zhen Lei, Shengcai Liao, Stan Z. Li. Learning Face Representation from Scratch. arXiv:1411.7923, 2014.</p>
<p>[2] Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang. Deep Learning Face Attributes in the Wild, ICCV, 2015.</p>
<p>[3] Bansal Ankan, Nanduri Anirudh, Castillo Carlos D, Ranjan Rajeev, Chellappa, Rama. UMDFaces: An Annotated Face Dataset for Training Deep Networks, arXiv:1611.01484v2, 2016.</p>
<p>[4] Qiong Cao, Li Shen, Weidi Xie, Omkar M. Parkhi, Andrew Zisserman. VGGFace2: A dataset for recognising faces across pose and age. FG, 2018.</p>
<p>[5] Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, Jianfeng Gao. Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. ECCV, 2016.</p>
<p>[6] Jiankang Deng, Yuxiang Zhou, Stefanos Zafeiriou. Marginal loss for deep face recognition, CVPRW, 2017.</p>
<p>[7] Jiankang Deng, Jia Guo, Stefanos Zafeiriou. Arcface: Additive angular margin loss for deep face recognition, arXiv:1801.07698, 2018.</p>
<p>[8] <a target="_blank" rel="noopener" href="http://trillionpairs.deepglint.com/">http://trillionpairs.deepglint.com/</a></p>
<p>[9] Wang Fei, Chen Liren, Li Cheng, Huang Shiyao, Chen Yanjie, Qian Chen, Loy, Chen Change. The Devil of Face Recognition is in the Noise, ECCV, 2018.</p>
<p>[10] Cao Jiajiong, Li Yingming, Zhang Zhongfei, Celeb-500K: A Large Training Dataset for Face Recognition, ICIP, 2018.</p>
<p>[11] Nech Aaron, Kemelmacher-Shlizerman Ira, Level Playing Field For Million Scale Face Recognition, CVPR, 2017.</p>
<p>[12] Sengupta Soumyadip, Chen Jun-Cheng, Castillo Carlos, Patel Vishal M, Chellappa Rama, Jacobs David W, Frontal to profile face verification in the wild, WACV, 2016.</p>
<p>[13] Moschoglou, Stylianos and Papaioannou, Athanasios and Sagonas, Christos and Deng, Jiankang and Kotsia, Irene and Zafeiriou, Stefanos, Agedb: the first manually collected, in-the-wild age database, CVPRW, 2017.</p>
<p>[14] Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller. Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments, 2007.</p>
<p>[15] Zheng Tianyue, Deng Weihong, Hu Jiani, Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments, arXiv:1708.08197, 2017.</p>
<p>[16] Zheng, Tianyue, and Weihong Deng. Cross-Pose LFW: A Database for Studying Cross-Pose Face Recognition in Unconstrained Environments, 2018.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CV/" rel="tag"># CV</a>
              <a href="/tags/Face-Recongnition/" rel="tag"># Face Recongnition</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/03/26/CV_3D/CV-3D-Model-BodyClothing/" rel="prev" title="CV-3D-Model-Apply">
      <i class="fa fa-chevron-left"></i> CV-3D-Model-Apply
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/04/07/CV/CV-Datasets-Animal/" rel="next" title="计算机视觉--视觉数据库--The Oxford-IIIT 宠物图像数据">
      计算机视觉--视觉数据库--The Oxford-IIIT 宠物图像数据 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#UMD-Faces-%E9%9D%A2%E9%83%A8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.</span> <span class="nav-text">UMD Faces 面部数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#UMD-Faces-Dataset"><span class="nav-number">1.1.</span> <span class="nav-text">UMD Faces Dataset</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3D-Face"><span class="nav-number">2.</span> <span class="nav-text">3D Face</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#300W"><span class="nav-number">2.1.</span> <span class="nav-text">300W</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3DDFA%E7%9A%84%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE"><span class="nav-number">2.2.</span> <span class="nav-text">3DDFA的生成数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3D-Body"><span class="nav-number">3.</span> <span class="nav-text">3D Body</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Human-3-6M"><span class="nav-number">3.1.</span> <span class="nav-text">Human 3.6M</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FAUST-2014"><span class="nav-number">3.2.</span> <span class="nav-text">FAUST 2014</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SAESAR"><span class="nav-number">3.3.</span> <span class="nav-text">SAESAR</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dyma"><span class="nav-number">3.4.</span> <span class="nav-text">Dyma</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TOSCA"><span class="nav-number">3.5.</span> <span class="nav-text">TOSCA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SHREC"><span class="nav-number">3.6.</span> <span class="nav-text">SHREC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SCAPE"><span class="nav-number">3.7.</span> <span class="nav-text">SCAPE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Buff"><span class="nav-number">3.8.</span> <span class="nav-text">Buff</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A"><span class="nav-number">4.</span> <span class="nav-text">参考资料：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%9F%E8%AE%A1%EF%BC%9A"><span class="nav-number">4.1.</span> <span class="nav-text">开源数据库统计：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3D%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF%EF%BC%9A"><span class="nav-number">4.2.</span> <span class="nav-text">3D人体重建技术：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Web-Face-Recognition-Training-Datasets-Updating"><span class="nav-number"></span> <span class="nav-text">Web Face Recognition Training Datasets (Updating)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CASIA-Webface-10K-ids-0-5M-images-1"><span class="nav-number">0.1.</span> <span class="nav-text">CASIA-Webface (10K ids&#x2F;0.5M images) [1]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CelebA-10K-ids-0-2M-images-2"><span class="nav-number">0.2.</span> <span class="nav-text">CelebA (10K ids&#x2F;0.2M images) [2]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#UMDFace-8K-ids-0-37M-images-3"><span class="nav-number">0.3.</span> <span class="nav-text">UMDFace (8K ids&#x2F;0.37M images) [3]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG2-9K-ids-3-31M-images-4"><span class="nav-number">0.4.</span> <span class="nav-text">VGG2 (9K ids&#x2F;3.31M images) [4]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG2-Face-HD"><span class="nav-number">0.5.</span> <span class="nav-text">VGG2-Face HD()</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MS1M-IBUG-85K-ids-3-8M-images-5-6"><span class="nav-number">0.6.</span> <span class="nav-text">MS1M-IBUG (85K ids&#x2F;3.8M images) [5,6]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MS1M-ArcFace-85K-ids-5-8M-images-5-7-Recommend"><span class="nav-number">0.7.</span> <span class="nav-text">MS1M-ArcFace (85K ids&#x2F;5.8M images) [5,7] (Recommend)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Asian-Celeb-94K-ids-2-8M-images-8-Recommend"><span class="nav-number">0.8.</span> <span class="nav-text">Asian-Celeb (94K ids&#x2F;2.8M images)[8] (Recommend)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DeepGlint-181K-ids-6-75M-images-8-Recommend"><span class="nav-number">0.9.</span> <span class="nav-text">DeepGlint (181K ids&#x2F;6.75M images) [8] (Recommend)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IMDB-Face-59K-ids-1-7M-images-9"><span class="nav-number">0.10.</span> <span class="nav-text">IMDB-Face (59K ids&#x2F;1.7M images) [9]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Celeb500k-500K-ids-50M-images-10"><span class="nav-number">0.11.</span> <span class="nav-text">Celeb500k (500K ids&#x2F;50M images) [10]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MegaFace-672K-ids-4-7M-images-11"><span class="nav-number">0.12.</span> <span class="nav-text">MegaFace (672K ids&#x2F;4.7M images) [11]</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Face-Recognition-Validation-Datasets"><span class="nav-number"></span> <span class="nav-text">Face Recognition Validation Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CFP-FP-500-ids-7K-images-7K-pairs-12"><span class="nav-number">0.1.</span> <span class="nav-text">CFP-FP (500 ids&#x2F;7K images&#x2F;7K pairs)[12]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AgeDB-30-570-ids-12-240-images-6K-pairs-13-6"><span class="nav-number">0.2.</span> <span class="nav-text">AgeDB-30 (570 ids&#x2F;12,240 images&#x2F;6K pairs)[13,6]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#LFW-5749-ids-13233-images-6K-pairs-14"><span class="nav-number">0.3.</span> <span class="nav-text">LFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[14]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CALFW-5749-ids-13233-images-6K-pairs-15"><span class="nav-number">0.4.</span> <span class="nav-text">CALFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[15]</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPLFW-5749-ids-13233-images-6K-pairs-16"><span class="nav-number">0.5.</span> <span class="nav-text">CPLFW (5749 ids&#x2F;13233 images&#x2F;6K pairs)[16]</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Face-Recognition-Image-Test-Datasets"><span class="nav-number"></span> <span class="nav-text">Face Recognition Image Test Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MegaFace"><span class="nav-number">0.1.</span> <span class="nav-text">MegaFace</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IJB-IJB-B-IJB-C"><span class="nav-number">0.2.</span> <span class="nav-text">IJB (IJB-B, IJB-C)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TrillionPairs"><span class="nav-number">0.3.</span> <span class="nav-text">TrillionPairs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NIST"><span class="nav-number">0.4.</span> <span class="nav-text">NIST</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Face-Recognition-Video-Test-Datasets"><span class="nav-number"></span> <span class="nav-text">Face Recognition Video Test Datasets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#YTF"><span class="nav-number">0.1.</span> <span class="nav-text">YTF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IQIYI"><span class="nav-number">0.2.</span> <span class="nav-text">IQIYI</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number"></span> <span class="nav-text">Reference</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon Shi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">322</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">269</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Simon Shi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
