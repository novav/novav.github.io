<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"novav.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="开源3D人脸重建项目整理[TOC] 本文主要总结了经典3D人脸重建开源算法，如有遗漏请大家提醒补充。 〇、基础1. 3DMM 19993D Morphable Model 《A Morphable Model For The Synthesis Of 3D Faces》 1999 提出人脸的一种线性表示方法 所有三维人脸是已经进行**稠密对齐(3D face registration)**的，即所">
<meta property="og:type" content="article">
<meta property="og:title" content="CV-3D-Face-Model">
<meta property="og:url" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/index.html">
<meta property="og:site_name" content="Simon Shi的小站">
<meta property="og:description" content="开源3D人脸重建项目整理[TOC] 本文主要总结了经典3D人脸重建开源算法，如有遗漏请大家提醒补充。 〇、基础1. 3DMM 19993D Morphable Model 《A Morphable Model For The Synthesis Of 3D Faces》 1999 提出人脸的一种线性表示方法 所有三维人脸是已经进行**稠密对齐(3D face registration)**的，即所">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210230052577.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/2024-03-18-16-33-15-image.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/vertex_3d.jpg">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190858197.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210191137165.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210193653717.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210223741952.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210173005834.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/fig1.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/sfm_shape_3448_mesh.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/4dfm_color_sample.jpg">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/4dfm_shape.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210185718650.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210185852990.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190114627.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190240938.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/3-Figure1-1.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210174434478.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/2-Figure2-1.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200731170617469.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200731170640042.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/55403032-76960580-5587-11e9-926b-4be4d72c3e3f.gif">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/55403128-b3fa9300-5587-11e9-92f0-b7733431ddc9.gif">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/4-Figure2-1.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/2-Figure1-1.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/avatarme_method.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/avatarme_teaser.png">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/proc_specAlbs.gif">
<meta property="og:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/6-Figure4-1.png">
<meta property="article:published_time" content="2020-02-10T17:21:48.000Z">
<meta property="article:modified_time" content="2025-08-06T08:16:38.357Z">
<meta property="article:author" content="Simon Shi">
<meta property="article:tag" content="3DMM">
<meta property="article:tag" content="3D Face">
<meta property="article:tag" content="PRNet">
<meta property="article:tag" content="3DDFA">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210230052577.png">

<link rel="canonical" href="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>CV-3D-Face-Model | Simon Shi的小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Simon Shi的小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能，机器学习， 强化学习，大模型，自动驾驶</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2020/02/10/CV_3D/CV-3D-Face-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CV-3D-Face-Model
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-02-10 17:21:48" itemprop="dateCreated datePublished" datetime="2020-02-10T17:21:48+00:00">2020-02-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:38" itemprop="dateModified" datetime="2025-08-06T08:16:38+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV-3D/" itemprop="url" rel="index"><span itemprop="name">CV_3D</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV-3D/3D-Face/" itemprop="url" rel="index"><span itemprop="name">3D Face</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="开源3D人脸重建项目整理"><a href="#开源3D人脸重建项目整理" class="headerlink" title="开源3D人脸重建项目整理"></a>开源3D人脸重建项目整理</h1><p>[TOC]</p>
<p>本文主要总结了经典3D人脸重建开源算法，如有遗漏请大家提醒补充。</p>
<h2 id="〇、基础"><a href="#〇、基础" class="headerlink" title="〇、基础"></a>〇、基础</h2><h3 id="1-3DMM-1999"><a href="#1-3DMM-1999" class="headerlink" title="1. 3DMM 1999"></a>1. 3DMM 1999</h3><p>3D Morphable Model</p>
<p>《A Morphable Model For The Synthesis Of 3D Faces》 1999</p>
<p>提出人脸的一种线性表示方法</p>
<p>所有三维人脸是已经进行**稠密对齐(3D face registration)**的，即所有的三维人脸都能用相同的点云数或面片数来表示，且相同序号的点代表相同的语义</p>
<p>The model has 53K vertices and 106K faces.</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/likewind1993/article/details/81455882">3D 人脸建模  介绍 + code</a></p>
<p><a target="_blank" rel="noopener" href="https://tensors.space/2020/01/3DMM%E7%9A%84%E4%BC%A0%E7%BB%9F%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/">3DMM的传统优化方法 | 阮明康</a></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210230052577.png" alt="image-20200210230052577"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">split_coeff</span><span class="params">(self, coeffs)</span>:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Return:</span><br><span class="line">        coeffs_dict     -- a dict of torch.tensors</span><br><span class="line"></span><br><span class="line">    Parameters:</span><br><span class="line">        coeffs          -- torch.tensor, <span class="title function_">size</span> <span class="params">(B, <span class="number">256</span>)</span></span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    id_coeffs = coeffs[:, :<span class="number">80</span>]</span><br><span class="line">    exp_coeffs = coeffs[:, <span class="number">80</span>: <span class="number">144</span>]</span><br><span class="line">    tex_coeffs = coeffs[:, <span class="number">144</span>: <span class="number">224</span>]</span><br><span class="line">    angles = coeffs[:, <span class="number">224</span>: <span class="number">227</span>]</span><br><span class="line">    gammas = coeffs[:, <span class="number">227</span>: <span class="number">254</span>]</span><br><span class="line">    translations = coeffs[:, <span class="number">254</span>:]</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&#x27;id&#x27;</span>: id_coeffs,</span><br><span class="line">        <span class="string">&#x27;exp&#x27;</span>: exp_coeffs,</span><br><span class="line">        <span class="string">&#x27;tex&#x27;</span>: tex_coeffs,</span><br><span class="line">        <span class="string">&#x27;angle&#x27;</span>: angles,</span><br><span class="line">        <span class="string">&#x27;gamma&#x27;</span>: gammas,</span><br><span class="line">        <span class="string">&#x27;trans&#x27;</span>: translations</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-BFM模型"><a href="#2-BFM模型" class="headerlink" title="2.BFM模型"></a>2.BFM模型</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ling_76539446/article/details/102886398">BFM模型介绍及可视化实现（C++）</a></p>
<p>Basel Face Model是一个开源的人脸 <a target="_blank" rel="noopener" href="http://www.wityx.com/database/">数据库</a>，其基本原理是3DMM，因此其便是在PCA的基础上进行存储的。 目前有多个版本的数据库（2009，2017， 2022）。 官方网站：2009，2017</p>
<h4 id="数据内容（以2009版本为例）"><a href="#数据内容（以2009版本为例）" class="headerlink" title="数据内容（以2009版本为例）"></a>数据内容（以2009版本为例）</h4><p>01_MorphableModel.mat（数据主体）</p>
<p>​    BFM模型由53490个顶点构成，其shape&#x2F;texture的数据长度为160470（53490*3），因为其排列方式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shape<span class="punctuation">:</span> x_1<span class="punctuation">,</span> y_1<span class="punctuation">,</span> z_1<span class="punctuation">,</span> x_2<span class="punctuation">,</span> y_2<span class="punctuation">,</span> z_2<span class="punctuation">,</span> ...<span class="punctuation">,</span> x_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> y_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> z_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span></span><br><span class="line">texture<span class="punctuation">:</span> r_1<span class="punctuation">,</span> g_1<span class="punctuation">,</span> b_1<span class="punctuation">,</span> r_2<span class="punctuation">,</span> g_2<span class="punctuation">,</span> b_2<span class="punctuation">,</span> ...<span class="punctuation">,</span> r_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> g_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span><span class="punctuation">,</span> b_<span class="punctuation">&#123;</span><span class="number">53490</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>.h5文件与.mat文件对应关系</p>
<p>​    <em>[注] .h5文件中的tl数量与.mat数量不同，主成分方差的值也不同，且shape的值是.mat中shape值的0.001倍（见<code>/shape/representer/length-unit</code>）。</em></p>
<p>Matlab脚本</p>
<p>​    建议阅读<code>script_gen_random_head.m</code>文件，该脚本实现了如何生成随机脸，从中我们可以学习到BFM模型的使用方法。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/2024-03-18-16-33-15-image.png"></p>
<h2 id="一、单图三维人脸重建开源算法"><a href="#一、单图三维人脸重建开源算法" class="headerlink" title="一、单图三维人脸重建开源算法"></a>一、单图三维人脸重建开源算法</h2><p>单图三维人脸重建代码，指根据一张二维人脸图像，恢复与之对应的三维人脸（包括形状和纹理），一些算法提供了训练代码及网络框架，一些算法仅提供了测试接口。</p>
<p>目前单图三维人脸重建主要的发展方向有两种，一种是基于多任务的三维人脸重建，在三维人脸重建过程的同时完成其他与人脸有关的任务，例如，人脸识别，人脸对齐，特征点定位等，以同时提高多任务的效果。另一种，期望重建出精细化的三维人脸，包括对表情和细节的恢复。</p>
<h3 id="1-3DDFA-CVPR-2016："><a href="#1-3DDFA-CVPR-2016：" class="headerlink" title="1.3DDFA CVPR 2016："></a>1.<a target="_blank" rel="noopener" href="https://github.com/cleardusk/3DDFA">3DDFA</a> CVPR 2016：</h3><p>Github: <a target="_blank" rel="noopener" href="https://github.com/cleardusk/3DDFA">https://github.com/cleardusk/3DDFA</a></p>
<p>《<a target="_blank" rel="noopener" href="http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm">Face Alignment in Full Pose Range: A 3D Total Solution</a>》CVPR2016</p>
<p>通过恢复稠密的三维形状，以解决大姿态人脸2D特征点检测的问题。文中提到，这是第一篇利用CNN来解决3D人脸对齐问题的文章，网络通过输入PNCC图和原始二维图，输出234维参数（包括6维姿态参数[缩放参数,pitch,yaw,roll偏转角,沿xy轴的平移量]，199维3DMM形状参数，29维3DMM表情参数），利用得到的系数更新原始的PNCC图，再与原图一起进行迭代。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/vertex_3d.jpg" alt="Vertex 3D"></p>
<h3 id="2-pix2vertex-ICCV-2017："><a href="#2-pix2vertex-ICCV-2017：" class="headerlink" title="2.pix2vertex ICCV 2017："></a>2.<a target="_blank" rel="noopener" href="https://github.com/matansel/pix2vertex">pix2vertex</a> ICCV 2017：</h3><p>Github: <a target="_blank" rel="noopener" href="https://github.com/matansel/pix2vertex">https://github.com/matansel/pix2vertex</a></p>
<p>《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.10131">Unrestricted Facial Geometry Reconstruction Using Image-to-Image Translation</a>》ICCV 2017(Sela17)</p>
<p>文章通过一个Image-to-Image转换网络，从一张二维图像中恢复一张普通深度图像与一张稠密对应图。根据文中提到的迭代弹性形变算法（实际是一种非刚性三维人脸对齐方法）将2.5D图像转化3D人脸网格。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190858197.png" alt="image-20200210190858197"></p>
<h3 id="3-CNN3DMM-CVPR-2017："><a href="#3-CNN3DMM-CVPR-2017：" class="headerlink" title="3.CNN3DMM_CVPR 2017："></a>3.<a target="_blank" rel="noopener" href="https://github.com/anhttran/3dmm_cnn">CNN3DMM</a>_CVPR 2017：</h3><p>《<a target="_blank" rel="noopener" href="https://talhassner.github.io/home/publication/2017_CVPR">Regressing Robust and Discriminative 3D Morphable Models With a Very Deep Neural Network</a>》CVPR2017</p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/anhttran/3dmm_cnn">https://github.com/anhttran/3dmm_cnn</a></p>
<p>本文介绍的是上2文中恢复基础形状的方法，利用ResNet101深层神经网络框架，从in-the-wild二维图像恢复三维人脸形状，并用于识别，在文中针对训练数据量不足提出数据扩充方法，利用一篇<a target="_blank" rel="noopener" href="http://xueshu.baidu.com/usercenter/paper/show%3Fpaperid%3D63c13a0fb4d7b33dac5c0de53ea5d415%26site%3Dxueshu_se">多图三维人脸重建文章方法</a>生成足量的带标签的三维人脸，训练过程仍采用回归3DMM参数的方法。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210191137165.png" alt="image-20200210191137165"></p>
<h3 id="4-Richardson-CVPR-2017："><a href="#4-Richardson-CVPR-2017：" class="headerlink" title="4.Richardson_CVPR 2017："></a>4.<a target="_blank" rel="noopener" href="https://github.com/Cogito2012/3DFaceRecon">Richardson_CVPR 2017</a>：</h3><p>Github: <a target="_blank" rel="noopener" href="https://github.com/Cogito2012/3DFaceRecon">https://github.com/Cogito2012/3DFaceRecon</a></p>
<p>《Learning Detailed Face Reconstruction from a Single Image》CVPR2017</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210193653717.png" alt="image-20200210193653717"></p>
<h3 id="5-E2FAR-CVPR-2017："><a href="#5-E2FAR-CVPR-2017：" class="headerlink" title="5.E2FAR CVPR 2017："></a>5.<a target="_blank" rel="noopener" href="https://github.com/ShownX/mxnet-E2FAR">E2FAR</a> CVPR 2017：</h3><p>《<a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2017/html/Dou_End-To-End_3D_Face_CVPR_2017_paper.html">End-To-End 3D Face Reconstruction With Deep Neural Networks</a>》CVPR2017</p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/ShownX/mxnet-E2FAR">https://github.com/ShownX/mxnet-E2FAR</a></p>
<p>文章采用端到端的方法估计最优3DMM参数，输入是二维图像及其感兴趣区域，采用Dlib进行特征点检测，将恢复人脸身份形状和表情形状作分为人脸重建的两个子任务，输出包含身份参数向量和表情参数向量。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210223741952.png" alt="image-20200210223741952"></p>
<h3 id="6-VRN-ICCV-2017："><a href="#6-VRN-ICCV-2017：" class="headerlink" title="6.VRN ICCV 2017："></a>6.<a target="_blank" rel="noopener" href="https://github.com/AaronJackson/vrn">VRN</a> ICCV 2017：</h3><p>《<a target="_blank" rel="noopener" href="http://aaronsplace.co.uk/papers/jackson2017recon/">Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression</a>》ICCV2017</p>
<p>GitHub: <a target="_blank" rel="noopener" href="https://github.com/AaronJackson/vrn">https://github.com/AaronJackson/vrn</a></p>
<p>官网: <a target="_blank" rel="noopener" href="https://cvl-demos.cs.nott.ac.uk/vrn/">https://cvl-demos.cs.nott.ac.uk/vrn/</a></p>
<p>A.S. Jackson 诺丁汉大学</p>
<p>采用体素方法进行三维人脸重建，对人脸而言重建精度不高，但是一种很好的三维人体重建方法。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210173005834.png" alt="image-20200210173005834"></p>
<h3 id="7-3DMMasSTN-ICCVW-2017："><a href="#7-3DMMasSTN-ICCVW-2017：" class="headerlink" title="7. 3DMMasSTN ICCVW 2017："></a>7. <a target="_blank" rel="noopener" href="https://github.com/anilbas/3DMMasSTN">3DMMasSTN</a> ICCVW 2017：</h3><p>Github: <a target="_blank" rel="noopener" href="https://github.com/anilbas/3DMMasSTN">https://github.com/anilbas/3DMMasSTN</a></p>
<p>《<a target="_blank" rel="noopener" href="http://xueshu.baidu.com/usercenter/paper/show%3Fpaperid%3D29a049c95a03ca5c49efbe02f08c2575%26site%3Dxueshu_se">3D Morphable Models as Spatial Transformer Networks</a>》ICCVW2017</p>
<p>3DMM方法作为空间转化网络的应用，利用3DMM恢复三维人脸形状从而得到姿态归一化和补全自遮挡的人脸图片。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/fig1.png" alt="Overview of the 3DMM-STN"></p>
<h3 id="8-EOSand4Dface-2017："><a href="#8-EOSand4Dface-2017：" class="headerlink" title="8. EOSand4Dface 2017："></a>8. <a target="_blank" rel="noopener" href="https://github.com/patrikhuber/eos">EOS</a>and<a target="_blank" rel="noopener" href="https://github.com/patrikhuber/4dface">4Dface</a> 2017：</h3><p>《<a target="_blank" rel="noopener" href="http://xueshu.baidu.com/usercenter/paper/show%3Fpaperid%3D55a34a1fbd6cbf9bf4cd824aa580fec4%26site%3Dxueshu_se">A Multiresolution 3D Morphable Face Model and Fitting Framework</a>》Visapp 2016 and 《<a target="_blank" rel="noopener" href="https://xueshu.baidu.com/usercenter/paper/show%3Fpaperid%3D074434f1094a27c7473330f65cbc5565%26site%3Dxueshu_se">Real-Time 3D Face Fitting and Texture Fusion on In-the-Wild Videos</a>》 <em>IEEE Signal Processing Letters</em>24.4 (2017)</p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/patrikhuber/eos">https://github.com/patrikhuber/eos</a></p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/patrikhuber/4dface">https://github.com/patrikhuber/4dface</a></p>
<p>这篇文章的方法主要致力于将3DMM应用到实际开发中，作者提出一个基于C++的拟合框架，可支持Surrey Face Model (SFM), 4D Face Model (4DFM), and the Basel Face Model (BFM) 2009 and 2017数据库，目前这个拟合框架仍在更新。</p>
<h4 id="eos"><a href="#eos" class="headerlink" title="eos"></a>eos</h4><img title src="/2020/02/10/CV_3D/CV-3D-Face-Model/sfm_shape_3448_mesh.png" alt="4D Face Model colour picture" style="zoom:20%;" width="251">

<h4 id="4Dface"><a href="#4Dface" class="headerlink" title="4Dface"></a>4Dface</h4><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><img title src="/2020/02/10/CV_3D/CV-3D-Face-Model/4dfm_color_sample.jpg" alt="4D Face Model colour picture" style="zoom:20%;" width="256"></td>
<td><img title src="/2020/02/10/CV_3D/CV-3D-Face-Model/4dfm_shape.png" alt="4D Face Model colour picture" style="zoom:10%;" width="258"></td>
</tr>
</tbody></table>
<p><a target="_blank" rel="noopener" href="https://www.4dface.io/4dfm/">www.4dface.io/4dfm</a>.</p>
<h3 id="9-Genova-CVPR-2018-1806-06098："><a href="#9-Genova-CVPR-2018-1806-06098：" class="headerlink" title="9 .Genova_CVPR 2018 1806.06098："></a>9 .<a target="_blank" rel="noopener" href="https://github.com/google/tf_mesh_renderer">Genova_CVPR 2018</a> 1806.06098：</h3><p>《Unsupervised Training for 3D Morphable Model Regression》CVPR2018</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.06098">https://arxiv.org/abs/1806.06098</a></p>
<p>github: <a target="_blank" rel="noopener" href="https://github.com/google/tf_mesh_renderer">https://github.com/google/tf_mesh_renderer</a>    (bazel, c++, tf)</p>
<p>本文由普林斯顿大学、谷歌和麻省理工学院合作完成，是 CVPR 2018 的 spotlight 文章。<strong>使用无监督训练的方法基于 3DMM 进行人脸三维重建</strong>。论文基于编码器和解码器模型，创新性地将人脸识别网络引入训练的损失函数，使得生成的 3D 人脸能很好地保留了输入图片的人脸个体特征。**该模型旨在拟合形状和纹理，并没有学习姿态表情和光照。**算法的编码器接受图像作为输入，输出用于 3DMM 模型的参数。解码器接受参数后合成 3D 人脸。为了使网络不仅能保持个体信息，还能生成自然真实的人脸，作者提出了 3 个新的损失函数，即批分布损失（batch distribution loss）、回环损失（loopback loss）和多视角身份损失（multi-view identity loss）。批分布损失可使每个批的统计量与 3DMM 的统计量一致。回环损失可保证生成的 3D 人脸模型的2D成像图片重新进入编码器得到的参数和原图的参数尽量一致。多视角身份损失能使得模型学习到独立于观察角度的个体特征。实验结果说明，模型不仅仅可以生成与输入图像高度相似的 3D 人脸，而且生成的人脸独立于输入的表情和姿态，甚至被遮挡的人脸也可以达到不错的生成效果。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210185718650.png" alt="image-20200210185718650"></p>
<h3 id="10-CoMA-ECCV-2018"><a href="#10-CoMA-ECCV-2018" class="headerlink" title="10. CoMA ECCV 2018:"></a>10. <a target="_blank" rel="noopener" href="https://github.com/anuragranj/coma">CoMA</a> ECCV 2018:</h3><p>《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.10267">Generating 3D faces using Convolutional Mesh Autoencoders</a>》ECCV2018</p>
<p>提出一种基于卷积面片自编码重建网络来获得三维人脸形状信息。</p>
<p>github: <a target="_blank" rel="noopener" href="https://github.com/anuragranj/coma">https://github.com/anuragranj/coma</a></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210185852990.png" alt="image-20200210185852990"></p>
<h3 id="11-PRnet-ECCV-2018："><a href="#11-PRnet-ECCV-2018：" class="headerlink" title="11. PRnet ECCV 2018："></a>11. <a target="_blank" rel="noopener" href="https://github.com/YadiraF/PRNet">PRnet</a> ECCV 2018：</h3><p>《<a target="_blank" rel="noopener" href="http://link.springer.com/content/pdf/10.1007/978-3-030-01264-9_33.pdf">Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network</a>》ECCV2018</p>
<p>github: <a target="_blank" rel="noopener" href="https://github.com/YadiraF/PRNet">https://github.com/YadiraF/PRNet</a></p>
<ul>
<li>上海交通大学 + 云从科技 +</li>
</ul>
<p>一篇针对三维人脸重建与对齐的论文，文章通过恢复稠密的3D人脸形状来定位2D人脸图片上的特征点，同时完成估计人脸姿态，人脸交换等应用。文中提到用uv-map来表示3D形状，实现了从端到端的网络结构。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190114627.png" alt="image-20200210190114627"></p>
<h3 id="12-Extreme-3d-faces-CVPR2018："><a href="#12-Extreme-3d-faces-CVPR2018：" class="headerlink" title="12. Extreme_3d_faces CVPR2018："></a>12. <a target="_blank" rel="noopener" href="https://github.com/anhttran/extreme_3d_faces">Extreme_3d_faces</a> CVPR2018：</h3><p>《<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1712.05083">Extreme 3D Face Reconstruction: Seeing Through Occlusions</a>》CVPR2018</p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/anhttran/extreme_3d_faces">https://github.com/anhttran/extreme_3d_faces</a></p>
<p>文章方法先恢复一个基础形状，表情，六维视角自由度，然后估计一个凹凸贴图，用来捕捉人脸皱纹和非参的中级特征，再补全人脸被遮挡区域。</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210190240938.png" alt="image-20200210190240938"></p>
<h3 id="13-Deep3DFace-CVPRW-2019："><a href="#13-Deep3DFace-CVPRW-2019：" class="headerlink" title="13. Deep3DFace CVPRW 2019："></a>13. <a target="_blank" rel="noopener" href="https://github.com/Microsoft/Deep3DFaceReconstruction">Deep3DFace</a> CVPRW 2019：</h3><p>《Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From Single Image to Image Set》arXiv 2019 </p>
<p>最近，基于深度学习的3D人脸重建方法在质量和效率上均显示出令人鼓舞的结果，但是训练深度神经网络通常需要大量数据，而具有真实3D人脸形状的人脸图像却很少。 在本文中，我们提出了一种新颖的深度3D人脸重建方法，该方法包括：1）利用鲁棒的混合损失函数进行<strong>弱监督学习</strong>，同时考虑了低层和感知层信息以进行监督，以及2）执行多通过利用来自不同图像的互补信息进行形状聚合来重建图像人脸。 我们的方法快速，准确，并且对遮挡和大姿势稳健。我们在三个数据集上提供了全面的实验，系统地比较了我们的方法和15种最新方法，并展示了其最新的性能。</p>
<p>github: <a target="_blank" rel="noopener" href="https://github.com/Microsoft/Deep3DFaceReconstruction">https://github.com/Microsoft/Deep3DFaceReconstruction</a></p>
<ul>
<li>Microsoft</li>
<li>3DMM系数</li>
</ul>
<p>训练流程：</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/3-Figure1-1.png" alt="3-Figure1-1"></p>
<p>示例：</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200210174434478.png" alt="image-20200210174434478"></p>
<h3 id="14-MMFace-CVPR-2019"><a href="#14-MMFace-CVPR-2019" class="headerlink" title="14. MMFace  CVPR 2019"></a>14. MMFace  CVPR 2019</h3><ul>
<li><p>用多指标回归网络MMFace解决3D人脸可变形模型（3DMM）与输入图像对齐的野外人脸重建问题。</p>
<p>  <img src="/2020/02/10/CV_3D/CV-3D-Face-Model/2-Figure2-1.png" alt="图2。我们的方法在AFLW2000-3D上的人脸重建和对齐结果[2]。"></p>
</li>
</ul>
<h3 id="15-2DASL-2019"><a href="#15-2DASL-2019" class="headerlink" title="15. 2DASL 2019"></a>15. 2DASL 2019</h3><p>project: Joint 3D Face Reconstruction and Dense Face Alignment from A Single Image with 2D-Assisted Self-Supervised Learning （2DASL)</p>
<p>1903.09359《3D Face Reconstruction from A Single Image Assisted by 2D Face Images in the Wild》</p>
<p>从单个2D图像重建3D人脸是具有广泛应用的挑战性问题。最近的方法通常旨在学习基于CNN的3D人脸模型，该模型从2D图像中回归3D变形模型（3DMM）的系数，以渲染3D人脸重建或密集人脸对齐。但是，缺少带有3D注释的训练数据会极大地限制那些方法的性能。为了缓解这个问题，我们提出了一种新颖的2D辅助自我监督学习（2DASL）方法，该方法可以有效地使用带有嘈杂地标信息的“野生” 2D面部图像来显着改善3D面部模型学习。具体来说，将稀疏的2D面部地标作为附加信息，2DSAL<strong>引入了四种新颖的自我监督方案</strong>，这些方案将2D地标和3D地标预测视为一种自映射过程，包括2D和3D界标自预测一致性，基于2D界标预测的循环一致性以及基于界标预测的预测3DMM系数的自评。使用这四个自我监督方案，2DASL方法大大减轻了对传统的配对2D到3D注释的需求，并提供了更高质量的3D人脸模型，而无需任何其他3D注释。在多个具有挑战性的数据集上进行的实验表明，我们的方法在3D人脸重建和密集人脸对齐方面都远远超过了最新技术。2DASL方法极大地减轻了对传统的2D到3D配对注释的需求，并提供了更高质量的3D人脸模型，而无需任何其他3D注释。在多个具有挑战性的数据集上进行的实验表明，我们的方法在3D人脸重建和密集人脸对齐方面都远远超过了最新技术。2DASL方法极大地减轻了对传统的2D到3D配对注释的需求，并提供了更高质量的3D人脸模型，而无需任何其他3D注释。在多个具有挑战性的数据集上进行的实验表明，我们的方法在3D人脸重建和密集人脸对齐方面都远远超过了最新技术。</p>
<p>Paper: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.09359">https://arxiv.org/abs/1903.09359</a></p>
<p>Github: <a target="_blank" rel="noopener" href="https://github.com/XgTu/2DASL">https://github.com/XgTu/2DASL</a></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200731170617469.png" alt="image-20200731170617469"></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/image-20200731170640042.png" alt="image-20200731170640042"></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/55403032-76960580-5587-11e9-926b-4be4d72c3e3f.gif"></p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/55403128-b3fa9300-5587-11e9-92f0-b7733431ddc9.gif"></p>
<h3 id="16-GANFIT-2019"><a href="#16-GANFIT-2019" class="headerlink" title="16. GANFIT 2019"></a>16. GANFIT 2019</h3><p>code: <a target="_blank" rel="noopener" href="https://github.com/barisgecer/GANFit">https://github.com/barisgecer/GANFit</a></p>
<p>《GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction》</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/4-Figure2-1.png" alt="Figure 2: Detailed overview of the proposed approach. A 3D face reconstruction is rendered by a differentiable renderer (shown in purple). Cost functions are mainly formulated by means of identity features on a pretrained face recognition network (shown in gray) and they are optimized by flowing the error all the way back to the latent parameters (ps, pe, pt, c, i, shown in green) with gradient descent optimization. End-to-end differentiable architecture enables us to use computationally cheap and reliable first order derivatives for optimization thus making it possible to employ deep networks as a generator (i.e,. statistical model) or as a cost function."></p>
<h3 id="17-TBGAN-2019"><a href="#17-TBGAN-2019" class="headerlink" title="17. TBGAN 2019"></a>17. TBGAN 2019</h3><p>code: <a target="_blank" rel="noopener" href="https://github.com/barisgecer/TBGAN">https://github.com/barisgecer/TBGAN</a></p>
<p>《Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative Adversarial Networks》</p>
<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/2-Figure1-1.png" alt="Fig. 1: We propose a novel generative adversarial network that can synthesize high-quality texture, shape, and normals jointly for realistic and coherent 3D faces. Moreover, we demonstrate how we can condition the generation on the expression and create faces with various facial expressions."></p>
<h3 id="Adaptive-2D-3D-2020"><a href="#Adaptive-2D-3D-2020" class="headerlink" title="Adaptive 2D 3D  2020"></a>Adaptive 2D 3D  2020</h3><ul>
<li>《Adaptive 3D Face Reconstruction from a Single Image》</li>
<li>3D重建，遮挡和极端姿势的解决方案</li>
<li>没有开源</li>
</ul>
<h3 id="AvatarMe-CVPR-2020"><a href="#AvatarMe-CVPR-2020" class="headerlink" title="AvatarMe CVPR 2020"></a>AvatarMe CVPR 2020</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.13845">https://arxiv.org/abs/2003.13845</a></p>
<p>《AvatarMe: Realistically Renderable 3D Facial Reconstruction “in-the-wild”》</p>
<p>AvatarMe是第一种能够从单个“野生”图像中以更高的细节水平重建逼真的3D人脸的方法。为此，我们捕获了大量的面部形状和反射率数据集，并基于一种3D纹理和形状重建方法，并逐步完善其结果，以生成高分辨率散布和镜面反射所需的图像。逼真的渲染。</p>
<ul>
<li>使用专业扫描设备，搜集了一套完整的3D人脸数据集</li>
</ul>
<img src="/2020/02/10/CV_3D/CV-3D-Face-Model/avatarme_method.png" alt="avatarme_method" style="zoom:200%;">

<p><img src="/2020/02/10/CV_3D/CV-3D-Face-Model/avatarme_teaser.png" alt="avatarme_teaser"></p>
<img src="/2020/02/10/CV_3D/CV-3D-Face-Model/proc_specAlbs.gif" alt="proc_specAlbs" style="zoom:50%;">

<h3 id="FRDA-open"><a href="#FRDA-open" class="headerlink" title="FRDA-open"></a>FRDA-open</h3><p><a target="_blank" rel="noopener" href="https://github.com/Star-Clouds/FRDA">https://github.com/Star-Clouds/FRDA</a></p>
<ul>
<li>Face Reconstruction</li>
<li>Dense Alignment</li>
<li>Face 3D landmarks</li>
<li>3D Pose Estimation</li>
</ul>
<hr>
<h2 id="二、多图三维人脸重建开源算法"><a href="#二、多图三维人脸重建开源算法" class="headerlink" title="二、多图三维人脸重建开源算法"></a>二、多图三维人脸重建开源算法</h2><p>大部分基于多图的三维人脸的工作，希望从同一个人不同时间和环境拍摄的图像集合中恢复一个标准的具有身份信息的人脸形状（不带姿态，表情，纹理等），</p>
<h3 id="1-AFAR："><a href="#1-AFAR：" class="headerlink" title="1.AFAR："></a>1.<a target="_blank" rel="noopener" href="http://cvlab.cse.msu.edu/project-face-recon.html">AFAR</a>：</h3><p>《<strong>Adaptive 3D Face Reconstruction from Unconstrained Photo Collections</strong>》CVPR2016</p>
<p>这篇文章在首先在CVPR2015提出，在CVPR2016对算法细节进行了改进，先基于从粗到细的方法，利用二维图片的特征点拟合3DMM系数，再根据PS方法对精细的细节进行恢复，最后得到三维人脸。</p>
<h2 id="三、人脸数据集"><a href="#三、人脸数据集" class="headerlink" title="三、人脸数据集"></a>三、人脸数据集</h2><h3 id="300W-LP"><a href="#300W-LP" class="headerlink" title="300W-LP"></a>300W-LP</h3><h3 id="FaceWarehouse：用于视觉计算的3D面部表情数据库"><a href="#FaceWarehouse：用于视觉计算的3D面部表情数据库" class="headerlink" title="FaceWarehouse：用于视觉计算的3D面部表情数据库"></a>FaceWarehouse：用于视觉计算的3D面部表情数据库</h3><p>3D面部表情数据库<img src="/2020/02/10/CV_3D/CV-3D-Face-Model/6-Figure4-1.png" alt="图4：使用具有不同数量组件的双线性模型拟合面部表情网格。 左上角是输入网格，下面显示了在identity属性和expression属性中使用不同数量组件的拟合结果。"></p>
<h2 id="训练源码"><a href="#训练源码" class="headerlink" title="训练源码:"></a>训练源码:</h2><h3 id="3D-Morphable-Model-training"><a href="#3D-Morphable-Model-training" class="headerlink" title="3D-Morphable-Model-training"></a><a target="_blank" rel="noopener" href="https://github.com/hkbonychen/3D-Morphable-Model-training">3D-Morphable-Model-training</a></h3><p>​        This program is to train the face 3D morphable model (3DMM)</p>
<p>​        <a target="_blank" rel="noopener" href="https://github.com/hkbonychen/3D-Morphable-Model-training">https://github.com/hkbonychen/3D-Morphable-Model-training</a></p>
<h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/3ef721e7c07e">开源3D人脸重建项目整理</a></p>
<p><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/3D-Morphable-Face-Models%E2%80%94Past%2C-Present%2C-and-Future-Egger-Smith/579fe5fa694cf6b27229fd0f0ce7dc487e0ceb18">3D Morphable Face Models—Past, Present, and Future</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/AndrewChiyz/3DMM-and-3D-Face-reconstruction-and-manipulation">3DMM-and-3D-Face-reconstruction-and-manipulation</a></p>
<h2 id="四、综述文献"><a href="#四、综述文献" class="headerlink" title="四、综述文献"></a>四、综述文献</h2><h4 id="State-of-the-Art-on-Monocular-3D-Face-Reconstruction-Tracking-and-Applications"><a href="#State-of-the-Art-on-Monocular-3D-Face-Reconstruction-Tracking-and-Applications" class="headerlink" title="State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications"></a>State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications</h4><p>单眼3D人脸重建，跟踪和应用的最新技术 2018</p>
<p>计算机图形和视觉社区长期致力于构建用于基于视觉输入来重建，跟踪和分析人脸的计算机化工具。在过去的几年中，取得了飞速的进步，这导致了新颖而强大的算法，即使在从单个RGB或RGB-D摄像机进行重建的极具挑战性的情况下，也能获得令人印象深刻的结果。随着这些技术在速度，准确性和易用性方面的进一步提高，应用范围广泛且稳步增长。受此飞速发展的推动，这份最新报告<strong>总结了单眼面部表情捕捉的最新趋势，并讨论了其应用，从基于动作的动画到实时面部重现</strong>。我们将讨论的重点放在使用基于优化的重建算法来恢复和跟踪人脸的三维模型的方法上。我们提供了有关真实世界图像形成的基本概念的深入概述，并讨论了使这些算法实用的常见假设和简化方法。 此外，**我们广泛介绍了用于更好地约束欠约束的单眼重建问题的先验知识，并讨论了用于从单眼2D数据中恢复密集的，光几何3D人脸模型的优化技术。**最后，我们在运动捕捉，面部动画以及图像和视频编辑的背景下，讨论了所审查算法的各种用例。</p>
<p>CCS概念•计算方法→重构；跟踪；动作捕捉; 形状造型；3D成像；</p>
<hr>
<h1 id="人脸企业级商业应用"><a href="#人脸企业级商业应用" class="headerlink" title="人脸企业级商业应用"></a>人脸企业级商业应用</h1><h2 id="face-8K"><a href="#face-8K" class="headerlink" title="face++8K"></a>face++8K</h2><h2 id="face-1K"><a href="#face-1K" class="headerlink" title="face++1K"></a>face++1K</h2><p>花钱采，花钱标 ：）</p>
<p>数据问题统一回复下：采集的话，主要是公司内部有一定数据积累，尤其是人脸识别组数据积累很大，这也是我们公司的优势吧。然后标注前期是精标，后期有些数据是大模型+筛选标注的。</p>
<p>10M的数据量</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/3DMM/" rel="tag"># 3DMM</a>
              <a href="/tags/3D-Face/" rel="tag"># 3D Face</a>
              <a href="/tags/PRNet/" rel="tag"># PRNet</a>
              <a href="/tags/3DDFA/" rel="tag"># 3DDFA</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/01/17/CV_3D/CV-3D-Model-Apply/" rel="prev" title="CV-3D-Model-Apply">
      <i class="fa fa-chevron-left"></i> CV-3D-Model-Apply
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/29/Tools/Tools-Ubuntu-Desktop%20install/" rel="next" title="Tools-Ubuntu-Desktop-install">
      Tools-Ubuntu-Desktop-install <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%80%E6%BA%903D%E4%BA%BA%E8%84%B8%E9%87%8D%E5%BB%BA%E9%A1%B9%E7%9B%AE%E6%95%B4%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">开源3D人脸重建项目整理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%87%E3%80%81%E5%9F%BA%E7%A1%80"><span class="nav-number">1.1.</span> <span class="nav-text">〇、基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3DMM-1999"><span class="nav-number">1.1.1.</span> <span class="nav-text">1. 3DMM 1999</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-BFM%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.1.2.</span> <span class="nav-text">2.BFM模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%86%85%E5%AE%B9%EF%BC%88%E4%BB%A52009%E7%89%88%E6%9C%AC%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">数据内容（以2009版本为例）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%8D%95%E5%9B%BE%E4%B8%89%E7%BB%B4%E4%BA%BA%E8%84%B8%E9%87%8D%E5%BB%BA%E5%BC%80%E6%BA%90%E7%AE%97%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">一、单图三维人脸重建开源算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3DDFA-CVPR-2016%EF%BC%9A"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.3DDFA CVPR 2016：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-pix2vertex-ICCV-2017%EF%BC%9A"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.pix2vertex ICCV 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-CNN3DMM-CVPR-2017%EF%BC%9A"><span class="nav-number">1.2.3.</span> <span class="nav-text">3.CNN3DMM_CVPR 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Richardson-CVPR-2017%EF%BC%9A"><span class="nav-number">1.2.4.</span> <span class="nav-text">4.Richardson_CVPR 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-E2FAR-CVPR-2017%EF%BC%9A"><span class="nav-number">1.2.5.</span> <span class="nav-text">5.E2FAR CVPR 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-VRN-ICCV-2017%EF%BC%9A"><span class="nav-number">1.2.6.</span> <span class="nav-text">6.VRN ICCV 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3DMMasSTN-ICCVW-2017%EF%BC%9A"><span class="nav-number">1.2.7.</span> <span class="nav-text">7. 3DMMasSTN ICCVW 2017：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-EOSand4Dface-2017%EF%BC%9A"><span class="nav-number">1.2.8.</span> <span class="nav-text">8. EOSand4Dface 2017：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#eos"><span class="nav-number">1.2.8.1.</span> <span class="nav-text">eos</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4Dface"><span class="nav-number">1.2.8.2.</span> <span class="nav-text">4Dface</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-Genova-CVPR-2018-1806-06098%EF%BC%9A"><span class="nav-number">1.2.9.</span> <span class="nav-text">9 .Genova_CVPR 2018 1806.06098：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-CoMA-ECCV-2018"><span class="nav-number">1.2.10.</span> <span class="nav-text">10. CoMA ECCV 2018:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-PRnet-ECCV-2018%EF%BC%9A"><span class="nav-number">1.2.11.</span> <span class="nav-text">11. PRnet ECCV 2018：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-Extreme-3d-faces-CVPR2018%EF%BC%9A"><span class="nav-number">1.2.12.</span> <span class="nav-text">12. Extreme_3d_faces CVPR2018：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#13-Deep3DFace-CVPRW-2019%EF%BC%9A"><span class="nav-number">1.2.13.</span> <span class="nav-text">13. Deep3DFace CVPRW 2019：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#14-MMFace-CVPR-2019"><span class="nav-number">1.2.14.</span> <span class="nav-text">14. MMFace  CVPR 2019</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#15-2DASL-2019"><span class="nav-number">1.2.15.</span> <span class="nav-text">15. 2DASL 2019</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#16-GANFIT-2019"><span class="nav-number">1.2.16.</span> <span class="nav-text">16. GANFIT 2019</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#17-TBGAN-2019"><span class="nav-number">1.2.17.</span> <span class="nav-text">17. TBGAN 2019</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adaptive-2D-3D-2020"><span class="nav-number">1.2.18.</span> <span class="nav-text">Adaptive 2D 3D  2020</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AvatarMe-CVPR-2020"><span class="nav-number">1.2.19.</span> <span class="nav-text">AvatarMe CVPR 2020</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FRDA-open"><span class="nav-number">1.2.20.</span> <span class="nav-text">FRDA-open</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%A4%9A%E5%9B%BE%E4%B8%89%E7%BB%B4%E4%BA%BA%E8%84%B8%E9%87%8D%E5%BB%BA%E5%BC%80%E6%BA%90%E7%AE%97%E6%B3%95"><span class="nav-number">1.3.</span> <span class="nav-text">二、多图三维人脸重建开源算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-AFAR%EF%BC%9A"><span class="nav-number">1.3.1.</span> <span class="nav-text">1.AFAR：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E3%80%81%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">1.4.</span> <span class="nav-text">三、人脸数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#300W-LP"><span class="nav-number">1.4.1.</span> <span class="nav-text">300W-LP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#FaceWarehouse%EF%BC%9A%E7%94%A8%E4%BA%8E%E8%A7%86%E8%A7%89%E8%AE%A1%E7%AE%97%E7%9A%843D%E9%9D%A2%E9%83%A8%E8%A1%A8%E6%83%85%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="nav-number">1.4.2.</span> <span class="nav-text">FaceWarehouse：用于视觉计算的3D面部表情数据库</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%BA%90%E7%A0%81"><span class="nav-number">1.5.</span> <span class="nav-text">训练源码:</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3D-Morphable-Model-training"><span class="nav-number">1.5.1.</span> <span class="nav-text">3D-Morphable-Model-training</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A"><span class="nav-number">1.6.</span> <span class="nav-text">参考资料：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E7%BB%BC%E8%BF%B0%E6%96%87%E7%8C%AE"><span class="nav-number">1.7.</span> <span class="nav-text">四、综述文献</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#State-of-the-Art-on-Monocular-3D-Face-Reconstruction-Tracking-and-Applications"><span class="nav-number">1.7.0.1.</span> <span class="nav-text">State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%BA%E8%84%B8%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%95%86%E4%B8%9A%E5%BA%94%E7%94%A8"><span class="nav-number">2.</span> <span class="nav-text">人脸企业级商业应用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#face-8K"><span class="nav-number">2.1.</span> <span class="nav-text">face++8K</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#face-1K"><span class="nav-number">2.2.</span> <span class="nav-text">face++1K</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon Shi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">322</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">269</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Simon Shi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
