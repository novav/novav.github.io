<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"novav.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="[toc] BackJTAKQ987 x 4 &#x3D; 32 Rule: ​	Grand（J王牌） ​	Null （无王牌） ​	Suit（J王牌，Suit王牌） ​	https:&#x2F;&#x2F;www.pagat.com&#x2F;schafkopf&#x2F;skat.html J A 10 K Q 9 8 7 2 11 10 4 3 0 0 0  Skat: 《Doctor Paper》《2011 [Skat] Pol">
<meta property="og:type" content="article">
<meta property="og:title" content="Game_Skat">
<meta property="og:url" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/index.html">
<meta property="og:site_name" content="Simon Shi的小站">
<meta property="og:description" content="[toc] BackJTAKQ987 x 4 &#x3D; 32 Rule: ​	Grand（J王牌） ​	Null （无王牌） ​	Suit（J王牌，Suit王牌） ​	https:&#x2F;&#x2F;www.pagat.com&#x2F;schafkopf&#x2F;skat.html J A 10 K Q 9 8 7 2 11 10 4 3 0 0 0  Skat: 《Doctor Paper》《2011 [Skat] Pol">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569227991203.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569247299838.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569379853117.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569379869506.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569488822453.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569488988224.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569491049415.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569552772685.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569551486523.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569550543360.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569550564693.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569549751076.png">
<meta property="og:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569502485229.png">
<meta property="article:published_time" content="2019-09-19T11:39:58.000Z">
<meta property="article:modified_time" content="2025-08-06T08:16:39.916Z">
<meta property="article:author" content="Simon Shi">
<meta property="article:tag" content="Paper Reading">
<meta property="article:tag" content="Skat">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/1569227991203.png">

<link rel="canonical" href="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Game_Skat | Simon Shi的小站</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Simon Shi的小站</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">人工智能，机器学习， 强化学习，大模型，自动驾驶</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://novav.github.io/2019/09/19/Games/Paper-Game-Skat/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Simon Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Simon Shi的小站">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Game_Skat
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-09-19 11:39:58" itemprop="dateCreated datePublished" datetime="2019-09-19T11:39:58+00:00">2019-09-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2025-08-06 08:16:39" itemprop="dateModified" datetime="2025-08-06T08:16:39+00:00">2025-08-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/" itemprop="url" rel="index"><span itemprop="name">Game</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Game/Imperfect-Information-Game/" itemprop="url" rel="index"><span itemprop="name">Imperfect Information Game</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>[toc]</p>
<h2 id="Back"><a href="#Back" class="headerlink" title="Back"></a>Back</h2><p>JTAKQ987 x 4 &#x3D; 32</p>
<p><strong>Rule</strong>:</p>
<p>​	Grand（J王牌）</p>
<p>​	Null （无王牌）</p>
<p>​	Suit（J王牌，Suit王牌）</p>
<p>​	<a target="_blank" rel="noopener" href="https://www.pagat.com/schafkopf/skat.html">https://www.pagat.com/schafkopf/skat.html</a></p>
<p>J A 10 K Q 9 8 7</p>
<p>2 11 10 4 3 0 0 0 </p>
<h2 id="Skat-《Doctor-Paper》"><a href="#Skat-《Doctor-Paper》" class="headerlink" title="Skat: 《Doctor Paper》"></a>Skat: 《Doctor Paper》</h2><p>《2011 [Skat] Policy Based Inference in Trick-Taking Card Games 》 【博士论文】Jeffrey Richard Long </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">三个贡献</span><br><span class="line"></span><br><span class="line">【4】专家级计算机SKAT-AI (组合游戏树搜索、状态评估和隐藏信息推理三个核心方面的组合来实现这一性能)</span><br><span class="line">《M. Buro, J. Long, T. Furtak, and N. R. Sturtevant. Improving state evaluation, inference, and search in trick-based card games. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI2009), 2009. 》</span><br><span class="line"></span><br><span class="line">【26】次优解决方案方法的框架</span><br><span class="line">《 J. Long, N. R. Sturtevant, M. Buro, and T. Furtak. Understanding the success of perfect information monte carlo sampling in game tree search. In Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI2010), 2010.》</span><br><span class="line"></span><br><span class="line">【27】一种简单的自适应对手实时建模技术。</span><br><span class="line">《 J. R. Long and M. Buro. Real-time opponent modelling in trick-taking card games. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI2011), page To appear, 2011. 》</span><br></pre></td></tr></table></figure>


<ul>
<li><p>介绍Best Defense Model的构建（三个假设）【Contract Bridge】</p>
<ul>
<li>对手(Miner)是完全信息的，我们(Maxer)是非完全</li>
<li>对手在Maxer选择之后play</li>
<li>Maxer采用纯策略，不适用融合策略</li>
</ul>
<p>this results in an algorithm for solving the best defense form of a game which frank and basin term exhaustive strategy minimisation（穷举策略最小化）.</p>
</li>
</ul>
<h4 id="SKAT"><a href="#SKAT" class="headerlink" title="SKAT:"></a>SKAT:</h4><p><strong>DDS(Double-Dummy Solver ):</strong>	MC simulation + ab-search</p>
<ul>
<li>采用PIMC算法的直接实现来构建的 (很大程度上)</li>
<li>以及加入了AB算法(对alpha-beta搜索组件的两个主要增强):<ul>
<li>准对称缩小(quasi-symmetry reduction )，是Ginsberg的分区搜索的一种改编，它将搜索状态组合在一起，这些状态“几乎”等价</li>
<li>启发式对抗（adversarial heuristics ）</li>
</ul>
</li>
<li>k-mean for bidding</li>
</ul>
<p><strong>UCT:</strong></p>
<h4 id="Poker"><a href="#Poker" class="headerlink" title="Poker"></a>Poker</h4><p>CFR是一个离线过程，它在游戏的每个信息集中学习移动概率。</p>
<p>迭代算法。</p>
<p>当到达游戏的终端状态时，树中的每个节点都会根据程序对实际执行策略的后悔程度来更新，该策略与每个信息集中的最佳可用移动相比较。</p>
<p>这一过程将收敛到纳什均衡（2人）</p>
<p>CFR &#x3D;》an enormous table of move probabilities, </p>
<p>Multi-player</p>
<ul>
<li><p>桥牌</p>
<p>在文献中，桥牌通常被视为一种两人游戏，但实际上它是由四位不同的玩家玩的；</p>
<p>对双玩家游戏的抽象是有意义的，因为玩家是在两个团队中结盟的，而对游戏的所有现有方法都是基于游戏的完美信息模型，在那里我们忽略了两个伙伴不一定知道对方的事实，</p>
<p>因此实际上并不像他们是一个实体那样玩。</p>
</li>
<li><p>Skat</p>
<p>虽然Cardplay阶段可以(而且已经)被视为一个两人游戏（<strong>this is interesting？ how?</strong>），但在biding阶段，每个玩家都是为自己而战。</p>
<p>更重要的是，vonstengel和koller[47]已经显示，在非合作的零和团队游戏中，一个具有共同回报但不同信息的agent小组与一个无所不知的对手竞争，最好的回报是，团队玩家可以希望得到团队-MaxMin平衡。</p>
</li>
</ul>
<h3 id="Kermit"><a href="#Kermit" class="headerlink" title="Kermit"></a>Kermit</h3><p>并且搭建了<em>当时最强Skat AI</em> ‘Kermit ‘  论文介绍了Kermit 的信息有：</p>
<ul>
<li>Card Play [采用PIMC]： Perfect Information Monte Carlo Search for Cardplay</li>
<li>估值：State Evaluation for Bidding</li>
<li>推理：Inference</li>
<li>Ai水平对比：Kermit Versus the World: Experimental Results</li>
</ul>
<h4 id="4-1-Perfect-Information-Monte-Carlo-Search-for-Cardplay"><a href="#4-1-Perfect-Information-Monte-Carlo-Search-for-Cardplay" class="headerlink" title="4.1 Perfect Information Monte Carlo Search for Cardplay"></a>4.1 Perfect Information Monte Carlo Search for Cardplay</h4><p><img src="/2019/09/19/Games/Paper-Game-Skat/1569227991203.png" alt="1569227991203"></p>
<p>【23】实现了一系列的card game  and skat move 排序启发式算法。</p>
<p>eg:	相等牌力出牌分组，单张7，8 出一张即可</p>
<p><strong>4.1.1 Perfect Information Search Enhancements</strong> </p>
<p>​	采用ab-search和启发式算法提升搜索树的性能；– <strong>可采用NN直接拟合在Sates下的action的选择</strong></p>
<p><strong>4.1.2 Search Payoffs</strong> </p>
<p>相反，我们采用一系列零窗口搜索来缩小搜索空间。零窗口Alpha-beta搜索是将Alpha和Beta分别设置为值V和V1的一个。使用这样的窗口执行搜索将确定该位置的真实值是否大于或小于-或-等于V</p>
<p>在Kermit的构造中，我们提出了直接逼近不完全信息状态值的方法，并将其应用于博弈树搜索博弈的竞价阶段。</p>
<ul>
<li><p>在非完备博弈数据可以得到的情况下，利用监督学习技术可以直接估计评价参数。</p>
</li>
<li><p>否则，就有可能从完善的信息评估中引导不完美的信息评估。{使用Cardplay方法(如pimc搜索)}</p>
</li>
</ul>
<h4 id="4-2-State-Evaluation-for-bidding"><a href="#4-2-State-Evaluation-for-bidding" class="headerlink" title="4.2 State Evaluation for bidding"></a>4.2 State Evaluation for bidding</h4><p>作者实验了PIMC的胜率评估结果，均比实际结果差，因此转为采用<strong>static evaluation</strong></p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569247299838.png" alt="1569247299838"></p>
<p><strong>4.2.1 Learning Table-Based State Evaluations</strong> </p>
<p>the generalized linear evaluation model (GOEM) framework [3]广义线性评价模型框架[3]<br>$$<br>e(s) &#x3D; l (\sum_i w_i · f_i(s) )<br>$$</p>
<p>where $e(s)$ is the state evaluation, $l$ is an increasing and differentiable link function, $w_i \in R$ are<br>weights and $f_i(s)$ are state features. </p>
<p>通常选择：$l(x)&#x3D;x$(线性回归)  和 $ l(x) &#x3D; 1&#x2F;(1+exp(-x))$ (logitic 回归)</p>
<p>the resulting expressiveness of $e$ may be low ; (因为这样e的结果会比较小，影响不够)，–&gt; 采用table-based features<br>$$<br>f(s) &#x3D; T [h_1(s)] … [h_n(s)]<br>$$</p>
<p>其中索引函数$h_j：s -&gt; {0,.., n_j−1}$ 计算状态 $s$ 的属性，并使用索引向量从多维表T中检索值。</p>
<p><strong>基于表的特性的优点是表值可以很容易地从有标签的样本中学习，并且状态评估速度快。</strong></p>
<p><strong>4.2.2 Application to Skat Bidding</strong> </p>
<p>采用 10+2 evalution $e_g(h, s, p)$ 估计胜率</p>
<p>g: game type</p>
<p>h: ten cards</p>
<p>s: discarded skat</p>
<p>p: position in {0, 1, 2,}</p>
<p>Kermit为什么可以采用PIMC ？</p>
<table>
<thead>
<tr>
<th></th>
<th>Kermit</th>
<th>DDZ</th>
</tr>
</thead>
<tbody><tr>
<td>叫分</td>
<td>叫分复杂（分多轮，不同的计分规则）</td>
<td>叫分简单</td>
</tr>
<tr>
<td>play</td>
<td>游戏规则相对单一，10轮    – 游戏树小</td>
<td>每局游戏1-52轮       –游戏树大</td>
</tr>
<tr>
<td></td>
<td>每人每轮有且只能出1张牌。–状态估值方便</td>
<td>每轮可出1-20张牌，–对状态的估值影响大</td>
</tr>
<tr>
<td></td>
<td>– 隐藏信息相对少</td>
<td>–隐藏状态多</td>
</tr>
</tbody></table>
<h4 id="4-3-inference"><a href="#4-3-inference" class="headerlink" title="4.3 inference"></a>4.3 inference</h4><p>以前的工作都不涉及在游戏中对对手牌的推断。</p>
<p>比较接近的是Ginsberg在桥牌【15】中的推理研究方，Richards and Amir in Scrabble </p>
<ul>
<li>Ginsberg的推理方法基本没有资料说明如何实现</li>
<li>Scrabble的推理，使用了Bayes’ Rule 估计P(leave|play);P(leave)是对手的牌上剩下的字母的先验概率，通过分析计算得到。</li>
</ul>
<p><strong>4.3.1 Inference Formulation</strong> </p>
<p>非完全信息的推理有两个问题：</p>
<ul>
<li>计算大量的假设世界，很难</li>
<li>计算机只可以生成确定性的概率0&#x2F;1，这点导致打发不同玩家时，不堪一击</li>
</ul>
<p>解决方法：</p>
<ul>
<li>人类对局数据学习</li>
<li>推广公式，不仅仅对World推理，加入高纬特征的（eg 特点花色的牌张数，多少个大牌）</li>
</ul>
<p>其中，$W_i^{‘}$代表32张卡的配置，在竞价阶段，通过考虑所有的扑克牌以及独奏者的卡片，从wi重构。</p>
<p>F: 从这些完整的32张卡配置中提取出对手竞投的个人手的功能，然后对这些手的出价进行评估。</p>
<p>W, R, T</p>
<p><strong>features</strong>:<br>Suit length $\in {0…7}$: 	The number of cards held in each of the four suits, }~♠|.<br>Jack constellaion $ \in {0…15}$: 	The exact configuration of the player’s Jacks.<br>Ace count $ \in {0…4}$: 	Number of Aces held.<br>High card count $ \in {0…8}$: 	Number of Aces and Tens held.<br>King Queen count $ \in {0…8}$: 	Number of Kings and Queens held.<br>Low card count $ \in {0…12}$: 	Number of 7s, 8s and 9s held. </p>
<h3 id="5-Why-PIMC"><a href="#5-Why-PIMC" class="headerlink" title="5. Why PIMC ?"></a>5. Why PIMC ?</h3><p>PIMC的缺陷failing</p>
<p>例如，我们有希望使用UCT算法，这种算法彻底改变了计算机围棋的世界。然而，Kermit的性能，使用了第4章描述的相对直截了当的pimc实现，以及它对其他计算机播放器的令人信服的控制，包括一个使用UCT方法的计算机播放器，使得我们重新考虑了这个目标。我们在本章中更深入地理解了pimc搜索的优点和弱点，以及它在应用的领域中的工作原理。</p>
<h4 id="5-1-Understanding-the-Failings-of-PIMC-Search"><a href="#5-1-Understanding-the-Failings-of-PIMC-Search" class="headerlink" title="5.1 Understanding the Failings of PIMC Search"></a>5.1 Understanding the Failings of PIMC Search</h4><p>众所周知，PIMC搜索作为一种算法不会产生纳什均衡或任何其它具有可证明的游戏理论属性的策略。Frank and Basin 是第一个精确地识别并形式化这一天然的错误， pimc搜索的本身缺陷导致的[9]。从根本上说，这些错误是由于游戏的完美信息变体的重复播放不能真实地捕捉原始游戏的所有不完美的信息方面而发生的。</p>
<p>两种错误，并且PIMC无法解决的。</p>
<p>1、strategy fusion</p>
<p>策略融合是因为完全信息蒙特卡罗搜索(错误地)认为任何特定的世界选择最佳策略是奢侈的，而在现实中，存在着由多个不同的完美信息场景组成的情况(或信息集)。</p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569379853117.png" alt="1569379853117"></p>
<p>pimc搜索将认为它总是可以在节点(A)和(B)上做出正确的决定，因此这两个节点的根移动看起来都是胜利。</p>
<p>然而，在现实中，Maxer玩家是混淆在世界1和2之间，实际上可能会在树的歧义问题方面犯错。</p>
<p>2、non-locality </p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569379869506.png" alt="1569379869506"></p>
<p>非局部性是一个事实的结果，在一个完美的信息博弈中，一个游戏树节点的值仅仅是它的子树的一个函数，因此节点的值完全由从其子代开始的搜索来确定。（完全信息博弈，节点值来自子节点的搜索来确定）</p>
<p>在不完美的信息游戏中，节点的值可以依赖于不包含在其子树内的游戏树的其它区域，主要是由于对手的能力来引导游戏朝向树的区域，他知道(或至少猜测)对于他来说是有利的，使用他拥有但我们不拥有的私人信息。此现象在树中可能的远程节点之间创建非本地依赖关系。（在游戏树远程节点之间创建非本地依赖）</p>
<h4 id="5-2-Success"><a href="#5-2-Success" class="headerlink" title="5.2 Success"></a>5.2 Success</h4><p>5.2.1</p>
<p>在比赛的前七招中，对于我们的首发位置，我们将使用人类玩的真正的滑雪板游戏，此时比赛结果仍然不确定的(也就是说，双方都还没有获得足够的牌分来赢得比赛)。</p>
<ul>
<li><p>Leaf Correlation, lc</p>
<p>给出所有兄弟终端节点具有相同回报值的概率。</p>
<p>Low lc 表示：一种游戏，玩家几乎总是有可能在很晚的时候影响他们的回报。</p>
</li>
<li><p>Bias,b, </p>
<p>determines the probability that the game will favor a particular player over the other. with very high or very low bias, we expect there to be large, homogeneous sections of the game, and as long as a game-playing algorithm can find these large regions, it should perform well in such games.</p>
<p>确定该游戏比另一位玩家更倾向于某一特定玩家的概率。在极高或很低的偏倚下，我们期望游戏中会有大的、同质的部分，只要游戏算法能够找到这些大区域，它就应该在这样的游戏中表现良好。</p>
</li>
<li><p>Disambiguation factor, df, </p>
<p>根据树的深度确定玩家信息集中节点数量缩小的速度</p>
<p>Skat每次播放都会显示一张卡片，这意味着每个信息集中的状态随着游戏的继续而急剧缩小。</p>
<p>相反，在像Poker这样的游戏中，几乎没有私密信息被直接显示，直到游戏结束。</p>
<p>我们可以通过考虑玩家的信息集合在每次玩家移动时收缩的程度来确定这个因素。</p>
</li>
</ul>
<h4 id="5-3-Methodology"><a href="#5-3-Methodology" class="headerlink" title="5.3 Methodology"></a>5.3 Methodology</h4><p>5.3.1 Measuring Properties in Real Games </p>
<h4 id="5-4-Experimental-Setup"><a href="#5-4-Experimental-Setup" class="headerlink" title="5.4 Experimental Setup"></a>5.4 Experimental Setup</h4><p>5.4.1 Synthetic Trees </p>
<p>5.4.2 Experiments on Synthetic Game Trees 合成游戏树实验</p>
<p>5.4.3 Real Games </p>
<h4 id="5-5-结论"><a href="#5-5-结论" class="headerlink" title="5.5 结论"></a>5.5 结论</h4><p> 在本章中，我们对简单、合成的游戏树进行了实验，以便深入了解为什么完美的信息蒙特卡罗搜索在各种实际领域中如此成功，尽管其理论上存在缺陷。我们定义了这些合成树的三个属性，它们似乎是PIMC搜索性能的良好预测因子，并证明这些属性是如何在真实游戏中测量的。</p>
<p>对简单，合成游戏树实验，定义了合成树的三个属性– 对PIMC的搜索性能良好因子</p>
<ul>
<li>演示了这些属性是如何在真实游戏中得到的。</li>
</ul>
<h3 id="6、推理"><a href="#6、推理" class="headerlink" title="6、推理"></a>6、推理</h3><p>inference, as we have taken it, is the problem of mapping a series of observed actions taken by a player into a probability distribution over that player’s private information. a reasonable and intuitive question to ask is whether inference is nothing more than an attempt to build a model of a particular opponent. certainly, since inference attempts to derive meaning from an opponent’s actions, it is inherently dependent on the opponent’s policy for choosing those actions — in other words, her strategy. and if the opponent does not act as we expect, could our inferences cause us to make more mistakes by misleading us?</p>
<p>正如我们所做的那样，推理是将玩家所采取的一系列观察到的行为映射成对该玩家私人信息的概率分布的问题。一个合理而直观的问题是，<strong>推论是否仅仅是试图建立一个特定对手的模型</strong>。当然，由于推理试图从对手的行为中获得意义，它本质上依赖于对手的政策来选择那些行动-换句话说，就是她的策略。如果对手不按我们的预期行事，我们的推论是否会误导我们，使我们犯更多的错误？</p>
<h4 id="6-2-Inference-and-Non-locality"><a href="#6-2-Inference-and-Non-locality" class="headerlink" title="6.2 Inference and Non-locality"></a>6.2 Inference and Non-locality</h4><p>Non-locality：非局部性的出现是因为对手可能能够利用他们的私人知识，将游戏指向对她更有利的游戏树的部分。</p>
<p>推理是捕捉对手移动所传递的信息的过程，而同样的道理是，意识到我们自己的动作传递给对手的信息。</p>
<p>假设我们有一个神奇的黑匣子，它可以在一个不完美的信息游戏的任何阶段，在游戏中的所有隐藏信息(即非公共信息)上产生一个精确的概率分布。我们将证明，我们可以使用这样一个盒子来寻找一个游戏g的子树的最优策略，而不需要考虑g的整个博弈树。</p>
<p>Define：</p>
<p>H: public History</p>
<p>Box(G, H, σ)：	Game + History -&gt; a set of possible states S, a strategy profile σ for all players in Game G; 生成P(s) for all $s \in S$ 校正后验概率分布, 在所有可能的状态S上。</p>
<h4 id="6-3-Inference-in-PIMC-Search"><a href="#6-3-Inference-in-PIMC-Search" class="headerlink" title="6.3 Inference in PIMC Search"></a>6.3 Inference in PIMC Search</h4><p>6.3.2 Considerations in inference Design</p>
<p>PIMC search would exhaustively examine all worlds, and weigh the result of each world’s analysis by the world’s probability. When the state space is still large, this approach is not feasible if the analysis of each world is time-consuming, as is the case when using alpha-beta search on perfect information worlds.  </p>
<p>​	</p>
<h3 id="7："><a href="#7：" class="headerlink" title="7："></a>7：</h3><p>对抗环境的越复杂，其随机性，不确定性</p>
<p>考虑不同的对手模型变得更加重要，原因有两个：</p>
<p>第一个原因是这些环境中的最佳策略常常是过度防御的</p>
<p>第二个原因是在不完善的信息环境中，根据其他代理的动作推断隐藏状态变量通常是有帮助的。对于某些类型的推理（尤其是我们在第6章中讨论的不正确的推断），这需要一个准确的模型，说明Agent在环境中的行为方式。因此，合适的对手模型允许代理明确地利用对手弱点，并且通过对隐藏信息的优良推断来改进其自己的决策。</p>
<h3 id="8"><a href="#8" class="headerlink" title="8"></a>8</h3><p>在我们建立一个强大的电脑滑板运动员和了解围绕这一目标的问题的过程中，我们调查了一些未能达到我们最初对它们的期望的技术。对于这些想法中的一些，也许是因为它们完全没有价值。对其他人来说，滑雪板可能根本不是正确的领域，或者他们缺少一些关键的完善。在这一章中，我们将记录我们认为最有趣的技术。</p>
<p>8.2 </p>
<p>与其预测玩家将在每个世界中进行最优的完美信息移动，我们还会预测他们将进行PIMC搜索在他们的位置上所建议的移动。</p>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><ul>
<li><p>【9】对不完美信息博弈的完美信息蒙特卡罗搜索(或称为重复最小化)方法的广泛批评。</p>
</li>
<li><p>【29】描述使用神经网络预测完美信息(或double-dummy )桥接问题的结果，并报告与某些类别交易的人类专家相当的准确性。</p>
</li>
<li><p>【35】最强桥牌AI-Ginsberg’s GIB  {加权MC样本weighted Monte Carlo samples }</p>
<p>对手牌的推理研究</p>
</li>
<li><p>【15】work by Ginsberg in bridge ，[brideg ai GIB] : 对桥牌中对手牌的推理研究</p>
</li>
<li><p>【32】Richards and Amir in Scrabble</p>
</li>
</ul>
<hr>
<p>《2009.3 Improving State Evaluation, Inference, and Search in Trick-Based Card Games》</p>
<p><a target="_blank" rel="noopener" href="https://www.cs.du.edu/~sturtevant/papers/skat.pdf">https://www.cs.du.edu/~sturtevant/papers/skat.pdf</a></p>
<ul>
<li><p>贝叶斯公式</p>
</li>
<li><p>KI Kermit infrence</p>
</li>
</ul>
<p>《AAAI2010 Understanding the success of perfect information monte carlo sampling in game tree search》</p>
<p>《Real-time opponent modelling in trick-taking card games (IJCAI2011) 》</p>
<hr>
<h2 id="14《2019-3-Improving-Search-with-Supervised-Learning-in-Trick-Based-Card-Games》"><a href="#14《2019-3-Improving-Search-with-Supervised-Learning-in-Trick-Based-Card-Games》" class="headerlink" title="14《2019.3 Improving Search with Supervised Learning in Trick-Based Card Games》"></a>14《2019.3 Improving Search with Supervised Learning in Trick-Based Card Games》</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1903.09604.pdf">https://arxiv.org/pdf/1903.09604.pdf</a></p>
<ul>
<li><p>trick-taking card game，<strong>状态采样和评价</strong>的两步过程被广泛用于拟合移动值</p>
</li>
<li><p>最近在扑克牌游戏ai中的工作主要集中在改进<strong>评估算法</strong>上。</p>
<p>本文，重点研究了<strong>采样</strong>对玩家力量的影响，并提出了一种新的方法来采样给定移动历史的更真实的状态。</p>
</li>
<li><p>采用DNN预测卡片的位置 (Card Location Inference  &#x3D; CLI)</p>
</li>
</ul>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569488822453.png" alt="1569488822453"></p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569488988224.png" alt="1569488988224"></p>
<p>图1：推理网络体系结构。所示的是一种特定于滑板的架构，用于预测所有32张卡的卡前位置。每一张牌可以在四个可能的位置之一(每个玩家的手和Skat)。输出目标在每个玩家手中有10张卡片，剩下的2张在滑板中。</p>
<p>四个可能的位置：玩家1，玩家2，玩家3，landlord</p>
<p>NN输入特征：</p>
<p>Lead Cards：First cards played</p>
<p>Sloughed cards: 掉牌是指当一名玩家不能效仿，但也不做一张王牌时使用的牌。</p>
<p>Void suits：游戏规则，是无suit规则</p>
<p>Bid， 分type和Magnitude</p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569491049415.png" alt="1569491049415"></p>
<p>TSSR 推理性能评估</p>
<hr>
<h2 id="18《2019-5-Learning-policies-form-human-data-for-skat》"><a href="#18《2019-5-Learning-policies-form-human-data-for-skat》" class="headerlink" title="18《2019.5 Learning policies form human data for skat》"></a>18《2019.5 Learning policies form human data for skat》</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.10907.pdf">https://arxiv.org/pdf/1905.10907.pdf</a></p>
<ul>
<li><p>预测隐藏牌</p>
</li>
<li><p>NN 训练pre-cardplay 和cardplay</p>
</li>
</ul>
<p>摘要大型不完全信息博弈中的决策是很困难的。由于最近在扑克方面的成功，反事实的遗憾最小化(CFR)方法在这些游戏中一直处于研究的前沿。然而，大多数大型游戏的成功都是通过使用前向模型和强大的状态抽象来实现的。在桥牌或滑雪板之类的纸牌游戏中，大量的信息集和无法在不完全确定状态的情况下推进模拟的能力使前向搜索成为问题。此外，由于每个参与者的精确持有量直接影响移动值，因此状态抽象可能特别难以构建。</p>
<p>  abs：</p>
<p>Trick-taking类游戏的挑战：</p>
<ul>
<li><p>Large info set</p>
</li>
<li><p>没有确定性的状态下，无法前向搜索</p>
</li>
<li><p>状态抽象壁垒– 参与者的精确手牌，影响大</p>
</li>
</ul>
<p><strong>本文实现</strong>：</p>
<p>使用DNN实现了一个SOTA 系统（model-free），对bidding和game declaration（叫分，游戏类型等）</p>
<p>CardPlay 比最佳的Search-Base算法要弱</p>
<p>还尝试了RL，但是应该进展不大。</p>
<h4 id="Pre-CardPlay-Train"><a href="#Pre-CardPlay-Train" class="headerlink" title="Pre-CardPlay Train"></a>Pre-CardPlay Train</h4><p>policy + value</p>
<p>每种GameType训练一个单独的NN（Null and Null Ouvert 除外）</p>
<p>NN- Input&#x2F;Output。数据集大小</p>
<p>总共10个model，10个数据集。每个模型的输入特征都是Table III的特征组合而成。</p>
<p>例如：Bid&#x2F;answer 模型的输入特征2个：是 Player Hand + Player Position。</p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569552772685.png" alt="1569552772685"></p>
<p>2 additional Network</p>
<p>​	Hand&#x2F;Pick UP phase</p>
<p>​	Declare phase</p>
<p>​	： 用于近似于行动的价值。</p>
<p><strong>DNN架构</strong></p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569551486523.png" alt="1569551486523"></p>
<p>人类数据训练的MLV方法提供了新的SOTA bot for Skat pre-cardplay</p>
<h4 id="CardPlay-Train"><a href="#CardPlay-Train" class="headerlink" title="CardPlay Train"></a>CardPlay Train</h4><p>same network architecture  used for pre-cardplay NN</p>
<p>训练总计6个神经网络。</p>
<p>defender and soloist versions of Grand, Suit, and Null. </p>
<p><strong>NN输入特征</strong></p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569550543360.png" alt="1569550543360"></p>
<p><strong>数据集大小</strong></p>
<p>6个模型的数据集，对应的是2个位置的三中游戏规则</p>
<ul>
<li>Grand</li>
<li>suit</li>
<li>Null</li>
</ul>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569550564693.png" alt="1569550564693"></p>
<p><strong>性能对比</strong></p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569549751076.png" alt="1569549751076"></p>
<p>–<strong>Conclusion</strong></p>
<p>在这篇论文中，我们已经证明了玩纸牌前策略可以从人类游戏数据中学习，并且它的表现要比以前的最先进的’Kermit‘播放要好得多。</p>
<p>bidding policy (采用DI-M) 比 Kermit差1.35TP&#x2F;G; (DI-S更是相差4.14TP&#x2F;G)</p>
<p>The best overall full network based player was MLV.925+C, </p>
<p>–<strong>Future</strong> Work</p>
<hr>
<h2 id="00《2019-Policy-Based-Inference-in-Trick-Taking-Card-Games》"><a href="#00《2019-Policy-Based-Inference-in-Trick-Taking-Card-Games》" class="headerlink" title="00《2019 Policy Based Inference in Trick-Taking Card Games》"></a>00《2019 Policy Based Inference in Trick-Taking Card Games》</h2><p><a target="_blank" rel="noopener" href="http://ieee-cog.org/papers/paper_123.pdf">http://ieee-cog.org/papers/paper_123.pdf</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.10911.pdf">https://arxiv.org/pdf/1905.10911.pdf</a></p>
<ul>
<li><p>评估信息集的状态概率</p>
</li>
<li><p>使用玩家模型，推理状态概率</p>
</li>
</ul>
<p><strong>Abstract</strong></p>
<p>卡牌游戏的特点是大量的私人信息，慢慢地被揭示通过一长串的行动。这使得历史记录在动作序列长度中呈指数增长，并创建了非常大的信息集。因此，这些游戏变得太大，无法解决。为了处理这些问题，许多算法采用推理，<strong>估计信息集中的状态概率</strong>。在本文中，我们演示了一种<strong>基于策略的推理（Pi）算法</strong>，该算法使用玩家建模来推断我们处于给定状态的概率。我们在德国特技拍摄游戏SKAT中进行实验，其中我们表明，与以前的工作相比，<strong>该方法极大地改进了推理</strong>，并且当它被<strong>应用到其确定的搜索算法</strong>中时，增加了现有技术的SKAT AI系统Kermit的性能。</p>
<p><strong>1-Introduce</strong></p>
<p>Determinized search algorithm，</p>
<p>推理是非完备信息的中心概念。</p>
<p>’冷扑大师‘ CFR的超越人类玩家的Ai，他们没有证明对trick-based 游戏是有用的。</p>
<p>这是因为信息集的非常大的大小、大量的竞价和很长的Cardplay序列，创建表达抽象的困难。</p>
<p>虽然这些长序列使游戏变得太大以至于无法解决，但是它们也慢慢地揭示其他玩家的私人信息，从而推断期望的方法。</p>
<p><strong>本文：</strong> 利用对手模型的推理。</p>
<p>特别是，我们培训关于受监督的人类数据的政策，并利用它们来根据对手和合作伙伴以前的每一次行动推断他们的私人信息。</p>
<p>Outline：1-Skat rule， 2.Opponent Model trained in human data, 3. conclude, idea for future research。</p>
<p><strong>2- 背景</strong></p>
<p>KI: 	使用一种基于表格的技术，根据对手的出价和声明，对状态采样进行偏置。这种方法只解释了有限数量的可用状态信息，而忽略了当对手玩特定卡片时发生的重要推理机会。这一推断将称为Kermit推断（Ki）。</p>
<p>Solinas等人[14]通过使用神经网络对个别卡的位置进行预测来扩展这一过程。通过假设这些预测之间的独立性，通过乘以配置中卡片位置对应的概率来计算给定配置的概率。尽管示出该方法是有效的，但是独立假设与对于给定配置的事实不一致，给定卡存在的概率高度依赖于其它卡的存在。</p>
<p>例如，他们的方法无法捕获玩家的动作表明他们的手可能包含梅花J或黑桃J，但不能同时包含两者。</p>
<p>本文提出的策略推理方法通过 <strong>根据精确卡片配置来估计状态的概率。</strong></p>
<p>Card Location Inference (CLI):</p>
<p><strong>III.INFERENCE</strong></p>
<p><strong>给定信息集上的一个状态，得到确定性的概率。也就是计算到达概率 η。</strong> 如果我们能够完美地确定导致这种状态的每个动作的概率，我们就可以将所有的概率相乘，得到η。</p>
<p>$$<br>\eta(s|I) &#x3D; \sum_{h \cdot a \sqsubseteq s} \pi(h, a)<br>$$</p>
<p>如果我们对信息集中的所有状态重复这个过程，我们就可以计算出状态之间的概率分布。如果我们能够完美地评估所有状态-动作对的值，我们就可以选择使这个期望值最大化的动作，从而提供一个最优的解决方案。</p>
<p><strong>Policy Inference</strong>：</p>
<p>ISSUE-1: 无法知道其他玩家的策略（或成本太贵）</p>
<p>这使得对手&#x2F;伙伴模型成为必要的，在这种模型中，我们假定其他玩家的模型计算成本不高，并使用它们来估计状态的到达概率。</p>
<p>ISSUE-2: 信息集的状态数据相当大</p>
<p>为了解决这个问题，我们可以对世界进行采样，并对状态子集上的分布进行规范化。因为在滑雪板中，玩家在玩纸牌之前的信息集大小可以包含多达28亿个状态，我们采用了抽样的方法。</p>
<p>Algorithm 1 ： 估计状态分布– 信息集，OppModel, </p>
<p><img src="/2019/09/19/Games/Paper-Game-Skat/1569502485229.png" alt="1569502485229"></p>
<p>算法1，评估状态的相对到达概率，当我们不是使用采样时。这将成为对状态的真实到达概率的估计。</p>
<p>CLI(Cards Location Inference)–18论文</p>
<p>两种推理</p>
<p>1- samples card configurations </p>
<p>如果相同的卡片配置有多个状态，但特征不同(输入到网络)，则决策点不进行推理</p>
<p>2-samples states directly </p>
<p>（method1）采样卡配置将被视为PI的默认方法。当对状态进行采样时，推断将被标记为PIF(Policy Inference Full)</p>
<hr>
<h2 id="《Challenging-Human-Supremacy-in-Skat-–-Guided-and-Complete-And-Or-Belief-Space-Tree-Search-for-Solving-the-Nullspiel-》"><a href="#《Challenging-Human-Supremacy-in-Skat-–-Guided-and-Complete-And-Or-Belief-Space-Tree-Search-for-Solving-the-Nullspiel-》" class="headerlink" title="《Challenging Human Supremacy in Skat – Guided and Complete And-Or Belief-Space Tree Search for Solving the Nullspiel 》"></a>《Challenging Human Supremacy in Skat – Guided and Complete And-Or Belief-Space Tree Search for Solving the Nullspiel 》</h2><h2 id="Scope"><a href="#Scope" class="headerlink" title="Scope"></a>Scope</h2><p>四人游戏（意大利游戏）</p>
<p>《1807.06813 [Scopone] Traditional Wisdom and Monte Carlo Tree Search Face-to-Face in the Card Game Scopone.pdf》</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Paper-Reading/" rel="tag"># Paper Reading</a>
              <a href="/tags/Skat/" rel="tag"># Skat</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/09/18/Games/Game-Poker-Skat/" rel="prev" title="Game-Poker-Skat">
      <i class="fa fa-chevron-left"></i> Game-Poker-Skat
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/09/20/Paper/Paper-CV-Survey/" rel="next" title="Paper-CV-Survey">
      Paper-CV-Survey <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Back"><span class="nav-number">1.</span> <span class="nav-text">Back</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Skat-%E3%80%8ADoctor-Paper%E3%80%8B"><span class="nav-number">2.</span> <span class="nav-text">Skat: 《Doctor Paper》</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SKAT"><span class="nav-number">2.0.1.</span> <span class="nav-text">SKAT:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Poker"><span class="nav-number">2.0.2.</span> <span class="nav-text">Poker</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kermit"><span class="nav-number">2.1.</span> <span class="nav-text">Kermit</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Perfect-Information-Monte-Carlo-Search-for-Cardplay"><span class="nav-number">2.1.1.</span> <span class="nav-text">4.1 Perfect Information Monte Carlo Search for Cardplay</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-State-Evaluation-for-bidding"><span class="nav-number">2.1.2.</span> <span class="nav-text">4.2 State Evaluation for bidding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-inference"><span class="nav-number">2.1.3.</span> <span class="nav-text">4.3 inference</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Why-PIMC"><span class="nav-number">2.2.</span> <span class="nav-text">5. Why PIMC ?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-Understanding-the-Failings-of-PIMC-Search"><span class="nav-number">2.2.1.</span> <span class="nav-text">5.1 Understanding the Failings of PIMC Search</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-Success"><span class="nav-number">2.2.2.</span> <span class="nav-text">5.2 Success</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-3-Methodology"><span class="nav-number">2.2.3.</span> <span class="nav-text">5.3 Methodology</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-4-Experimental-Setup"><span class="nav-number">2.2.4.</span> <span class="nav-text">5.4 Experimental Setup</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-%E7%BB%93%E8%AE%BA"><span class="nav-number">2.2.5.</span> <span class="nav-text">5.5 结论</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6%E3%80%81%E6%8E%A8%E7%90%86"><span class="nav-number">2.3.</span> <span class="nav-text">6、推理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-Inference-and-Non-locality"><span class="nav-number">2.3.1.</span> <span class="nav-text">6.2 Inference and Non-locality</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-3-Inference-in-PIMC-Search"><span class="nav-number">2.3.2.</span> <span class="nav-text">6.3 Inference in PIMC Search</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7%EF%BC%9A"><span class="nav-number">2.4.</span> <span class="nav-text">7：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8"><span class="nav-number">2.5.</span> <span class="nav-text">8</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%95%E7%94%A8"><span class="nav-number">2.6.</span> <span class="nav-text">引用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14%E3%80%8A2019-3-Improving-Search-with-Supervised-Learning-in-Trick-Based-Card-Games%E3%80%8B"><span class="nav-number">3.</span> <span class="nav-text">14《2019.3 Improving Search with Supervised Learning in Trick-Based Card Games》</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#18%E3%80%8A2019-5-Learning-policies-form-human-data-for-skat%E3%80%8B"><span class="nav-number">4.</span> <span class="nav-text">18《2019.5 Learning policies form human data for skat》</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Pre-CardPlay-Train"><span class="nav-number">4.0.1.</span> <span class="nav-text">Pre-CardPlay Train</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CardPlay-Train"><span class="nav-number">4.0.2.</span> <span class="nav-text">CardPlay Train</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#00%E3%80%8A2019-Policy-Based-Inference-in-Trick-Taking-Card-Games%E3%80%8B"><span class="nav-number">5.</span> <span class="nav-text">00《2019 Policy Based Inference in Trick-Taking Card Games》</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E3%80%8AChallenging-Human-Supremacy-in-Skat-%E2%80%93-Guided-and-Complete-And-Or-Belief-Space-Tree-Search-for-Solving-the-Nullspiel-%E3%80%8B"><span class="nav-number">6.</span> <span class="nav-text">《Challenging Human Supremacy in Skat – Guided and Complete And-Or Belief-Space Tree Search for Solving the Nullspiel 》</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scope"><span class="nav-number">7.</span> <span class="nav-text">Scope</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Simon Shi</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">322</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">142</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">269</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:yourname@gmail.com" title="E-Mail → mailto:yourname@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Simon Shi</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
